//
// Copyright (c) 2003, 2013, Oracle and/or its affiliates. All rights reserved.
// Copyright (c) 2015, 2021, Loongson Technology. All rights reserved.
// DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
//
// This code is free software; you can redistribute it and/or modify it
// under the terms of the GNU General Public License version 2 only, as
// published by the Free Software Foundation.
//
// This code is distributed in the hope that it will be useful, but WITHOUT
// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// version 2 for more details (a copy is included in the LICENSE file that
// accompanied this code).
//
// You should have received a copy of the GNU General Public License version
// 2 along with this work; if not, write to the Free Software Foundation,
// Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
//
// Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
// or visit www.oracle.com if you need additional information or have any
// questions.
//
//

// GodSon3 Architecture Description File

//----------REGISTER DEFINITION BLOCK------------------------------------------
// This information is used by the matcher and the register allocator to
// describe individual registers and classes of registers within the target
// archtecture.

// format:
// reg_def name (call convention, c-call convention, ideal type, encoding);
//     call convention :
//      NS  = No-Save
//      SOC = Save-On-Call
//      SOE = Save-On-Entry
//      AS  = Always-Save
//    ideal type :
//      see opto/opcodes.hpp for more info
// reg_class name (reg, ...);
// alloc_class name (reg, ...);
register %{

// General Registers
// Integer Registers
  reg_def R0      ( NS,  NS,   Op_RegI,  0, VMRegImpl::Bad());
  reg_def AT    ( NS,  NS,   Op_RegI,  1, AT->as_VMReg());
  reg_def AT_H    ( NS,  NS,  Op_RegI,  1, AT->as_VMReg()->next());
  reg_def V0    (SOC, SOC,  Op_RegI,  2, V0->as_VMReg());
  reg_def V0_H  (SOC, SOC,  Op_RegI,  2, V0->as_VMReg()->next());
  reg_def V1    (SOC, SOC,  Op_RegI,  3, V1->as_VMReg());
  reg_def V1_H  (SOC, SOC,  Op_RegI,  3, V1->as_VMReg()->next());
  reg_def A0    (SOC, SOC,  Op_RegI,  4, A0->as_VMReg());
  reg_def A0_H  (SOC, SOC,  Op_RegI,  4, A0->as_VMReg()->next());
  reg_def A1    (SOC, SOC,  Op_RegI,  5, A1->as_VMReg());
  reg_def A1_H  (SOC, SOC,  Op_RegI,  5, A1->as_VMReg()->next());
  reg_def A2    (SOC, SOC,  Op_RegI,  6, A2->as_VMReg());
  reg_def A2_H  (SOC, SOC,  Op_RegI,  6, A2->as_VMReg()->next());
  reg_def A3    (SOC, SOC,  Op_RegI,  7, A3->as_VMReg());
  reg_def A3_H  (SOC, SOC,  Op_RegI,  7, A3->as_VMReg()->next());
  reg_def A4    (SOC, SOC,  Op_RegI,  8, A4->as_VMReg());
  reg_def A4_H  (SOC, SOC,  Op_RegI,  8, A4->as_VMReg()->next());
  reg_def A5    (SOC, SOC,  Op_RegI,  9, A5->as_VMReg());
  reg_def A5_H  (SOC, SOC,  Op_RegI,  9, A5->as_VMReg()->next());
  reg_def A6    (SOC, SOC,  Op_RegI,  10, A6->as_VMReg());
  reg_def A6_H  (SOC, SOC,  Op_RegI,  10, A6->as_VMReg()->next());
  reg_def A7    (SOC, SOC,  Op_RegI,  11, A7->as_VMReg());
  reg_def A7_H  (SOC, SOC,  Op_RegI,  11, A7->as_VMReg()->next());
  reg_def T0    (SOC, SOC,  Op_RegI,  12, T0->as_VMReg());
  reg_def T0_H  (SOC, SOC,  Op_RegI,  12, T0->as_VMReg()->next());
  reg_def T1    (SOC, SOC,  Op_RegI,  13, T1->as_VMReg());
  reg_def T1_H  (SOC, SOC,  Op_RegI,  13, T1->as_VMReg()->next());
  reg_def T2    (SOC, SOC,  Op_RegI,  14, T2->as_VMReg());
  reg_def T2_H  (SOC, SOC,  Op_RegI,  14, T2->as_VMReg()->next());
  reg_def T3    (SOC, SOC,  Op_RegI,  15, T3->as_VMReg());
  reg_def T3_H  (SOC, SOC,  Op_RegI,  15, T3->as_VMReg()->next());
  reg_def S0    (SOC, SOE,  Op_RegI,  16, S0->as_VMReg());
  reg_def S0_H  (SOC, SOE,  Op_RegI,  16, S0->as_VMReg()->next());
  reg_def S1    (SOC, SOE,  Op_RegI,  17, S1->as_VMReg());
  reg_def S1_H  (SOC, SOE,  Op_RegI,  17, S1->as_VMReg()->next());
  reg_def S2    (SOC, SOE,  Op_RegI,  18, S2->as_VMReg());
  reg_def S2_H  (SOC, SOE,  Op_RegI,  18, S2->as_VMReg()->next());
  reg_def S3    (SOC, SOE,  Op_RegI,  19, S3->as_VMReg());
  reg_def S3_H  (SOC, SOE,  Op_RegI,  19, S3->as_VMReg()->next());
  reg_def S4    (SOC, SOE,  Op_RegI,  20, S4->as_VMReg());
  reg_def S4_H  (SOC, SOE,  Op_RegI,  20, S4->as_VMReg()->next());
  reg_def S5    (SOC, SOE,  Op_RegI,  21, S5->as_VMReg());
  reg_def S5_H  (SOC, SOE,  Op_RegI,  21, S5->as_VMReg()->next());
  reg_def S6    (SOC, SOE,  Op_RegI,  22, S6->as_VMReg());
  reg_def S6_H  (SOC, SOE,  Op_RegI,  22, S6->as_VMReg()->next());
  reg_def S7    (SOC, SOE,  Op_RegI,  23, S7->as_VMReg());
  reg_def S7_H  (SOC, SOE,  Op_RegI,  23, S7->as_VMReg()->next());
  reg_def T8    (SOC, SOC,  Op_RegI,  24, T8->as_VMReg());
  reg_def T8_H  (SOC, SOC,  Op_RegI,  24, T8->as_VMReg()->next());
  reg_def T9    (SOC, SOC,  Op_RegI,  25, T9->as_VMReg());
  reg_def T9_H  (SOC, SOC,  Op_RegI,  25, T9->as_VMReg()->next());

// Special Registers
  reg_def K0    ( NS,  NS,  Op_RegI, 26, K0->as_VMReg());
  reg_def K1    ( NS,  NS,  Op_RegI, 27, K1->as_VMReg());
  reg_def GP    ( NS,  NS,  Op_RegI, 28, GP->as_VMReg());
  reg_def GP_H  ( NS,  NS,  Op_RegI, 28, GP->as_VMReg()->next());
  reg_def SP    ( NS,  NS,  Op_RegI, 29, SP->as_VMReg());
  reg_def SP_H  ( NS,  NS,  Op_RegI, 29, SP->as_VMReg()->next());
  reg_def FP    ( NS,  NS,  Op_RegI, 30, FP->as_VMReg());
  reg_def FP_H  ( NS,  NS,  Op_RegI, 30, FP->as_VMReg()->next());
  reg_def RA    ( NS,  NS,  Op_RegI, 31, RA->as_VMReg());
  reg_def RA_H  ( NS,  NS,  Op_RegI, 31, RA->as_VMReg()->next());

// Floating registers.
reg_def F0          ( SOC, SOC, Op_RegF, 0, F0->as_VMReg());
reg_def F0_H        ( SOC, SOC, Op_RegF, 0, F0->as_VMReg()->next());
reg_def F1          ( SOC, SOC, Op_RegF, 1, F1->as_VMReg());
reg_def F1_H        ( SOC, SOC, Op_RegF, 1, F1->as_VMReg()->next());
reg_def F2          ( SOC, SOC, Op_RegF, 2, F2->as_VMReg());
reg_def F2_H        ( SOC, SOC, Op_RegF, 2, F2->as_VMReg()->next());
reg_def F3          ( SOC, SOC, Op_RegF, 3, F3->as_VMReg());
reg_def F3_H        ( SOC, SOC, Op_RegF, 3, F3->as_VMReg()->next());
reg_def F4          ( SOC, SOC, Op_RegF, 4, F4->as_VMReg());
reg_def F4_H        ( SOC, SOC, Op_RegF, 4, F4->as_VMReg()->next());
reg_def F5          ( SOC, SOC, Op_RegF, 5, F5->as_VMReg());
reg_def F5_H        ( SOC, SOC, Op_RegF, 5, F5->as_VMReg()->next());
reg_def F6          ( SOC, SOC, Op_RegF, 6, F6->as_VMReg());
reg_def F6_H        ( SOC, SOC, Op_RegF, 6, F6->as_VMReg()->next());
reg_def F7          ( SOC, SOC, Op_RegF, 7, F7->as_VMReg());
reg_def F7_H        ( SOC, SOC, Op_RegF, 7, F7->as_VMReg()->next());
reg_def F8          ( SOC, SOC, Op_RegF, 8, F8->as_VMReg());
reg_def F8_H        ( SOC, SOC, Op_RegF, 8, F8->as_VMReg()->next());
reg_def F9          ( SOC, SOC, Op_RegF, 9, F9->as_VMReg());
reg_def F9_H        ( SOC, SOC, Op_RegF, 9, F9->as_VMReg()->next());
reg_def F10         ( SOC, SOC, Op_RegF, 10, F10->as_VMReg());
reg_def F10_H       ( SOC, SOC, Op_RegF, 10, F10->as_VMReg()->next());
reg_def F11         ( SOC, SOC, Op_RegF, 11, F11->as_VMReg());
reg_def F11_H       ( SOC, SOC, Op_RegF, 11, F11->as_VMReg()->next());
reg_def F12         ( SOC, SOC, Op_RegF, 12, F12->as_VMReg());
reg_def F12_H       ( SOC, SOC, Op_RegF, 12, F12->as_VMReg()->next());
reg_def F13         ( SOC, SOC, Op_RegF, 13, F13->as_VMReg());
reg_def F13_H       ( SOC, SOC, Op_RegF, 13, F13->as_VMReg()->next());
reg_def F14         ( SOC, SOC, Op_RegF, 14, F14->as_VMReg());
reg_def F14_H       ( SOC, SOC, Op_RegF, 14, F14->as_VMReg()->next());
reg_def F15         ( SOC, SOC, Op_RegF, 15, F15->as_VMReg());
reg_def F15_H       ( SOC, SOC, Op_RegF, 15, F15->as_VMReg()->next());
reg_def F16         ( SOC, SOC, Op_RegF, 16, F16->as_VMReg());
reg_def F16_H       ( SOC, SOC, Op_RegF, 16, F16->as_VMReg()->next());
reg_def F17         ( SOC, SOC, Op_RegF, 17, F17->as_VMReg());
reg_def F17_H       ( SOC, SOC, Op_RegF, 17, F17->as_VMReg()->next());
reg_def F18         ( SOC, SOC, Op_RegF, 18, F18->as_VMReg());
reg_def F18_H       ( SOC, SOC, Op_RegF, 18, F18->as_VMReg()->next());
reg_def F19         ( SOC, SOC, Op_RegF, 19, F19->as_VMReg());
reg_def F19_H       ( SOC, SOC, Op_RegF, 19, F19->as_VMReg()->next());
reg_def F20         ( SOC, SOC, Op_RegF, 20, F20->as_VMReg());
reg_def F20_H       ( SOC, SOC, Op_RegF, 20, F20->as_VMReg()->next());
reg_def F21         ( SOC, SOC, Op_RegF, 21, F21->as_VMReg());
reg_def F21_H       ( SOC, SOC, Op_RegF, 21, F21->as_VMReg()->next());
reg_def F22         ( SOC, SOC, Op_RegF, 22, F22->as_VMReg());
reg_def F22_H       ( SOC, SOC, Op_RegF, 22, F22->as_VMReg()->next());
reg_def F23         ( SOC, SOC, Op_RegF, 23, F23->as_VMReg());
reg_def F23_H       ( SOC, SOC, Op_RegF, 23, F23->as_VMReg()->next());
reg_def F24         ( SOC, SOC, Op_RegF, 24, F24->as_VMReg());
reg_def F24_H       ( SOC, SOC, Op_RegF, 24, F24->as_VMReg()->next());
reg_def F25         ( SOC, SOC, Op_RegF, 25, F25->as_VMReg());
reg_def F25_H       ( SOC, SOC, Op_RegF, 25, F25->as_VMReg()->next());
reg_def F26         ( SOC, SOC, Op_RegF, 26, F26->as_VMReg());
reg_def F26_H       ( SOC, SOC, Op_RegF, 26, F26->as_VMReg()->next());
reg_def F27         ( SOC, SOC, Op_RegF, 27, F27->as_VMReg());
reg_def F27_H       ( SOC, SOC, Op_RegF, 27, F27->as_VMReg()->next());
reg_def F28         ( SOC, SOC, Op_RegF, 28, F28->as_VMReg());
reg_def F28_H       ( SOC, SOC, Op_RegF, 28, F28->as_VMReg()->next());
reg_def F29         ( SOC, SOC, Op_RegF, 29, F29->as_VMReg());
reg_def F29_H       ( SOC, SOC, Op_RegF, 29, F29->as_VMReg()->next());
reg_def F30         ( SOC, SOC, Op_RegF, 30, F30->as_VMReg());
reg_def F30_H       ( SOC, SOC, Op_RegF, 30, F30->as_VMReg()->next());
reg_def F31         ( SOC, SOC, Op_RegF, 31, F31->as_VMReg());
reg_def F31_H       ( SOC, SOC, Op_RegF, 31, F31->as_VMReg()->next());


// ----------------------------
// Special Registers
// Condition Codes Flag Registers
reg_def MIPS_FLAG (SOC, SOC,  Op_RegFlags, 1, as_Register(1)->as_VMReg());
//S6 is used for get_thread(S6)
//S5 is uesd for heapbase of compressed oop
alloc_class chunk0(
                     S7, S7_H,
                     S0, S0_H,
                     S1, S1_H,
                     S2, S2_H,
                     S4, S4_H,
                     S5, S5_H,
                     S6, S6_H,
                     S3, S3_H,
                     T2, T2_H,
                     T3, T3_H,
                     T8, T8_H,
                     T9, T9_H,
                     T1, T1_H, // inline_cache_reg
                     V1, V1_H,
                     A7, A7_H,
                     A6, A6_H,
                     A5, A5_H,
                     A4, A4_H,
                     V0, V0_H,
                     A3, A3_H,
                     A2, A2_H,
                     A1, A1_H,
                     A0, A0_H,
                     T0, T0_H,
                     GP, GP_H
                     RA, RA_H,
                     SP, SP_H, // stack_pointer
                     FP, FP_H  // frame_pointer
                 );

alloc_class chunk1(  F0, F0_H,
                     F1, F1_H,
                     F2, F2_H,
                     F3, F3_H,
                     F4, F4_H,
                     F5, F5_H,
                     F6, F6_H,
                     F7, F7_H,
                     F8, F8_H,
                     F9, F9_H,
                     F10, F10_H,
                     F11, F11_H,
                     F20, F20_H,
                     F21, F21_H,
                     F22, F22_H,
                     F23, F23_H,
                     F24, F24_H,
                     F25, F25_H,
                     F26, F26_H,
                     F27, F27_H,
                     F28, F28_H,
                     F19, F19_H,
                     F18, F18_H,
                     F17, F17_H,
                     F16, F16_H,
                     F15, F15_H,
                     F14, F14_H,
                     F13, F13_H,
                     F12, F12_H,
                     F29, F29_H,
                     F30, F30_H,
                     F31, F31_H);

alloc_class chunk2(MIPS_FLAG);

reg_class s_reg( S0, S1, S2, S3, S4, S5, S6, S7 );
reg_class s0_reg( S0 );
reg_class s1_reg( S1 );
reg_class s2_reg( S2 );
reg_class s3_reg( S3 );
reg_class s4_reg( S4 );
reg_class s5_reg( S5 );
reg_class s6_reg( S6 );
reg_class s7_reg( S7 );

reg_class t_reg( T0, T1, T2, T3, T8, T9 );
reg_class t0_reg( T0 );
reg_class t1_reg( T1 );
reg_class t2_reg( T2 );
reg_class t3_reg( T3 );
reg_class t8_reg( T8 );
reg_class t9_reg( T9 );

reg_class a_reg( A0, A1, A2, A3, A4, A5, A6, A7 );
reg_class a0_reg( A0 );
reg_class a1_reg( A1 );
reg_class a2_reg( A2 );
reg_class a3_reg( A3 );
reg_class a4_reg( A4 );
reg_class a5_reg( A5 );
reg_class a6_reg( A6 );
reg_class a7_reg( A7 );

reg_class v0_reg( V0 );
reg_class v1_reg( V1 );

reg_class sp_reg( SP, SP_H );
reg_class fp_reg( FP, FP_H );

reg_class mips_flags(MIPS_FLAG);

reg_class v0_long_reg( V0, V0_H );
reg_class v1_long_reg( V1, V1_H );
reg_class a0_long_reg( A0, A0_H );
reg_class a1_long_reg( A1, A1_H );
reg_class a2_long_reg( A2, A2_H );
reg_class a3_long_reg( A3, A3_H );
reg_class a4_long_reg( A4, A4_H );
reg_class a5_long_reg( A5, A5_H );
reg_class a6_long_reg( A6, A6_H );
reg_class a7_long_reg( A7, A7_H );
reg_class t0_long_reg( T0, T0_H );
reg_class t1_long_reg( T1, T1_H );
reg_class t2_long_reg( T2, T2_H );
reg_class t3_long_reg( T3, T3_H );
reg_class t8_long_reg( T8, T8_H );
reg_class t9_long_reg( T9, T9_H );
reg_class s0_long_reg( S0, S0_H );
reg_class s1_long_reg( S1, S1_H );
reg_class s2_long_reg( S2, S2_H );
reg_class s3_long_reg( S3, S3_H );
reg_class s4_long_reg( S4, S4_H );
reg_class s5_long_reg( S5, S5_H );
reg_class s6_long_reg( S6, S6_H );
reg_class s7_long_reg( S7, S7_H );

reg_class int_reg( S7, S0, S1, S2, S4, S3, T8, T2, T3, T1, V1, A7, A6, A5, A4, V0, A3, A2, A1, A0, T0 );

reg_class no_Ax_int_reg( S7, S0, S1, S2, S4, S3, T8, T2, T3, T1, V1, V0, T0 );

reg_class p_reg(
                 S7, S7_H,
                 S0, S0_H,
                 S1, S1_H,
                 S2, S2_H,
                 S4, S4_H,
                 S3, S3_H,
                 T8, T8_H,
                 T2, T2_H,
                 T3, T3_H,
                 T1, T1_H,
                 A7, A7_H,
                 A6, A6_H,
                 A5, A5_H,
                 A4, A4_H,
                 A3, A3_H,
                 A2, A2_H,
                 A1, A1_H,
                 A0, A0_H,
                 T0, T0_H
               );

reg_class no_T8_p_reg(
                 S7, S7_H,
                 S0, S0_H,
                 S1, S1_H,
                 S2, S2_H,
                 S4, S4_H,
                 S3, S3_H,
                 T2, T2_H,
                 T3, T3_H,
                 T1, T1_H,
                 A7, A7_H,
                 A6, A6_H,
                 A5, A5_H,
                 A4, A4_H,
                 A3, A3_H,
                 A2, A2_H,
                 A1, A1_H,
                 A0, A0_H,
                 T0, T0_H
               );

reg_class long_reg(
                    S7, S7_H,
                    S0, S0_H,
                    S1, S1_H,
                    S2, S2_H,
                    S4, S4_H,
                    S3, S3_H,
                    T8, T8_H,
                    T2, T2_H,
                    T3, T3_H,
                    T1, T1_H,
                    A7, A7_H,
                    A6, A6_H,
                    A5, A5_H,
                    A4, A4_H,
                    A3, A3_H,
                    A2, A2_H,
                    A1, A1_H,
                    A0, A0_H,
                    T0, T0_H
                  );


// Floating point registers.
// F31 are not used as temporary registers in D2I
reg_class flt_reg( F0, F1, F2, F3, F4, F5, F6, F7, F8, F9, F10, F11, F12, F13, F14, F15, F16, F17, F18, F19, F20, F21, F22, F23, F24, F25, F26, F27, F28, F29, F31);
reg_class dbl_reg( F0, F0_H,
                   F1, F1_H,
                   F2, F2_H,
                   F3, F3_H,
                   F4, F4_H,
                   F5, F5_H,
                   F6, F6_H,
                   F7, F7_H,
                   F8, F8_H,
                   F9, F9_H,
                   F10, F10_H,
                   F11, F11_H,
                   F12, F12_H,
                   F13, F13_H,
                   F14, F14_H,
                   F15, F15_H,
                   F16, F16_H,
                   F17, F17_H,
                   F18, F18_H,
                   F19, F19_H,
                   F20, F20_H,
                   F21, F21_H,
                   F22, F22_H,
                   F23, F23_H,
                   F24, F24_H,
                   F25, F25_H,
                   F26, F26_H,
                   F27, F27_H,
                   F28, F28_H,
                   F29, F29_H,
                   F31, F31_H);

reg_class flt_arg0( F12 );
reg_class dbl_arg0( F12, F12_H );
reg_class dbl_arg1( F14, F14_H );

%}

//----------DEFINITION BLOCK---------------------------------------------------
// Define name --> value mappings to inform the ADLC of an integer valued name
// Current support includes integer values in the range [0, 0x7FFFFFFF]
// Format:
//        int_def  <name>         ( <int_value>, <expression>);
// Generated Code in ad_<arch>.hpp
//        #define  <name>   (<expression>)
//        // value == <int_value>
// Generated code in ad_<arch>.cpp adlc_verification()
//        assert( <name> == <int_value>, "Expect (<expression>) to equal <int_value>");
//
definitions %{
  int_def DEFAULT_COST      (    100,     100);
  int_def HUGE_COST         (1000000, 1000000);

  // Memory refs are twice as expensive as run-of-the-mill.
  int_def MEMORY_REF_COST   (    200, DEFAULT_COST * 2);

  // Branches are even more expensive.
  int_def BRANCH_COST       (    300, DEFAULT_COST * 3);
  // we use jr instruction to construct call, so more expensive
  int_def CALL_COST         (    500, DEFAULT_COST * 5);
/*
        int_def EQUAL             (   1, 1  );
        int_def NOT_EQUAL         (   2, 2  );
        int_def GREATER           (   3, 3  );
        int_def GREATER_EQUAL     (   4, 4  );
        int_def LESS              (   5, 5  );
        int_def LESS_EQUAL        (   6, 6  );
*/
%}



//----------SOURCE BLOCK-------------------------------------------------------
// This is a block of C++ code which provides values, functions, and
// definitions necessary in the rest of the architecture description

source_hpp %{
// Header information of the source block.
// Method declarations/definitions which are used outside
// the ad-scope can conveniently be defined here.
//
// To keep related declarations/definitions/uses close together,
// we switch between source %{ }% and source_hpp %{ }% freely as needed.

class CallStubImpl {

  //--------------------------------------------------------------
  //---<  Used for optimization in Compile::shorten_branches  >---
  //--------------------------------------------------------------

 public:
  // Size of call trampoline stub.
  static uint size_call_trampoline() {
    return 0; // no call trampolines on this platform
  }

  // number of relocations needed by a call trampoline stub
  static uint reloc_call_trampoline() {
    return 0; // no call trampolines on this platform
  }
};

class HandlerImpl {

 public:

  static int emit_exception_handler(CodeBuffer &cbuf);
  static int emit_deopt_handler(CodeBuffer& cbuf);

  static uint size_exception_handler() {
    // NativeCall instruction size is the same as NativeJump.
    // exception handler starts out as jump and can be patched to
    // a call be deoptimization.  (4932387)
    // Note that this value is also credited (in output.cpp) to
    // the size of the code section.
    int size = NativeCall::instruction_size;
    return round_to(size, 16);
  }

#ifdef _LP64
  static uint size_deopt_handler() {
    int size = NativeCall::instruction_size;
    return round_to(size, 16);
  }
#else
  static uint size_deopt_handler() {
    // NativeCall instruction size is the same as NativeJump.
    // exception handler starts out as jump and can be patched to
    // a call be deoptimization.  (4932387)
    // Note that this value is also credited (in output.cpp) to
    // the size of the code section.
    return 5 + NativeJump::instruction_size; // pushl(); jmp;
  }
#endif
};

%} // end source_hpp

source %{

#define   NO_INDEX    0
#define   RELOC_IMM64    Assembler::imm_operand
#define   RELOC_DISP32   Assembler::disp32_operand


#define __ _masm.

#define A0 RA0
#define A1 RA1
#define A2 RA2
#define A3 RA3
#define A4 RA4
#define A5 RA5
#define A6 RA6
#define A7 RA7
#define T0 RT0
#define T1 RT1
#define T2 RT2
#define T3 RT3
#define T8 RT8
#define T9 RT9


// Emit exception handler code.
// Stuff framesize into a register and call a VM stub routine.
int HandlerImpl::emit_exception_handler(CodeBuffer& cbuf) {
  // Note that the code buffer's insts_mark is always relative to insts.
  // That's why we must use the macroassembler to generate a handler.
  MacroAssembler _masm(&cbuf);
  address base = __ start_a_stub(size_exception_handler());
  if (base == NULL) {
    ciEnv::current()->record_failure("CodeCache is full");
    return 0;  // CodeBuffer::expand failed
  }

  int offset = __ offset();

  __ block_comment("; emit_exception_handler");

  cbuf.set_insts_mark();
  __ relocate(relocInfo::runtime_call_type);
  __ patchable_jump((address)OptoRuntime::exception_blob()->entry_point());
  __ align(16);
  assert(__ offset() - offset <= (int) size_exception_handler(), "overflow");
  __ end_a_stub();
  return offset;
}

// Emit deopt handler code.
int HandlerImpl::emit_deopt_handler(CodeBuffer& cbuf) {
  // Note that the code buffer's insts_mark is always relative to insts.
  // That's why we must use the macroassembler to generate a handler.
  MacroAssembler _masm(&cbuf);
  address base = __ start_a_stub(size_deopt_handler());
  if (base == NULL) {
    ciEnv::current()->record_failure("CodeCache is full");
    return 0;  // CodeBuffer::expand failed
  }

  int offset = __ offset();

  __ block_comment("; emit_deopt_handler");

  cbuf.set_insts_mark();
  __ relocate(relocInfo::runtime_call_type);
  __ patchable_call(SharedRuntime::deopt_blob()->unpack());
  __ align(16);
  assert(__ offset() - offset <= (int) size_deopt_handler(), "overflow");
  __ end_a_stub();
  return offset;
}


const bool Matcher::match_rule_supported(int opcode) {
  if (!has_match_rule(opcode))
    return false;

  switch (opcode) {
    //Op_CountLeadingZerosI Op_CountLeadingZerosL can be deleted, all MIPS CPUs support clz & dclz.
    case Op_CountLeadingZerosI:
    case Op_CountLeadingZerosL:
      if (!UseCountLeadingZerosInstructionMIPS64)
        return false;
      break;
    case Op_CountTrailingZerosI:
    case Op_CountTrailingZerosL:
      if (!UseCountTrailingZerosInstructionMIPS64)
        return false;
      break;
  }

  return true;  // Per default match rules are supported.
}

bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
  int offs = offset - br_size + 4;
  // To be conservative on MIPS
  // branch node should be end with:
  //   branch inst
  //   delay slot
  const int safety_zone = 3 * BytesPerInstWord;
  return Assembler::is_simm16((offs<0 ? offs-safety_zone : offs+safety_zone) >> 2);
}


// No additional cost for CMOVL.
const int Matcher::long_cmove_cost() { return 0; }

// No CMOVF/CMOVD with SSE2
const int Matcher::float_cmove_cost() { return ConditionalMoveLimit; }

// Does the CPU require late expand (see block.cpp for description of late expand)?
const bool Matcher::require_postalloc_expand = false;

// Should the Matcher clone shifts on addressing modes, expecting them
// to be subsumed into complex addressing expressions or compute them
// into registers?  True for Intel but false for most RISCs
const bool Matcher::clone_shift_expressions = false;

// Do we need to mask the count passed to shift instructions or does
// the cpu only look at the lower 5/6 bits anyway?
const bool Matcher::need_masked_shift_count = false;

bool Matcher::narrow_oop_use_complex_address() {
  NOT_LP64(ShouldNotCallThis());
  assert(UseCompressedOops, "only for compressed oops code");
  return false;
}

bool Matcher::narrow_klass_use_complex_address() {
  NOT_LP64(ShouldNotCallThis());
  assert(UseCompressedClassPointers, "only for compressed klass code");
  return false;
}

// This is UltraSparc specific, true just means we have fast l2f conversion
const bool Matcher::convL2FSupported(void) {
  return true;
}

// Max vector size in bytes. 0 if not supported.
const int Matcher::vector_width_in_bytes(BasicType bt) {
  if (MaxVectorSize == 0)
    return 0;
  assert(MaxVectorSize == 8, "");
  return 8;
}

// Vector ideal reg
const uint Matcher::vector_ideal_reg(int size) {
  assert(MaxVectorSize == 8, "");
  switch(size) {
    case  8: return Op_VecD;
  }
  ShouldNotReachHere();
  return 0;
}

// Only lowest bits of xmm reg are used for vector shift count.
const uint Matcher::vector_shift_count_ideal_reg(int size) {
  fatal("vector shift is not supported");
  return Node::NotAMachineReg;
}

// Limits on vector size (number of elements) loaded into vector.
const int Matcher::max_vector_size(const BasicType bt) {
  assert(is_java_primitive(bt), "only primitive type vectors");
  return vector_width_in_bytes(bt)/type2aelembytes(bt);
}

const int Matcher::min_vector_size(const BasicType bt) {
  return max_vector_size(bt); // Same as max.
}

// MIPS supports misaligned vectors store/load? FIXME
const bool Matcher::misaligned_vectors_ok() {
  return false;
  //return !AlignVector; // can be changed by flag
}

// Register for DIVI projection of divmodI
RegMask Matcher::divI_proj_mask() {
  ShouldNotReachHere();
  return RegMask();
}

// Register for MODI projection of divmodI
RegMask Matcher::modI_proj_mask() {
  ShouldNotReachHere();
  return RegMask();
}

// Register for DIVL projection of divmodL
RegMask Matcher::divL_proj_mask() {
  ShouldNotReachHere();
  return RegMask();
}

int Matcher::regnum_to_fpu_offset(int regnum) {
  return regnum - 32; // The FP registers are in the second chunk
}


const bool Matcher::isSimpleConstant64(jlong value) {
  // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
  return true;
}


// Return whether or not this register is ever used as an argument.  This
// function is used on startup to build the trampoline stubs in generateOptoStub.
// Registers not mentioned will be killed by the VM call in the trampoline, and
// arguments in those registers not be available to the callee.
bool Matcher::can_be_java_arg( int reg ) {
  // Refer to: [sharedRuntime_mips_64.cpp] SharedRuntime::java_calling_convention()
  if (    reg == T0_num || reg == T0_H_num
       || reg == A0_num || reg == A0_H_num
       || reg == A1_num || reg == A1_H_num
       || reg == A2_num || reg == A2_H_num
       || reg == A3_num || reg == A3_H_num
       || reg == A4_num || reg == A4_H_num
       || reg == A5_num || reg == A5_H_num
       || reg == A6_num || reg == A6_H_num
       || reg == A7_num || reg == A7_H_num )
    return true;

  if (    reg == F12_num || reg == F12_H_num
       || reg == F13_num || reg == F13_H_num
       || reg == F14_num || reg == F14_H_num
       || reg == F15_num || reg == F15_H_num
       || reg == F16_num || reg == F16_H_num
       || reg == F17_num || reg == F17_H_num
       || reg == F18_num || reg == F18_H_num
       || reg == F19_num || reg == F19_H_num )
    return true;

  return false;
}

bool Matcher::is_spillable_arg( int reg ) {
  return can_be_java_arg(reg);
}

bool Matcher::use_asm_for_ldiv_by_con( jlong divisor ) {
  return false;
}

// Register for MODL projection of divmodL
RegMask Matcher::modL_proj_mask() {
  ShouldNotReachHere();
  return RegMask();
}

const RegMask Matcher::method_handle_invoke_SP_save_mask() {
  return FP_REG_mask();
}

// MIPS doesn't support AES intrinsics
const bool Matcher::pass_original_key_for_aes() {
  return false;
}

int CallStaticJavaDirectNode::compute_padding(int current_offset) const {
  return round_to(current_offset, alignment_required()) - current_offset;
}

int CallDynamicJavaDirectNode::compute_padding(int current_offset) const {
  return round_to(current_offset, alignment_required()) - current_offset;
}

int CallLeafNoFPDirectNode::compute_padding(int current_offset) const {
  return round_to(current_offset, alignment_required()) - current_offset;
}

int CallLeafDirectNode::compute_padding(int current_offset) const {
  return round_to(current_offset, alignment_required()) - current_offset;
}

int CallRuntimeDirectNode::compute_padding(int current_offset) const {
  return round_to(current_offset, alignment_required()) - current_offset;
}

// If CPU can load and store mis-aligned doubles directly then no fixup is
// needed.  Else we split the double into 2 integer pieces and move it
// piece-by-piece.  Only happens when passing doubles into C code as the
// Java calling convention forces doubles to be aligned.
const bool Matcher::misaligned_doubles_ok = false;
// Do floats take an entire double register or just half?
//const bool Matcher::float_in_double = true;
bool Matcher::float_in_double() { return false; }
// Threshold size for cleararray.
const int Matcher::init_array_short_size = 8 * BytesPerLong;
// Do ints take an entire long register or just half?
const bool Matcher::int_in_long = true;
// Is it better to copy float constants, or load them directly from memory?
// Intel can load a float constant from a direct address, requiring no
// extra registers.  Most RISCs will have to materialize an address into a
// register first, so they would do better to copy the constant from stack.
const bool Matcher::rematerialize_float_constants = false;
// Advertise here if the CPU requires explicit rounding operations
// to implement the UseStrictFP mode.
const bool Matcher::strict_fp_requires_explicit_rounding = false;
// false => size gets scaled to BytesPerLong, ok.
const bool Matcher::init_array_count_is_in_bytes = false;

// Indicate if the safepoint node needs the polling page as an input.
// Since MIPS doesn't have absolute addressing, it needs.
bool SafePointNode::needs_polling_address_input() {
  return false;
}

// !!!!! Special hack to get all type of calls to specify the byte offset
//       from the start of the call to the point where the return address
//       will point.
int MachCallStaticJavaNode::ret_addr_offset() {
  //lui
  //ori
  //nop
  //nop
  //jalr
  //nop
  return 24;
}

int MachCallDynamicJavaNode::ret_addr_offset() {
  //lui IC_Klass,
  //ori IC_Klass,
  //dsll IC_Klass
  //ori IC_Klass

  //lui T9
  //ori T9
  //nop
  //nop
  //jalr T9
  //nop
  return 4 * 4 + 4 * 6;
}

//=============================================================================

// Figure out which register class each belongs in: rc_int, rc_float, rc_stack
enum RC { rc_bad, rc_int, rc_float, rc_stack };
static enum RC rc_class( OptoReg::Name reg ) {
  if( !OptoReg::is_valid(reg)  ) return rc_bad;
  if (OptoReg::is_stack(reg)) return rc_stack;
  VMReg r = OptoReg::as_VMReg(reg);
  if (r->is_Register()) return rc_int;
  assert(r->is_FloatRegister(), "must be");
  return rc_float;
}

uint MachSpillCopyNode::implementation( CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream* st ) const {
  // Get registers to move
  OptoReg::Name src_second = ra_->get_reg_second(in(1));
  OptoReg::Name src_first = ra_->get_reg_first(in(1));
  OptoReg::Name dst_second = ra_->get_reg_second(this );
  OptoReg::Name dst_first = ra_->get_reg_first(this );

  enum RC src_second_rc = rc_class(src_second);
  enum RC src_first_rc = rc_class(src_first);
  enum RC dst_second_rc = rc_class(dst_second);
  enum RC dst_first_rc = rc_class(dst_first);

  assert(OptoReg::is_valid(src_first) && OptoReg::is_valid(dst_first), "must move at least 1 register" );

  // Generate spill code!
  int size = 0;

  if( src_first == dst_first && src_second == dst_second )
    return 0;            // Self copy, no move

  if (src_first_rc == rc_stack) {
    // mem ->
    if (dst_first_rc == rc_stack) {
      // mem -> mem
      assert(src_second != dst_first, "overlap");
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        int src_offset = ra_->reg2offset(src_first);
        int dst_offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ ld(AT, Address(SP, src_offset));
          __ sd(AT, Address(SP, dst_offset));
#ifndef PRODUCT
        } else {
          if(!do_size){
            if (size != 0) st->print("\n\t");
              st->print("ld    AT, [SP + #%d]\t# 64-bit mem-mem spill 1\n\t"
                        "sd    AT, [SP + #%d]",
                        src_offset, dst_offset);
          }
#endif
        }
        size += 8;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        // No pushl/popl, so:
        int src_offset = ra_->reg2offset(src_first);
        int dst_offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ lw(AT, Address(SP, src_offset));
          __ sw(AT, Address(SP, dst_offset));
#ifndef PRODUCT
        } else {
          if(!do_size){
            if (size != 0) st->print("\n\t");
              st->print("lw    AT, [SP + #%d] spill 2\n\t"
                        "sw    AT, [SP + #%d]\n\t",
                        src_offset, dst_offset);
          }
#endif
        }
        size += 8;
      }
      return size;
    } else if (dst_first_rc == rc_int) {
      // mem -> gpr
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        int offset = ra_->reg2offset(src_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ ld(as_Register(Matcher::_regEncode[dst_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
          if(!do_size){
            if (size != 0) st->print("\n\t");
              st->print("ld    %s, [SP + #%d]\t# spill 3",
                        Matcher::regName[dst_first],
                        offset);
          }
#endif
        }
        size += 4;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        int offset = ra_->reg2offset(src_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          if (this->ideal_reg() == Op_RegI)
            __ lw(as_Register(Matcher::_regEncode[dst_first]), Address(SP, offset));
          else
            __ lwu(as_Register(Matcher::_regEncode[dst_first]), Address(SP, offset));
#ifndef PRODUCT
          } else {
            if(!do_size){
              if (size != 0) st->print("\n\t");
              if (this->ideal_reg() == Op_RegI)
                st->print("lw    %s, [SP + #%d]\t# spill 4",
                          Matcher::regName[dst_first],
                          offset);
              else
                st->print("lwu    %s, [SP + #%d]\t# spill 5",
                          Matcher::regName[dst_first],
                          offset);
            }
#endif
          }
          size += 4;
      }
      return size;
    } else if (dst_first_rc == rc_float) {
      // mem-> xmm
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        int offset = ra_->reg2offset(src_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ ldc1( as_FloatRegister(Matcher::_regEncode[dst_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
          if (!do_size) {
            if (size != 0) st->print("\n\t");
            st->print("ldc1  %s, [SP + #%d]\t# spill 6",
                      Matcher::regName[dst_first],
                      offset);
          }
#endif
        }
        size += 4;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        int offset = ra_->reg2offset(src_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ lwc1( as_FloatRegister(Matcher::_regEncode[dst_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
          if(!do_size){
            if (size != 0) st->print("\n\t");
            st->print("lwc1   %s, [SP + #%d]\t# spill 7",
                      Matcher::regName[dst_first],
                      offset);
            }
#endif
        }
        size += 4;
      }
      return size;
    }
  } else if (src_first_rc == rc_int) {
    // gpr ->
    if (dst_first_rc == rc_stack) {
      // gpr -> mem
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        int offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ sd(as_Register(Matcher::_regEncode[src_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
          if(!do_size){
            if (size != 0) st->print("\n\t");
            st->print("sd    %s, [SP + #%d] # spill 8",
                      Matcher::regName[src_first],
                      offset);
          }
#endif
        }
        size += 4;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        int offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ sw(as_Register(Matcher::_regEncode[src_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
          if (!do_size) {
            if (size != 0) st->print("\n\t");
            st->print("sw    %s, [SP + #%d]\t# spill 9",
                      Matcher::regName[src_first], offset);
          }
#endif
        }
        size += 4;
      }
      return size;
    } else if (dst_first_rc == rc_int) {
      // gpr -> gpr
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ move(as_Register(Matcher::_regEncode[dst_first]),
                  as_Register(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
          if(!do_size){
            if (size != 0) st->print("\n\t");
            st->print("move(64bit)    %s <-- %s\t# spill 10",
                      Matcher::regName[dst_first],
                      Matcher::regName[src_first]);
          }
#endif
        }
        size += 4;
        return size;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          if (this->ideal_reg() == Op_RegI)
              __ move_u32(as_Register(Matcher::_regEncode[dst_first]), as_Register(Matcher::_regEncode[src_first]));
          else
              __ daddu(as_Register(Matcher::_regEncode[dst_first]), as_Register(Matcher::_regEncode[src_first]), R0);
#ifndef PRODUCT
        } else {
          if (!do_size) {
            if (size != 0) st->print("\n\t");
            st->print("move(32-bit)    %s <-- %s\t# spill 11",
                      Matcher::regName[dst_first],
                      Matcher::regName[src_first]);
          }
#endif
        }
        size += 4;
        return size;
      }
    } else if (dst_first_rc == rc_float) {
      // gpr -> xmm
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ dmtc1(as_Register(Matcher::_regEncode[src_first]), as_FloatRegister(Matcher::_regEncode[dst_first]));
#ifndef PRODUCT
        } else {
          if(!do_size){
            if (size != 0) st->print("\n\t");
            st->print("dmtc1   %s, %s\t# spill 12",
                      Matcher::regName[dst_first],
                      Matcher::regName[src_first]);
          }
#endif
        }
        size += 4;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ mtc1( as_Register(Matcher::_regEncode[src_first]), as_FloatRegister(Matcher::_regEncode[dst_first]) );
#ifndef PRODUCT
        } else {
          if(!do_size){
            if (size != 0) st->print("\n\t");
            st->print("mtc1   %s, %s\t# spill 13",
                      Matcher::regName[dst_first],
                      Matcher::regName[src_first]);
          }
#endif
        }
        size += 4;
      }
      return size;
    }
  } else if (src_first_rc == rc_float) {
    // xmm ->
    if (dst_first_rc == rc_stack) {
      // xmm -> mem
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        int offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ sdc1( as_FloatRegister(Matcher::_regEncode[src_first]), Address(SP, offset) );
#ifndef PRODUCT
        } else {
          if(!do_size){
            if (size != 0) st->print("\n\t");
            st->print("sdc1   %s, [SP + #%d]\t# spill 14",
                      Matcher::regName[src_first],
                      offset);
          }
#endif
        }
        size += 4;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        int offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ swc1(as_FloatRegister(Matcher::_regEncode[src_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
          if(!do_size){
            if (size != 0) st->print("\n\t");
            st->print("swc1   %s, [SP + #%d]\t# spill 15",
                      Matcher::regName[src_first],
                      offset);
          }
#endif
        }
        size += 4;
      }
      return size;
    } else if (dst_first_rc == rc_int) {
      // xmm -> gpr
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ dmfc1( as_Register(Matcher::_regEncode[dst_first]), as_FloatRegister(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
          if(!do_size){
            if (size != 0) st->print("\n\t");
            st->print("dmfc1   %s, %s\t# spill 16",
                      Matcher::regName[dst_first],
                      Matcher::regName[src_first]);
          }
#endif
        }
        size += 4;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ mfc1( as_Register(Matcher::_regEncode[dst_first]), as_FloatRegister(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
      if(!do_size){
            if (size != 0) st->print("\n\t");
            st->print("mfc1   %s, %s\t# spill 17",
                      Matcher::regName[dst_first],
                      Matcher::regName[src_first]);
          }
#endif
        }
        size += 4;
      }
      return size;
    } else if (dst_first_rc == rc_float) {
      // xmm -> xmm
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ mov_d( as_FloatRegister(Matcher::_regEncode[dst_first]), as_FloatRegister(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
          if(!do_size){
            if (size != 0) st->print("\n\t");
            st->print("mov_d  %s <-- %s\t# spill 18",
                      Matcher::regName[dst_first],
                      Matcher::regName[src_first]);
          }
#endif
        }
        size += 4;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ mov_s( as_FloatRegister(Matcher::_regEncode[dst_first]), as_FloatRegister(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
          if(!do_size){
            if (size != 0) st->print("\n\t");
            st->print("mov_s  %s <-- %s\t# spill 19",
                      Matcher::regName[dst_first],
                      Matcher::regName[src_first]);
          }
#endif
        }
        size += 4;
      }
      return size;
    }
  }

  assert(0," foo ");
  Unimplemented();
  return size;

}

#ifndef PRODUCT
void MachSpillCopyNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {
  implementation( NULL, ra_, false, st );
}
#endif

void MachSpillCopyNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
  implementation( &cbuf, ra_, false, NULL );
}

uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
  return MachNode::size(ra_);
}

//=============================================================================
#

#ifndef PRODUCT
void MachBreakpointNode::format( PhaseRegAlloc *, outputStream* st ) const {
  st->print("INT3");
}
#endif

void MachBreakpointNode::emit(CodeBuffer &cbuf, PhaseRegAlloc* ra_) const {
  MacroAssembler _masm(&cbuf);
  __ int3();
}

uint MachBreakpointNode::size(PhaseRegAlloc* ra_) const {
  return MachNode::size(ra_);
}


//=============================================================================
#ifndef PRODUCT
void MachEpilogNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {
  Compile *C = ra_->C;
  int framesize = C->frame_size_in_bytes();

  assert((framesize & (StackAlignmentInBytes-1)) == 0, "frame size not aligned");

  st->print_cr("daddiu   SP, SP, %d # Rlease stack @ MachEpilogNode", framesize);
  st->print("\t");
  if (UseLEXT1) {
    st->print_cr("gslq  RA, FP, SP, %d # Restore FP & RA @ MachEpilogNode", -wordSize*2);
  } else {
    st->print_cr("ld    RA, SP, %d # Restore RA @ MachEpilogNode", -wordSize);
    st->print("\t");
    st->print_cr("ld    FP, SP, %d # Restore FP @ MachEpilogNode", -wordSize*2);
  }

  if( do_polling() && C->is_method_compilation() ) {
    st->print("\t");
    st->print_cr("Poll Safepoint # MachEpilogNode");
  }
}
#endif

void MachEpilogNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
  Compile *C = ra_->C;
  MacroAssembler _masm(&cbuf);
  int framesize = C->frame_size_in_bytes();

  assert((framesize & (StackAlignmentInBytes-1)) == 0, "frame size not aligned");

  if (UseLEXT1) {
    __ gslq(RA, FP, SP, framesize - wordSize * 2);
  } else {
    __ ld(RA, SP, framesize - wordSize );
    __ ld(FP, SP, framesize - wordSize * 2);
  }
  __ daddiu(SP, SP, framesize);

  if( do_polling() && C->is_method_compilation() ) {
    __ set64(AT, (long)os::get_polling_page());
    __ relocate(relocInfo::poll_return_type);
    __ lw(AT, AT, 0);
  }
}

uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
  return MachNode::size(ra_); // too many variables; just compute it the hard way  fujie debug
}

int MachEpilogNode::reloc() const {
  return 0; // a large enough number
}

const Pipeline * MachEpilogNode::pipeline() const {
  return MachNode::pipeline_class();
}

int MachEpilogNode::safepoint_offset() const { return 0; }

//=============================================================================

#ifndef PRODUCT
void BoxLockNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {
  int offset = ra_->reg2offset(in_RegMask(0).find_first_elem());
  int reg = ra_->get_reg_first(this);
  st->print("ADDI %s, SP, %d   @BoxLockNode",Matcher::regName[reg],offset);
}
#endif


uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
  return 4;
}

void BoxLockNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
  MacroAssembler _masm(&cbuf);
  int offset = ra_->reg2offset(in_RegMask(0).find_first_elem());
  int reg = ra_->get_encode(this);

  __ addiu(as_Register(reg), SP, offset);
}


//static int sizeof_FFree_Float_Stack_All = -1;

int MachCallRuntimeNode::ret_addr_offset() {
  //lui
  //ori
  //dsll
  //ori
  //jalr
  //nop
  assert(NativeCall::instruction_size == 24, "in MachCallRuntimeNode::ret_addr_offset()");
  return NativeCall::instruction_size;
}


//=============================================================================
#ifndef PRODUCT
void MachNopNode::format( PhaseRegAlloc *, outputStream* st ) const {
  st->print("NOP \t# %d bytes pad for loops and calls", 4 * _count);
}
#endif

void MachNopNode::emit(CodeBuffer &cbuf, PhaseRegAlloc * ) const {
  MacroAssembler _masm(&cbuf);
  int i = 0;
  for(i = 0; i < _count; i++)
     __ nop();
}

uint MachNopNode::size(PhaseRegAlloc *) const {
  return 4 * _count;
}
const Pipeline* MachNopNode::pipeline() const {
  return MachNode::pipeline_class();
}

//=============================================================================

//=============================================================================
#ifndef PRODUCT
void MachUEPNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {
  st->print_cr("load_klass(T9, T0)");
  st->print_cr("\tbeq(T9, iCache, L)");
  st->print_cr("\tnop");
  st->print_cr("\tjmp(SharedRuntime::get_ic_miss_stub(), relocInfo::runtime_call_type)");
  st->print_cr("\tnop");
  st->print_cr("\tnop");
  st->print_cr("    L:");
}
#endif


void MachUEPNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
  MacroAssembler _masm(&cbuf);
  int  ic_reg = Matcher::inline_cache_reg_encode();
  Label L;
  Register receiver = T0;
  Register   iCache = as_Register(ic_reg);

  __ load_klass(T9, receiver);
  __ beq(T9, iCache, L);
  __ delayed()->nop();
  __ jmp((address)SharedRuntime::get_ic_miss_stub(), relocInfo::runtime_call_type);
  __ delayed()->nop();
  __ bind(L);
}

uint MachUEPNode::size(PhaseRegAlloc *ra_) const {
  return MachNode::size(ra_);
}



//=============================================================================

const RegMask& MachConstantBaseNode::_out_RegMask = P_REG_mask();

int Compile::ConstantTable::calculate_table_base_offset() const {
  return 0;  // absolute addressing, no offset
}

bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
void MachConstantBaseNode::postalloc_expand(GrowableArray <Node *> *nodes, PhaseRegAlloc *ra_) {
  ShouldNotReachHere();
}

void MachConstantBaseNode::emit(CodeBuffer& cbuf, PhaseRegAlloc* ra_) const {
  Compile* C = ra_->C;
  Compile::ConstantTable& constant_table = C->constant_table();
  MacroAssembler _masm(&cbuf);

  Register Rtoc = as_Register(ra_->get_encode(this));
  CodeSection* consts_section = __ code()->consts();
  int consts_size = consts_section->align_at_start(consts_section->size());
  assert(constant_table.size() == consts_size, "must be equal");

  if (consts_section->size()) {
    // Materialize the constant table base.
    address baseaddr = consts_section->start() + -(constant_table.table_base_offset());
    // RelocationHolder rspec = internal_word_Relocation::spec(baseaddr);
    __ relocate(relocInfo::internal_word_type);
    __ patchable_set48(Rtoc, (long)baseaddr);
  }
}

uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
  // patchable_set48 (4 insts)
  return 4 * 4;
}

#ifndef PRODUCT
void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
  Register r = as_Register(ra_->get_encode(this));
  st->print("patchable_set48    %s, &constanttable (constant table base) @ MachConstantBaseNode", r->name());
}
#endif


//=============================================================================
#ifndef PRODUCT
void MachPrologNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {
  Compile* C = ra_->C;

  int framesize = C->frame_size_in_bytes();
  int bangsize = C->bang_size_in_bytes();
  assert((framesize & (StackAlignmentInBytes-1)) == 0, "frame size not aligned");

  // Calls to C2R adapters often do not accept exceptional returns.
  // We require that their callers must bang for them.  But be careful, because
  // some VM calls (such as call site linkage) can use several kilobytes of
  // stack.  But the stack safety zone should account for that.
  // See bugs 4446381, 4468289, 4497237.
  if (C->need_stack_bang(bangsize)) {
    st->print_cr("# stack bang"); st->print("\t");
  }
  if (UseLEXT1) {
    st->print("gssq     RA, FP, %d(SP)  @ MachPrologNode\n\t", -wordSize*2);
  } else {
    st->print("sd       RA, %d(SP)  @ MachPrologNode\n\t", -wordSize);
    st->print("sd       FP, %d(SP)  @ MachPrologNode\n\t", -wordSize*2);
  }
  st->print("daddiu   FP, SP, -%d \n\t", wordSize*2);
  st->print("daddiu   SP, SP, -%d \t",framesize);
}
#endif


void MachPrologNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
  Compile* C = ra_->C;
  MacroAssembler _masm(&cbuf);

  int framesize = C->frame_size_in_bytes();
  int bangsize = C->bang_size_in_bytes();

  assert((framesize & (StackAlignmentInBytes-1)) == 0, "frame size not aligned");

  // Make enough room for patch_verified_entry
  __ nop();
  __ nop();

  if (C->need_stack_bang(bangsize)) {
    __ generate_stack_overflow_check(bangsize);
  }

  __ daddiu(SP, SP, -framesize);
  if (UseLEXT1) {
    __ gssq(RA, FP, SP, framesize - wordSize * 2);
  } else {
    __ sd(RA, SP, framesize - wordSize);
    __ sd(FP, SP, framesize - wordSize * 2);
  }
  __ daddiu(FP, SP, framesize - wordSize * 2);

  C->set_frame_complete(cbuf.insts_size());
  if (C->has_mach_constant_base_node()) {
    // NOTE: We set the table base offset here because users might be
    // emitted before MachConstantBaseNode.
    Compile::ConstantTable& constant_table = C->constant_table();
    constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
  }
}


uint MachPrologNode::size(PhaseRegAlloc *ra_) const {
  return MachNode::size(ra_); // too many variables; just compute it the hard way
}

int MachPrologNode::reloc() const {
  return 0; // a large enough number
}

%}

//----------ENCODING BLOCK-----------------------------------------------------
// This block specifies the encoding classes used by the compiler to output
// byte streams.  Encoding classes generate functions which are called by
// Machine Instruction Nodes in order to generate the bit encoding of the
// instruction.  Operands specify their base encoding interface with the
// interface keyword.  There are currently supported four interfaces,
// REG_INTER, CONST_INTER, MEMORY_INTER, & COND_INTER.  REG_INTER causes an
// operand to generate a function which returns its register number when
// queried.   CONST_INTER causes an operand to generate a function which
// returns the value of the constant when queried.  MEMORY_INTER causes an
// operand to generate four functions which return the Base Register, the
// Index Register, the Scale Value, and the Offset Value of the operand when
// queried.  COND_INTER causes an operand to generate six functions which
// return the encoding code (ie - encoding bits for the instruction)
// associated with each basic boolean condition for a conditional instruction.
// Instructions specify two basic values for encoding.  They use the
// ins_encode keyword to specify their encoding class (which must be one of
// the class names specified in the encoding block), and they use the
// opcode keyword to specify, in order, their primary, secondary, and
// tertiary opcode.  Only the opcode sections which a particular instruction
// needs for encoding need to be specified.
encode %{

  //Load byte signed
  enc_class load_B_enc (mRegI dst, memory mem) %{
    MacroAssembler _masm(&cbuf);
    int  dst = $dst$$reg;
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if( Assembler::is_simm16(disp) ) {
        if (UseLEXT1) {
          if (scale == 0) {
            __ gslbx(as_Register(dst), as_Register(base), as_Register(index), disp);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ gslbx(as_Register(dst), as_Register(base), AT, disp);
          }
        } else {
          if (scale == 0) {
            __ addu(AT, as_Register(base), as_Register(index));
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ addu(AT, as_Register(base), AT);
          }
          __ lb(as_Register(dst), AT, disp);
        }
      } else {
        if (scale == 0) {
          __ addu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ addu(AT, as_Register(base), AT);
        }
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gslbx(as_Register(dst), AT, T9, 0);
        } else {
          __ addu(AT, AT, T9);
          __ lb(as_Register(dst), AT, 0);
        }
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ lb(as_Register(dst), as_Register(base), disp);
      } else {
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gslbx(as_Register(dst), as_Register(base), T9, 0);
        } else {
          __ addu(AT, as_Register(base), T9);
          __ lb(as_Register(dst), AT, 0);
        }
      }
    }
  %}

  //Load byte unsigned
  enc_class load_UB_enc (mRegI dst, memory mem) %{
    MacroAssembler _masm(&cbuf);
    int  dst = $dst$$reg;
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if (scale == 0) {
        __ daddu(AT, as_Register(base), as_Register(index));
      } else {
        __ dsll(AT, as_Register(index), scale);
        __ daddu(AT, as_Register(base), AT);
      }
      if( Assembler::is_simm16(disp) ) {
        __ lbu(as_Register(dst), AT, disp);
      } else {
        __ move(T9, disp);
        __ daddu(AT, AT, T9);
        __ lbu(as_Register(dst), AT, 0);
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ lbu(as_Register(dst), as_Register(base), disp);
      } else {
        __ move(T9, disp);
        __ daddu(AT, as_Register(base), T9);
        __ lbu(as_Register(dst), AT, 0);
      }
    }
  %}

  enc_class store_B_reg_enc (memory mem, mRegI src) %{
    MacroAssembler _masm(&cbuf);
    int  src = $src$$reg;
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if (scale == 0) {
        if( Assembler::is_simm(disp, 8) ) {
          if (UseLEXT1) {
            __ gssbx(as_Register(src), as_Register(base), as_Register(index), disp);
          } else {
            __ addu(AT, as_Register(base), as_Register(index));
            __ sb(as_Register(src), AT, disp);
          }
        } else if( Assembler::is_simm16(disp) ) {
          __ addu(AT, as_Register(base), as_Register(index));
          __ sb(as_Register(src), AT, disp);
        } else {
          __ addu(AT, as_Register(base), as_Register(index));
          __ move(T9, disp);
          if (UseLEXT1) {
            __ gssbx(as_Register(src), AT, T9, 0);
          } else {
            __ addu(AT, AT, T9);
            __ sb(as_Register(src), AT, 0);
          }
        }
      } else {
        __ dsll(AT, as_Register(index), scale);
        if( Assembler::is_simm(disp, 8) ) {
          if (UseLEXT1) {
            __ gssbx(as_Register(src), AT, as_Register(base), disp);
          } else {
            __ addu(AT, as_Register(base), AT);
            __ sb(as_Register(src), AT, disp);
          }
        } else if( Assembler::is_simm16(disp) ) {
          __ addu(AT, as_Register(base), AT);
          __ sb(as_Register(src), AT, disp);
        } else {
          __ addu(AT, as_Register(base), AT);
          __ move(T9, disp);
          if (UseLEXT1) {
            __ gssbx(as_Register(src), AT, T9, 0);
          } else {
            __ addu(AT, AT, T9);
            __ sb(as_Register(src), AT, 0);
          }
        }
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ sb(as_Register(src), as_Register(base), disp);
      } else {
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gssbx(as_Register(src), as_Register(base), T9, 0);
        } else {
          __ addu(AT, as_Register(base), T9);
          __ sb(as_Register(src), AT, 0);
        }
      }
    }
  %}

  enc_class store_B_immI_enc (memory mem, immI8 src) %{
    MacroAssembler _masm(&cbuf);
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;
    int value = $src$$constant;

    if( index != 0 ) {
      if (!UseLEXT1) {
        if (scale == 0) {
          __ daddu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ daddu(AT, as_Register(base), AT);
        }
        if( Assembler::is_simm16(disp) ) {
          if (value == 0) {
            __ sb(R0, AT, disp);
          } else {
            __ move(T9, value);
            __ sb(T9, AT, disp);
          }
        } else {
          if (value == 0) {
            __ move(T9, disp);
            __ daddu(AT, AT, T9);
            __ sb(R0, AT, 0);
          } else {
            __ move(T9, disp);
            __ daddu(AT, AT, T9);
            __ move(T9, value);
            __ sb(T9, AT, 0);
          }
        }
      } else {

        if (scale == 0) {
          if( Assembler::is_simm(disp, 8) ) {
            if (value == 0) {
              __ gssbx(R0, as_Register(base), as_Register(index), disp);
            } else {
              __ move(T9, value);
              __ gssbx(T9, as_Register(base), as_Register(index), disp);
            }
          } else if( Assembler::is_simm16(disp) ) {
            __ daddu(AT, as_Register(base), as_Register(index));
            if (value == 0) {
              __ sb(R0, AT, disp);
            } else {
              __ move(T9, value);
              __ sb(T9, AT, disp);
            }
          } else {
            if (value == 0) {
              __ daddu(AT, as_Register(base), as_Register(index));
              __ move(T9, disp);
              __ gssbx(R0, AT, T9, 0);
            } else {
              __ move(AT, disp);
              __ move(T9, value);
              __ daddu(AT, as_Register(base), AT);
              __ gssbx(T9, AT, as_Register(index), 0);
            }
          }

        } else {

          if( Assembler::is_simm(disp, 8) ) {
            __ dsll(AT, as_Register(index), scale);
            if (value == 0) {
              __ gssbx(R0, as_Register(base), AT, disp);
            } else {
              __ move(T9, value);
              __ gssbx(T9, as_Register(base), AT, disp);
            }
          } else if( Assembler::is_simm16(disp) ) {
            __ dsll(AT, as_Register(index), scale);
            __ daddu(AT, as_Register(base), AT);
            if (value == 0) {
              __ sb(R0, AT, disp);
            } else {
              __ move(T9, value);
              __ sb(T9, AT, disp);
            }
          } else {
            __ dsll(AT, as_Register(index), scale);
            if (value == 0) {
              __ daddu(AT, as_Register(base), AT);
              __ move(T9, disp);
              __ gssbx(R0, AT, T9, 0);
            } else {
              __ move(T9, disp);
              __ daddu(AT, AT, T9);
              __ move(T9, value);
              __ gssbx(T9, as_Register(base), AT, 0);
            }
          }
        }
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        if (value == 0) {
          __ sb(R0, as_Register(base), disp);
        } else {
          __ move(AT, value);
          __ sb(AT, as_Register(base), disp);
        }
      } else {
        if (value == 0) {
          __ move(T9, disp);
          if (UseLEXT1) {
            __ gssbx(R0, as_Register(base), T9, 0);
          } else {
            __ daddu(AT, as_Register(base), T9);
            __ sb(R0, AT, 0);
          }
        } else {
          __ move(T9, disp);
          if (UseLEXT1) {
            __ move(AT, value);
            __ gssbx(AT, as_Register(base), T9, 0);
          } else {
            __ daddu(AT, as_Register(base), T9);
            __ move(T9, value);
            __ sb(T9, AT, 0);
          }
        }
      }
    }
  %}


  enc_class store_B_immI_enc_sync (memory mem, immI8 src) %{
    MacroAssembler _masm(&cbuf);
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;
    int value = $src$$constant;

    if( index != 0 ) {
      if (UseLEXT1) {
        if ( Assembler::is_simm(disp,8) ) {
          if ( scale == 0 ) {
            if ( value == 0 ) {
              __ gssbx(R0, as_Register(base), as_Register(index), disp);
            } else {
              __ move(AT, value);
              __ gssbx(AT, as_Register(base), as_Register(index), disp);
            }
          } else {
            __ dsll(AT, as_Register(index), scale);
            if ( value == 0 ) {
              __ gssbx(R0, as_Register(base), AT, disp);
            } else {
              __ move(T9, value);
              __ gssbx(T9, as_Register(base), AT, disp);
            }
          }
        } else if ( Assembler::is_simm16(disp) ) {
          if ( scale == 0 ) {
            __ daddu(AT, as_Register(base), as_Register(index));
            if ( value == 0 ){
              __ sb(R0, AT, disp);
            } else {
              __ move(T9, value);
              __ sb(T9, AT, disp);
            }
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ daddu(AT, as_Register(base), AT);
            if ( value == 0 ) {
              __ sb(R0, AT, disp);
            } else {
              __ move(T9, value);
              __ sb(T9, AT, disp);
            }
          }
        } else {
          if ( scale == 0 ) {
            __ move(AT, disp);
            __ daddu(AT, as_Register(index), AT);
            if ( value == 0 ) {
              __ gssbx(R0, as_Register(base), AT, 0);
            } else {
              __ move(T9, value);
              __ gssbx(T9, as_Register(base), AT, 0);
            }
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ move(T9, disp);
            __ daddu(AT, AT, T9);
            if ( value == 0 ) {
              __ gssbx(R0, as_Register(base), AT, 0);
            } else {
              __ move(T9, value);
              __ gssbx(T9, as_Register(base), AT, 0);
            }
          }
        }
      } else { //not use loongson isa
        if (scale == 0) {
          __ daddu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ daddu(AT, as_Register(base), AT);
        }
        if( Assembler::is_simm16(disp) ) {
          if (value == 0) {
            __ sb(R0, AT, disp);
          } else {
            __ move(T9, value);
            __ sb(T9, AT, disp);
          }
        } else {
          if (value == 0) {
            __ move(T9, disp);
            __ daddu(AT, AT, T9);
            __ sb(R0, AT, 0);
          } else {
            __ move(T9, disp);
            __ daddu(AT, AT, T9);
            __ move(T9, value);
            __ sb(T9, AT, 0);
          }
        }
      }
    } else {
      if (UseLEXT1){
        if ( Assembler::is_simm16(disp) ){
          if ( value == 0 ) {
            __ sb(R0, as_Register(base), disp);
          } else {
            __ move(AT, value);
            __ sb(AT, as_Register(base), disp);
          }
        } else {
          __ move(AT, disp);
          if ( value == 0 ) {
            __ gssbx(R0, as_Register(base), AT, 0);
          } else {
            __ move(T9, value);
            __ gssbx(T9, as_Register(base), AT, 0);
          }
        }
      } else {
        if( Assembler::is_simm16(disp) ) {
          if (value == 0) {
            __ sb(R0, as_Register(base), disp);
          } else {
            __ move(AT, value);
            __ sb(AT, as_Register(base), disp);
          }
        } else {
          if (value == 0) {
            __ move(T9, disp);
            __ daddu(AT, as_Register(base), T9);
            __ sb(R0, AT, 0);
          } else {
            __ move(T9, disp);
            __ daddu(AT, as_Register(base), T9);
            __ move(T9, value);
            __ sb(T9, AT, 0);
          }
        }
      }
    }

    __ sync();
  %}

  // Load Short (16bit signed)
  enc_class load_S_enc (mRegI dst, memory mem) %{
    MacroAssembler _masm(&cbuf);
    int  dst = $dst$$reg;
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if (UseLEXT1) {
        if ( Assembler::is_simm(disp, 8) ) {
          if (scale == 0) {
            __ gslhx(as_Register(dst), as_Register(base), as_Register(index), disp);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ gslhx(as_Register(dst), as_Register(base), AT, disp);
          }
        } else if ( Assembler::is_simm16(disp) ) {
          if (scale == 0) {
            __ daddu(AT, as_Register(base), as_Register(index));
            __ lh(as_Register(dst), AT, disp);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ daddu(AT, as_Register(base), AT);
            __ lh(as_Register(dst), AT, disp);
          }
        } else {
          if (scale == 0) {
            __ move(AT, disp);
            __ daddu(AT, as_Register(index), AT);
            __ gslhx(as_Register(dst), as_Register(base), AT, 0);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ move(T9, disp);
            __ daddu(AT, AT, T9);
            __ gslhx(as_Register(dst), as_Register(base), AT, 0);
          }
        }
      } else { // not use loongson isa
        if (scale == 0) {
          __ daddu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ daddu(AT, as_Register(base), AT);
        }
        if( Assembler::is_simm16(disp) ) {
          __ lh(as_Register(dst), AT, disp);
        } else {
          __ move(T9, disp);
          __ daddu(AT, AT, T9);
          __ lh(as_Register(dst), AT, 0);
        }
      }
    } else { // index is 0
      if (UseLEXT1) {
        if ( Assembler::is_simm16(disp) ) {
          __ lh(as_Register(dst), as_Register(base), disp);
        } else {
          __ move(T9, disp);
          __ gslhx(as_Register(dst), as_Register(base), T9, 0);
        }
      } else { //not use loongson isa
        if( Assembler::is_simm16(disp) ) {
          __ lh(as_Register(dst), as_Register(base), disp);
        } else {
          __ move(T9, disp);
          __ daddu(AT, as_Register(base), T9);
          __ lh(as_Register(dst), AT, 0);
        }
      }
    }
  %}

  // Load Char (16bit unsigned)
  enc_class load_C_enc (mRegI dst, memory mem) %{
    MacroAssembler _masm(&cbuf);
    int  dst = $dst$$reg;
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if (scale == 0) {
        __ daddu(AT, as_Register(base), as_Register(index));
      } else {
        __ dsll(AT, as_Register(index), scale);
        __ daddu(AT, as_Register(base), AT);
      }
      if( Assembler::is_simm16(disp) ) {
        __ lhu(as_Register(dst), AT, disp);
      } else {
        __ move(T9, disp);
        __ addu(AT, AT, T9);
        __ lhu(as_Register(dst), AT, 0);
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ lhu(as_Register(dst), as_Register(base), disp);
      } else {
        __ move(T9, disp);
        __ daddu(AT, as_Register(base), T9);
        __ lhu(as_Register(dst), AT, 0);
      }
    }
  %}

  // Store Char (16bit unsigned)
  enc_class store_C_reg_enc (memory mem, mRegI src) %{
    MacroAssembler _masm(&cbuf);
    int  src = $src$$reg;
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if( Assembler::is_simm16(disp) ) {
        if ( UseLEXT1 && Assembler::is_simm(disp, 8) ) {
          if (scale == 0) {
            __ gsshx(as_Register(src), as_Register(base), as_Register(index), disp);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ gsshx(as_Register(src), as_Register(base), AT, disp);
          }
        } else {
          if (scale == 0) {
            __ addu(AT, as_Register(base), as_Register(index));
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ addu(AT, as_Register(base), AT);
          }
          __ sh(as_Register(src), AT, disp);
        }
      } else {
        if (scale == 0) {
          __ addu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ addu(AT, as_Register(base), AT);
        }
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gsshx(as_Register(src), AT, T9, 0);
        } else {
          __ addu(AT, AT, T9);
          __ sh(as_Register(src), AT, 0);
        }
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ sh(as_Register(src), as_Register(base), disp);
      } else {
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gsshx(as_Register(src), as_Register(base), T9, 0);
        } else {
          __ addu(AT, as_Register(base), T9);
          __ sh(as_Register(src), AT, 0);
        }
      }
    }
  %}

  enc_class store_C0_enc (memory mem) %{
    MacroAssembler _masm(&cbuf);
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if ( Assembler::is_simm16(disp) ) {
        if ( UseLEXT1 && Assembler::is_simm(disp, 8) ) {
          if (scale == 0) {
            __ gsshx(R0, as_Register(base), as_Register(index), disp);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ gsshx(R0, as_Register(base), AT, disp);
          }
        } else {
          if (scale == 0) {
            __ addu(AT, as_Register(base), as_Register(index));
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ addu(AT, as_Register(base), AT);
          }
          __ sh(R0, AT, disp);
        }
      } else {
        if (scale == 0) {
          __ addu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ addu(AT, as_Register(base), AT);
        }
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gsshx(R0, AT, T9, 0);
        } else {
          __ addu(AT, AT, T9);
          __ sh(R0, AT, 0);
        }
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ sh(R0, as_Register(base), disp);
      } else {
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gsshx(R0, as_Register(base), T9, 0);
        } else {
          __ addu(AT, as_Register(base), T9);
          __ sh(R0, AT, 0);
        }
      }
    }
  %}

  enc_class load_I_enc (mRegI dst, memory mem) %{
    MacroAssembler _masm(&cbuf);
    int  dst = $dst$$reg;
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if( Assembler::is_simm16(disp) ) {
        if ( UseLEXT1 && Assembler::is_simm(disp, 8) ) {
          if (scale == 0) {
            __ gslwx(as_Register(dst), as_Register(base), as_Register(index), disp);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ gslwx(as_Register(dst), as_Register(base), AT, disp);
          }
        } else {
          if (scale == 0) {
            __ addu(AT, as_Register(base), as_Register(index));
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ addu(AT, as_Register(base), AT);
          }
          __ lw(as_Register(dst), AT, disp);
        }
      } else {
        if (scale == 0) {
          __ addu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ addu(AT, as_Register(base), AT);
        }
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gslwx(as_Register(dst), AT, T9, 0);
        } else {
          __ addu(AT, AT, T9);
          __ lw(as_Register(dst), AT, 0);
        }
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ lw(as_Register(dst), as_Register(base), disp);
      } else {
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gslwx(as_Register(dst), as_Register(base), T9, 0);
        } else {
          __ addu(AT, as_Register(base), T9);
          __ lw(as_Register(dst), AT, 0);
        }
      }
    }
  %}

  enc_class store_I_reg_enc (memory mem, mRegI src) %{
    MacroAssembler _masm(&cbuf);
    int  src = $src$$reg;
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if( Assembler::is_simm16(disp) ) {
        if ( UseLEXT1 && Assembler::is_simm(disp, 8) ) {
          if (scale == 0) {
            __ gsswx(as_Register(src), as_Register(base), as_Register(index), disp);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ gsswx(as_Register(src), as_Register(base), AT, disp);
          }
        } else {
          if (scale == 0) {
            __ addu(AT, as_Register(base), as_Register(index));
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ addu(AT, as_Register(base), AT);
          }
          __ sw(as_Register(src), AT, disp);
        }
      } else {
        if (scale == 0) {
          __ addu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ addu(AT, as_Register(base), AT);
        }
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gsswx(as_Register(src), AT, T9, 0);
        } else {
          __ addu(AT, AT, T9);
          __ sw(as_Register(src), AT, 0);
        }
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ sw(as_Register(src), as_Register(base), disp);
      } else {
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gsswx(as_Register(src), as_Register(base), T9, 0);
        } else {
          __ addu(AT, as_Register(base), T9);
          __ sw(as_Register(src), AT, 0);
        }
      }
    }
  %}

  enc_class store_I_immI_enc (memory mem, immI src) %{
    MacroAssembler _masm(&cbuf);
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;
    int value = $src$$constant;

    if( index != 0 ) {
      if (UseLEXT1) {
        if ( Assembler::is_simm(disp, 8) ) {
          if ( scale == 0 ) {
            if ( value == 0 ) {
              __ gsswx(R0, as_Register(base), as_Register(index), disp);
            } else {
              __ move(T9, value);
              __ gsswx(T9, as_Register(base), as_Register(index), disp);
            }
          } else {
            __ dsll(AT, as_Register(index), scale);
            if ( value == 0 ) {
              __ gsswx(R0, as_Register(base), AT, disp);
            } else {
              __ move(T9, value);
              __ gsswx(T9, as_Register(base), AT, disp);
            }
          }
        } else if ( Assembler::is_simm16(disp) ) {
          if ( scale == 0 ) {
            __ daddu(AT, as_Register(base), as_Register(index));
            if ( value == 0 ) {
              __ sw(R0, AT, disp);
            } else {
              __ move(T9, value);
              __ sw(T9, AT, disp);
            }
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ daddu(AT, as_Register(base), AT);
            if ( value == 0 ) {
              __ sw(R0, AT, disp);
            } else {
              __ move(T9, value);
              __ sw(T9, AT, disp);
            }
          }
        } else {
          if ( scale == 0 ) {
            __ move(T9, disp);
            __ daddu(AT, as_Register(index), T9);
            if ( value ==0 ) {
              __ gsswx(R0, as_Register(base), AT, 0);
            } else {
              __ move(T9, value);
              __ gsswx(T9, as_Register(base), AT, 0);
            }
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ move(T9, disp);
            __ daddu(AT, AT, T9);
            if ( value == 0 ) {
              __ gsswx(R0, as_Register(base), AT, 0);
            } else {
              __ move(T9, value);
              __ gsswx(T9, as_Register(base), AT, 0);
            }
          }
        }
      } else { //not use loongson isa
        if (scale == 0) {
          __ daddu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ daddu(AT, as_Register(base), AT);
        }
        if( Assembler::is_simm16(disp) ) {
          if (value == 0) {
            __ sw(R0, AT, disp);
          } else {
            __ move(T9, value);
            __ sw(T9, AT, disp);
          }
        } else {
          if (value == 0) {
            __ move(T9, disp);
            __ daddu(AT, AT, T9);
            __ sw(R0, AT, 0);
          } else {
            __ move(T9, disp);
            __ daddu(AT, AT, T9);
            __ move(T9, value);
            __ sw(T9, AT, 0);
          }
        }
      }
    } else {
      if (UseLEXT1) {
        if ( Assembler::is_simm16(disp) ) {
          if ( value == 0 ) {
            __ sw(R0, as_Register(base), disp);
          } else {
            __ move(AT, value);
            __ sw(AT, as_Register(base), disp);
          }
        } else {
          __ move(T9, disp);
          if ( value == 0 ) {
            __ gsswx(R0, as_Register(base), T9, 0);
          } else {
            __ move(AT, value);
            __ gsswx(AT, as_Register(base), T9, 0);
          }
        }
      } else {
        if( Assembler::is_simm16(disp) ) {
          if (value == 0) {
            __ sw(R0, as_Register(base), disp);
          } else {
            __ move(AT, value);
            __ sw(AT, as_Register(base), disp);
          }
        } else {
          if (value == 0) {
            __ move(T9, disp);
            __ daddu(AT, as_Register(base), T9);
            __ sw(R0, AT, 0);
          } else {
            __ move(T9, disp);
            __ daddu(AT, as_Register(base), T9);
            __ move(T9, value);
            __ sw(T9, AT, 0);
          }
        }
      }
    }
  %}

  enc_class load_N_enc (mRegN dst, memory mem) %{
    MacroAssembler _masm(&cbuf);
    int  dst = $dst$$reg;
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;
    relocInfo::relocType disp_reloc = $mem->disp_reloc();
    assert(disp_reloc == relocInfo::none, "cannot have disp");

    if( index != 0 ) {
      if (scale == 0) {
        __ daddu(AT, as_Register(base), as_Register(index));
      } else {
        __ dsll(AT, as_Register(index), scale);
        __ daddu(AT, as_Register(base), AT);
      }
      if( Assembler::is_simm16(disp) ) {
        __ lwu(as_Register(dst), AT, disp);
      } else {
        __ set64(T9, disp);
        __ daddu(AT, AT, T9);
        __ lwu(as_Register(dst), AT, 0);
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ lwu(as_Register(dst), as_Register(base), disp);
      } else {
        __ set64(T9, disp);
        __ daddu(AT, as_Register(base), T9);
        __ lwu(as_Register(dst), AT, 0);
      }
    }
  %}


  enc_class load_P_enc (mRegP dst, memory mem) %{
    MacroAssembler _masm(&cbuf);
    int  dst = $dst$$reg;
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;
    relocInfo::relocType disp_reloc = $mem->disp_reloc();
    assert(disp_reloc == relocInfo::none, "cannot have disp");

    if( index != 0 ) {
      if (UseLEXT1) {
        if ( Assembler::is_simm(disp, 8) ) {
          if ( scale != 0 ) {
            __ dsll(AT, as_Register(index), scale);
            __ gsldx(as_Register(dst), as_Register(base), AT, disp);
          } else {
            __ gsldx(as_Register(dst), as_Register(base), as_Register(index), disp);
          }
        } else if ( Assembler::is_simm16(disp) ){
          if ( scale != 0 ) {
            __ dsll(AT, as_Register(index), scale);
            __ daddu(AT, AT, as_Register(base));
          } else {
            __ daddu(AT, as_Register(index), as_Register(base));
          }
          __ ld(as_Register(dst), AT, disp);
        } else {
          if ( scale != 0 ) {
            __ dsll(AT, as_Register(index), scale);
            __ move(T9, disp);
            __ daddu(AT, AT, T9);
          } else {
            __ move(T9, disp);
            __ daddu(AT, as_Register(index), T9);
          }
          __ gsldx(as_Register(dst), as_Register(base), AT, 0);
        }
      } else { //not use loongson isa
        if (scale == 0) {
          __ daddu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ daddu(AT, as_Register(base), AT);
        }
        if( Assembler::is_simm16(disp) ) {
          __ ld(as_Register(dst), AT, disp);
        } else {
          __ set64(T9, disp);
          __ daddu(AT, AT, T9);
          __ ld(as_Register(dst), AT, 0);
        }
      }
    } else {
      if (UseLEXT1) {
        if ( Assembler::is_simm16(disp) ){
          __ ld(as_Register(dst), as_Register(base), disp);
        } else {
          __ set64(T9, disp);
          __ gsldx(as_Register(dst), as_Register(base), T9, 0);
        }
      } else { //not use loongson isa
        if( Assembler::is_simm16(disp) ) {
          __ ld(as_Register(dst), as_Register(base), disp);
        } else {
          __ set64(T9, disp);
          __ daddu(AT, as_Register(base), T9);
          __ ld(as_Register(dst), AT, 0);
        }
      }
    }
  %}

  // Load acquire.
  // load_P_enc + sync
  enc_class load_P_enc_ac (mRegP dst, memory mem) %{
    MacroAssembler _masm(&cbuf);
    int  dst = $dst$$reg;
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;
    relocInfo::relocType disp_reloc = $mem->disp_reloc();
    assert(disp_reloc == relocInfo::none, "cannot have disp");

    if( index != 0 ) {
      if (UseLEXT1) {
        if ( Assembler::is_simm(disp, 8) ) {
          if ( scale != 0 ) {
            __ dsll(AT, as_Register(index), scale);
            __ gsldx(as_Register(dst), as_Register(base), AT, disp);
          } else {
            __ gsldx(as_Register(dst), as_Register(base), as_Register(index), disp);
          }
        } else if ( Assembler::is_simm16(disp) ){
          if ( scale != 0 ) {
            __ dsll(AT, as_Register(index), scale);
            __ daddu(AT, AT, as_Register(base));
          } else {
            __ daddu(AT, as_Register(index), as_Register(base));
          }
          __ ld(as_Register(dst), AT, disp);
        } else {
          if ( scale != 0 ) {
            __ dsll(AT, as_Register(index), scale);
            __ move(T9, disp);
            __ daddu(AT, AT, T9);
          } else {
            __ move(T9, disp);
            __ daddu(AT, as_Register(index), T9);
          }
          __ gsldx(as_Register(dst), as_Register(base), AT, 0);
        }
      } else { //not use loongson isa
        if (scale == 0) {
          __ daddu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ daddu(AT, as_Register(base), AT);
        }
        if( Assembler::is_simm16(disp) ) {
          __ ld(as_Register(dst), AT, disp);
        } else {
          __ set64(T9, disp);
          __ daddu(AT, AT, T9);
          __ ld(as_Register(dst), AT, 0);
        }
      }
    } else {
      if (UseLEXT1) {
        if ( Assembler::is_simm16(disp) ){
          __ ld(as_Register(dst), as_Register(base), disp);
        } else {
          __ set64(T9, disp);
          __ gsldx(as_Register(dst), as_Register(base), T9, 0);
        }
      } else { //not use loongson isa
        if( Assembler::is_simm16(disp) ) {
          __ ld(as_Register(dst), as_Register(base), disp);
        } else {
          __ set64(T9, disp);
          __ daddu(AT, as_Register(base), T9);
          __ ld(as_Register(dst), AT, 0);
        }
      }
    }
    __ sync();
  %}

  enc_class store_P_reg_enc (memory mem, mRegP src) %{
    MacroAssembler _masm(&cbuf);
    int  src = $src$$reg;
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if (UseLEXT1){
        if ( Assembler::is_simm(disp, 8) ) {
          if ( scale == 0 ) {
            __ gssdx(as_Register(src), as_Register(base), as_Register(index), disp);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ gssdx(as_Register(src), as_Register(base), AT, disp);
          }
        } else if ( Assembler::is_simm16(disp) ) {
          if ( scale == 0 ) {
            __ daddu(AT, as_Register(base), as_Register(index));
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ daddu(AT, as_Register(base), AT);
          }
          __ sd(as_Register(src), AT, disp);
        } else {
          if ( scale == 0 ) {
            __ move(T9, disp);
            __ daddu(AT, as_Register(index), T9);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ move(T9, disp);
            __ daddu(AT, AT, T9);
          }
          __ gssdx(as_Register(src), as_Register(base), AT, 0);
        }
      } else { //not use loongson isa
        if (scale == 0) {
          __ daddu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ daddu(AT, as_Register(base), AT);
        }
        if( Assembler::is_simm16(disp) ) {
          __ sd(as_Register(src), AT, disp);
        } else {
          __ move(T9, disp);
          __ daddu(AT, AT, T9);
          __ sd(as_Register(src), AT, 0);
        }
      }
    } else {
      if (UseLEXT1) {
        if ( Assembler::is_simm16(disp) ) {
          __ sd(as_Register(src), as_Register(base), disp);
        } else {
          __ move(T9, disp);
          __ gssdx(as_Register(src), as_Register(base), T9, 0);
        }
      } else {
        if( Assembler::is_simm16(disp) ) {
          __ sd(as_Register(src), as_Register(base), disp);
        } else {
          __ move(T9, disp);
          __ daddu(AT, as_Register(base), T9);
          __ sd(as_Register(src), AT, 0);
        }
      }
    }
  %}

  enc_class store_N_reg_enc (memory mem, mRegN src) %{
    MacroAssembler _masm(&cbuf);
    int  src = $src$$reg;
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if (UseLEXT1){
        if ( Assembler::is_simm(disp, 8) ) {
          if ( scale == 0 ) {
            __ gsswx(as_Register(src), as_Register(base), as_Register(index), disp);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ gsswx(as_Register(src), as_Register(base), AT, disp);
          }
        } else if ( Assembler::is_simm16(disp) ) {
          if ( scale == 0 ) {
            __ daddu(AT, as_Register(base), as_Register(index));
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ daddu(AT, as_Register(base), AT);
          }
          __ sw(as_Register(src), AT, disp);
        } else {
          if ( scale == 0 ) {
            __ move(T9, disp);
            __ daddu(AT, as_Register(index), T9);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ move(T9, disp);
            __ daddu(AT, AT, T9);
          }
          __ gsswx(as_Register(src), as_Register(base), AT, 0);
        }
      } else { //not use loongson isa
        if (scale == 0) {
          __ daddu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ daddu(AT, as_Register(base), AT);
        }
        if( Assembler::is_simm16(disp) ) {
          __ sw(as_Register(src), AT, disp);
        } else {
          __ move(T9, disp);
          __ daddu(AT, AT, T9);
          __ sw(as_Register(src), AT, 0);
        }
      }
    } else {
      if (UseLEXT1) {
        if ( Assembler::is_simm16(disp) ) {
          __ sw(as_Register(src), as_Register(base), disp);
        } else {
          __ move(T9, disp);
          __ gsswx(as_Register(src), as_Register(base), T9, 0);
        }
      } else {
        if( Assembler::is_simm16(disp) ) {
          __ sw(as_Register(src), as_Register(base), disp);
        } else {
          __ move(T9, disp);
          __ daddu(AT, as_Register(base), T9);
          __ sw(as_Register(src), AT, 0);
        }
      }
    }
  %}

  enc_class store_P_immP0_enc (memory mem) %{
    MacroAssembler _masm(&cbuf);
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if (scale == 0) {
        if ( Assembler::is_simm16(disp) ) {
          if (UseLEXT1 && Assembler::is_simm(disp, 8)) {
            __ gssdx(R0, as_Register(base), as_Register(index), disp);
          } else {
            __ daddu(AT, as_Register(base), as_Register(index));
            __ sd(R0, AT, disp);
          }
        } else {
          __ daddu(AT, as_Register(base), as_Register(index));
          __ move(T9, disp);
          if (UseLEXT1) {
            __ gssdx(R0, AT, T9, 0);
          } else {
            __ daddu(AT, AT, T9);
            __ sd(R0, AT, 0);
          }
        }
      } else {
        __ dsll(AT, as_Register(index), scale);
        if( Assembler::is_simm16(disp) ) {
          if (UseLEXT1 && Assembler::is_simm(disp, 8)) {
            __ gssdx(R0, as_Register(base), AT, disp);
          } else {
            __ daddu(AT, as_Register(base), AT);
            __ sd(R0, AT, disp);
          }
        } else {
          __ daddu(AT, as_Register(base), AT);
          __ move(T9, disp);
          if (UseLEXT1) {
            __ gssdx(R0, AT, T9, 0);
          } else {
            __ daddu(AT, AT, T9);
            __ sd(R0, AT, 0);
          }
        }
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ sd(R0, as_Register(base), disp);
      } else {
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gssdx(R0, as_Register(base), T9, 0);
        } else {
          __ daddu(AT, as_Register(base), T9);
          __ sd(R0, AT, 0);
        }
      }
    }
  %}

  enc_class storeImmN0_enc(memory mem, ImmN0 src) %{
    MacroAssembler _masm(&cbuf);
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if(index!=0){
      if (scale == 0) {
        __ daddu(AT, as_Register(base), as_Register(index));
      } else {
        __ dsll(AT, as_Register(index), scale);
        __ daddu(AT, as_Register(base), AT);
      }

      if( Assembler::is_simm16(disp) ) {
        __ sw(R0, AT, disp);
      } else {
        __ move(T9, disp);
        __ daddu(AT, AT, T9);
        __ sw(R0, AT, 0);
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ sw(R0, as_Register(base), disp);
      } else {
        __ move(T9, disp);
        __ daddu(AT, as_Register(base), T9);
        __ sw(R0, AT, 0);
      }
    }
  %}

  enc_class load_L_enc (mRegL dst, memory mem) %{
    MacroAssembler _masm(&cbuf);
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;
    Register  dst_reg = as_Register($dst$$reg);

    if( index != 0 ) {
      if (scale == 0) {
        __ daddu(AT, as_Register(base), as_Register(index));
      } else {
        __ dsll(AT, as_Register(index), scale);
        __ daddu(AT, as_Register(base), AT);
      }
      if( Assembler::is_simm16(disp) ) {
        __ ld(dst_reg, AT, disp);
      } else {
        __ move(T9, disp);
        __ daddu(AT, AT, T9);
        __ ld(dst_reg, AT, 0);
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ ld(dst_reg, as_Register(base), disp);
      } else {
        __ move(T9, disp);
        __ daddu(AT, as_Register(base), T9);
        __ ld(dst_reg, AT, 0);
      }
    }
  %}

  enc_class store_L_reg_enc (memory mem, mRegL src) %{
    MacroAssembler _masm(&cbuf);
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;
    Register  src_reg = as_Register($src$$reg);

    if( index != 0 ) {
      if (scale == 0) {
        __ daddu(AT, as_Register(base), as_Register(index));
      } else {
        __ dsll(AT, as_Register(index), scale);
        __ daddu(AT, as_Register(base), AT);
      }
      if( Assembler::is_simm16(disp) ) {
        __ sd(src_reg, AT, disp);
      } else {
        __ move(T9, disp);
        __ daddu(AT, AT, T9);
        __ sd(src_reg, AT, 0);
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ sd(src_reg, as_Register(base), disp);
      } else {
        __ move(T9, disp);
        __ daddu(AT, as_Register(base), T9);
        __ sd(src_reg, AT, 0);
      }
    }
  %}

  enc_class store_L_immL_0_enc (memory mem, immL_0 src) %{
    MacroAssembler _masm(&cbuf);
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if (scale == 0) {
        __ daddu(AT, as_Register(base), as_Register(index));
      } else {
        __ dsll(AT, as_Register(index), scale);
        __ daddu(AT, as_Register(base), AT);
      }
      if( Assembler::is_simm16(disp) ) {
        __ sd(R0, AT, disp);
      } else {
        __ move(T9, disp);
        __ addu(AT, AT, T9);
        __ sd(R0, AT, 0);
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ sd(R0, as_Register(base), disp);
      } else {
        __ move(T9, disp);
        __ addu(AT, as_Register(base), T9);
        __ sd(R0, AT, 0);
      }
    }
  %}

  enc_class store_L_immL_enc (memory mem, immL src) %{
    MacroAssembler _masm(&cbuf);
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;
    long  imm = $src$$constant;

    if( index != 0 ) {
      if (scale == 0) {
        __ daddu(AT, as_Register(base), as_Register(index));
      } else {
        __ dsll(AT, as_Register(index), scale);
        __ daddu(AT, as_Register(base), AT);
      }
      if( Assembler::is_simm16(disp) ) {
        __ set64(T9, imm);
        __ sd(T9, AT, disp);
      } else {
        __ move(T9, disp);
        __ addu(AT, AT, T9);
        __ set64(T9, imm);
        __ sd(T9, AT, 0);
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ move(AT, as_Register(base));
        __ set64(T9, imm);
        __ sd(T9, AT, disp);
      } else {
        __ move(T9, disp);
        __ addu(AT, as_Register(base), T9);
        __ set64(T9, imm);
        __ sd(T9, AT, 0);
      }
    }
  %}

  enc_class load_F_enc (regF dst, memory mem) %{
    MacroAssembler _masm(&cbuf);
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;
    FloatRegister dst = $dst$$FloatRegister;

    if( index != 0 ) {
      if( Assembler::is_simm16(disp) ) {
        if ( UseLEXT1 && Assembler::is_simm(disp, 8) ) {
          if (scale == 0) {
            __ gslwxc1(dst, as_Register(base), as_Register(index), disp);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ gslwxc1(dst, as_Register(base), AT, disp);
          }
        } else {
          if (scale == 0) {
            __ daddu(AT, as_Register(base), as_Register(index));
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ daddu(AT, as_Register(base), AT);
          }
          __ lwc1(dst, AT, disp);
        }
      } else {
        if (scale == 0) {
          __ daddu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ daddu(AT, as_Register(base), AT);
        }
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gslwxc1(dst, AT, T9, 0);
        } else {
          __ daddu(AT, AT, T9);
          __ lwc1(dst, AT, 0);
        }
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ lwc1(dst, as_Register(base), disp);
      } else {
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gslwxc1(dst, as_Register(base), T9, 0);
        } else {
          __ daddu(AT, as_Register(base), T9);
          __ lwc1(dst, AT, 0);
        }
      }
    }
  %}

  enc_class store_F_reg_enc (memory mem, regF src) %{
    MacroAssembler _masm(&cbuf);
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;
    FloatRegister src = $src$$FloatRegister;

    if( index != 0 ) {
      if ( Assembler::is_simm16(disp) ) {
        if ( UseLEXT1 && Assembler::is_simm(disp, 8) ) {
          if (scale == 0) {
            __ gsswxc1(src, as_Register(base), as_Register(index), disp);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ gsswxc1(src, as_Register(base), AT, disp);
          }
        } else {
          if (scale == 0) {
            __ daddu(AT, as_Register(base), as_Register(index));
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ daddu(AT, as_Register(base), AT);
          }
          __ swc1(src, AT, disp);
        }
      } else {
        if (scale == 0) {
          __ daddu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ daddu(AT, as_Register(base), AT);
        }
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gsswxc1(src, AT, T9, 0);
        } else {
          __ daddu(AT, AT, T9);
          __ swc1(src, AT, 0);
        }
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ swc1(src, as_Register(base), disp);
      } else {
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gsswxc1(src, as_Register(base), T9, 0);
        } else {
          __ daddu(AT, as_Register(base), T9);
          __ swc1(src, AT, 0);
        }
      }
    }
  %}

  enc_class load_D_enc (regD dst, memory mem) %{
    MacroAssembler _masm(&cbuf);
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;
    FloatRegister dst_reg = as_FloatRegister($dst$$reg);

    if ( index != 0 ) {
      if ( Assembler::is_simm16(disp) ) {
        if ( UseLEXT1 && Assembler::is_simm(disp, 8) ) {
          if (scale == 0) {
            __ gsldxc1(dst_reg, as_Register(base), as_Register(index), disp);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ gsldxc1(dst_reg, as_Register(base), AT, disp);
          }
        } else {
          if (scale == 0) {
            __ daddu(AT, as_Register(base), as_Register(index));
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ daddu(AT, as_Register(base), AT);
          }
          __ ldc1(dst_reg, AT, disp);
        }
      } else {
        if (scale == 0) {
          __ daddu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ daddu(AT, as_Register(base), AT);
        }
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gsldxc1(dst_reg, AT, T9, 0);
        } else {
          __ addu(AT, AT, T9);
          __ ldc1(dst_reg, AT, 0);
        }
      }
    } else {
      if( Assembler::is_simm16(disp) ) {
        __ ldc1(dst_reg, as_Register(base), disp);
      } else {
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gsldxc1(dst_reg, as_Register(base), T9, 0);
        } else {
          __ addu(AT, as_Register(base), T9);
          __ ldc1(dst_reg, AT, 0);
        }
      }
    }
  %}

  enc_class store_D_reg_enc (memory mem, regD src) %{
    MacroAssembler _masm(&cbuf);
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;
    FloatRegister src_reg = as_FloatRegister($src$$reg);

    if ( index != 0 ) {
      if ( Assembler::is_simm16(disp) ) {
        if ( UseLEXT1 && Assembler::is_simm(disp, 8) ) {
          if (scale == 0) {
            __ gssdxc1(src_reg, as_Register(base), as_Register(index), disp);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ gssdxc1(src_reg, as_Register(base), AT, disp);
          }
        } else {
          if (scale == 0) {
            __ daddu(AT, as_Register(base), as_Register(index));
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ daddu(AT, as_Register(base), AT);
          }
          __ sdc1(src_reg, AT, disp);
        }
      } else {
        if (scale == 0) {
          __ daddu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ daddu(AT, as_Register(base), AT);
        }
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gssdxc1(src_reg, AT, T9, 0);
        } else {
          __ addu(AT, AT, T9);
          __ sdc1(src_reg, AT, 0);
        }
      }
    } else {
      if ( Assembler::is_simm16(disp) ) {
        __ sdc1(src_reg, as_Register(base), disp);
      } else {
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gssdxc1(src_reg, as_Register(base), T9, 0);
        } else {
          __ addu(AT, as_Register(base), T9);
          __ sdc1(src_reg, AT, 0);
        }
      }
    }
  %}

  enc_class Java_To_Runtime (method meth) %{    // CALL Java_To_Runtime, Java_To_Runtime_Leaf
    MacroAssembler _masm(&cbuf);
    // This is the instruction starting address for relocation info.
    __ block_comment("Java_To_Runtime");
    cbuf.set_insts_mark();
    __ relocate(relocInfo::runtime_call_type);
    __ patchable_call((address)$meth$$method);
  %}

  enc_class Java_Static_Call (method meth) %{    // JAVA STATIC CALL
    // CALL to fixup routine.  Fixup routine uses ScopeDesc info to determine
    // who we intended to call.
    MacroAssembler _masm(&cbuf);
    address addr = (address)$meth$$method;
    address call;
    __ block_comment("Java_Static_Call");

    if ( !_method ) {
      // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
      call = __ trampoline_call(AddressLiteral(addr, relocInfo::runtime_call_type), &cbuf);
    } else if(_optimized_virtual) {
      call = __ trampoline_call(AddressLiteral(addr, relocInfo::opt_virtual_call_type), &cbuf);
    } else {
      call = __ trampoline_call(AddressLiteral(addr, relocInfo::static_call_type), &cbuf);
    }

    if (call == NULL) {
      ciEnv::current()->record_failure("CodeCache is full");
      return;
    }

    if( _method ) {  // Emit stub for static call
      address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
      if (stub == NULL) {
        ciEnv::current()->record_failure("CodeCache is full");
        return;
      }
    }
  %}


  //
  // [Ref: LIR_Assembler::ic_call() ]
  //
  enc_class Java_Dynamic_Call (method meth) %{    // JAVA DYNAMIC CALL
    MacroAssembler _masm(&cbuf);
    __ block_comment("Java_Dynamic_Call");
    __ ic_call((address)$meth$$method);
  %}


  enc_class Set_Flags_After_Fast_Lock_Unlock(FlagsReg cr) %{
    Register flags = $cr$$Register;
    Label  L;

    MacroAssembler _masm(&cbuf);

    __ addu(flags, R0, R0);
    __ beq(AT, R0, L);
    __ delayed()->nop();
    __ move(flags, 0xFFFFFFFF);
    __ bind(L);
  %}

  enc_class enc_PartialSubtypeCheck(mRegP result, mRegP sub, mRegP super, mRegI tmp) %{
    Register result = $result$$Register;
    Register sub    = $sub$$Register;
    Register super  = $super$$Register;
    Register length = $tmp$$Register;
    Register tmp    = T9;
    Label miss;

    // result may be the same as sub
    //    47c   B40: #    B21 B41 <- B20  Freq: 0.155379
    //    47c     partialSubtypeCheck result=S1, sub=S1, super=S3, length=S0
    //    4bc     mov   S2, NULL #@loadConP
    //    4c0     beq   S1, S2, B21 #@branchConP  P=0.999999 C=-1.000000
    //
    MacroAssembler _masm(&cbuf);
    Label done;
    __ check_klass_subtype_slow_path(sub, super, length, tmp,
        NULL, &miss,
        /*set_cond_codes:*/ true);
    // Refer to X86_64's RDI
    __ move(result, 0);
    __ b(done);
    __ delayed()->nop();

    __ bind(miss);
    __ move(result, 1);
    __ bind(done);
  %}

%}


//---------MIPS FRAME--------------------------------------------------------------
// Definition of frame structure and management information.
//
//  S T A C K   L A Y O U T    Allocators stack-slot number
//                             |   (to get allocators register number
//  G  Owned by    |        |  v    add SharedInfo::stack0)
//  r   CALLER     |        |
//  o     |        +--------+      pad to even-align allocators stack-slot
//  w     V        |  pad0  |        numbers; owned by CALLER
//  t   -----------+--------+----> Matcher::_in_arg_limit, unaligned
//  h     ^        |   in   |  5
//        |        |  args  |  4   Holes in incoming args owned by SELF
//  |     |    old |        |  3
//  |     |     SP-+--------+----> Matcher::_old_SP, even aligned
//  v     |        |  ret   |  3   return address
//     Owned by    +--------+
//      Self       |  pad2  |  2   pad to align old SP
//        |        +--------+  1
//        |        | locks  |  0
//        |        +--------+----> SharedInfo::stack0, even aligned
//        |        |  pad1  | 11   pad to align new SP
//        |        +--------+
//        |        |        | 10
//        |        | spills |  9   spills
//        V        |        |  8   (pad0 slot for callee)
//      -----------+--------+----> Matcher::_out_arg_limit, unaligned
//        ^        |  out   |  7
//        |        |  args  |  6   Holes in outgoing args owned by CALLEE
//   Owned by  new |        |
//    Callee    SP-+--------+----> Matcher::_new_SP, even aligned
//                  |        |
//
// Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
//         known from SELF's arguments and the Java calling convention.
//         Region 6-7 is determined per call site.
// Note 2: If the calling convention leaves holes in the incoming argument
//         area, those holes are owned by SELF.  Holes in the outgoing area
//         are owned by the CALLEE.  Holes should not be nessecary in the
//         incoming area, as the Java calling convention is completely under
//         the control of the AD file.  Doubles can be sorted and packed to
//         avoid holes.  Holes in the outgoing arguments may be nessecary for
//         varargs C calling conventions.
// Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
//         even aligned with pad0 as needed.
//         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
//         region 6-11 is even aligned; it may be padded out more so that
//         the region from SP to FP meets the minimum stack alignment.
// Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
//         alignment.  Region 11, pad1, may be dynamically extended so that
//         SP meets the minimum alignment.


frame %{

  stack_direction(TOWARDS_LOW);

  // These two registers define part of the calling convention
  // between compiled code and the interpreter.
  // SEE StartI2CNode::calling_convention & StartC2INode::calling_convention & StartOSRNode::calling_convention
  // for more information.

  inline_cache_reg(T1);                // Inline Cache Register
  interpreter_method_oop_reg(S3);      // Method Oop Register when calling interpreter

  // Optional: name the operand used by cisc-spilling to access [stack_pointer + offset]
  cisc_spilling_operand_name(indOffset32);

  // Number of stack slots consumed by locking an object
  // generate Compile::sync_stack_slots
#ifdef _LP64
  sync_stack_slots(2);
#else
  sync_stack_slots(1);
#endif

  frame_pointer(SP);

  // Interpreter stores its frame pointer in a register which is
  // stored to the stack by I2CAdaptors.
  // I2CAdaptors convert from interpreted java to compiled java.

  interpreter_frame_pointer(FP);

  // generate Matcher::stack_alignment
  stack_alignment(StackAlignmentInBytes);  //wordSize = sizeof(char*);

  // Number of stack slots between incoming argument block and the start of
  // a new frame.  The PROLOG must add this many slots to the stack.  The
  // EPILOG must remove this many slots.
  in_preserve_stack_slots(4);  //Now VerifyStackAtCalls is defined as false ! Leave two stack slots for ra and fp

  // Number of outgoing stack slots killed above the out_preserve_stack_slots
  // for calls to C.  Supports the var-args backing area for register parms.
  varargs_C_out_slots_killed(0);

  // The after-PROLOG location of the return address.  Location of
  // return address specifies a type (REG or STACK) and a number
  // representing the register number (i.e. - use a register name) or
  // stack slot.
  // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
  // Otherwise, it is above the locks and verification slot and alignment word
  //return_addr(STACK -1+ round_to(1+VerifyStackAtCalls+Compile::current()->sync()*Compile::current()->sync_stack_slots(),WordsPerLong));
  return_addr(REG RA);

  // Body of function which returns an integer array locating
  // arguments either in registers or in stack slots.  Passed an array
  // of ideal registers called "sig" and a "length" count.  Stack-slot
  // offsets are based on outgoing arguments, i.e. a CALLER setting up
  // arguments for a CALLEE.  Incoming stack arguments are
  // automatically biased by the preserve_stack_slots field above.


  // will generated to Matcher::calling_convention(OptoRegPair *sig, uint length, bool is_outgoing)
  // StartNode::calling_convention call this.
  calling_convention %{
    SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
  %}




  // Body of function which returns an integer array locating
  // arguments either in registers or in stack slots.  Passed an array
  // of ideal registers called "sig" and a "length" count.  Stack-slot
  // offsets are based on outgoing arguments, i.e. a CALLER setting up
  // arguments for a CALLEE.  Incoming stack arguments are
  // automatically biased by the preserve_stack_slots field above.


  // SEE CallRuntimeNode::calling_convention for more information.
  c_calling_convention %{
   (void) SharedRuntime::c_calling_convention(sig_bt, regs, /*regs2=*/NULL, length);
  %}


  // Location of C & interpreter return values
  // register(s) contain(s) return value for Op_StartI2C and Op_StartOSR.
  // SEE Matcher::match.
  c_return_value %{
    assert( ideal_reg >= Op_RegI && ideal_reg <= Op_RegL, "only return normal values" );
                               /* -- , -- , Op_RegN, Op_RegI, Op_RegP, Op_RegF, Op_RegD, Op_RegL */
    static int lo[Op_RegL+1] = { 0, 0, V0_num,       V0_num,       V0_num,       F0_num,       F0_num,    V0_num };
    static int hi[Op_RegL+1] = { 0, 0, OptoReg::Bad, OptoReg::Bad, V0_H_num,     OptoReg::Bad, F0_H_num,  V0_H_num };
    return OptoRegPair(hi[ideal_reg],lo[ideal_reg]);
  %}

  // Location of return values
  // register(s) contain(s) return value for Op_StartC2I and Op_Start.
  // SEE Matcher::match.

  return_value %{
    assert( ideal_reg >= Op_RegI && ideal_reg <= Op_RegL, "only return normal values" );
                               /* -- , -- , Op_RegN, Op_RegI, Op_RegP, Op_RegF, Op_RegD, Op_RegL */
    static int lo[Op_RegL+1] = { 0, 0, V0_num,       V0_num,       V0_num,       F0_num,       F0_num,     V0_num };
    static int hi[Op_RegL+1] = { 0, 0, OptoReg::Bad, OptoReg::Bad, V0_H_num,     OptoReg::Bad, F0_H_num,   V0_H_num};
    return OptoRegPair(hi[ideal_reg],lo[ideal_reg]);
  %}

%}

//----------ATTRIBUTES---------------------------------------------------------
//----------Operand Attributes-------------------------------------------------
op_attrib op_cost(0);        // Required cost attribute

//----------Instruction Attributes---------------------------------------------
ins_attrib ins_cost(100);       // Required cost attribute
ins_attrib ins_size(32);         // Required size attribute (in bits)
ins_attrib ins_pc_relative(0);  // Required PC Relative flag
ins_attrib ins_short_branch(0); // Required flag: is this instruction a
                                // non-matching short branch variant of some
                                                            // long branch?
ins_attrib ins_alignment(4);    // Required alignment attribute (must be a power of 2)
                                // specifies the alignment that some part of the instruction (not
                                // necessarily the start) requires.  If > 1, a compute_padding()
                                // function must be provided for the instruction

//----------OPERANDS-----------------------------------------------------------
// Operand definitions must precede instruction definitions for correct parsing
// in the ADLC because operands constitute user defined types which are used in
// instruction definitions.

// Vectors
operand vecD() %{
  constraint(ALLOC_IN_RC(dbl_reg));
  match(VecD);

  format %{ %}
  interface(REG_INTER);
%}

// Flags register, used as output of compare instructions
operand FlagsReg() %{
  constraint(ALLOC_IN_RC(mips_flags));
  match(RegFlags);

  format %{ "AT" %}
  interface(REG_INTER);
%}

//----------Simple Operands----------------------------------------------------
// TODO: Should we need to define some more special immediate number ?
// Immediate Operands
// Integer Immediate
operand immI() %{
  match(ConI);
  // TODO: should not match immI8 here LEE
  match(immI8);

  op_cost(20);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI8() %{
  predicate((-128 <= n->get_int()) && (n->get_int() <= 127));
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI16() %{
  predicate((-32768 <= n->get_int()) && (n->get_int() <= 32767));
  match(ConI);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_M65536() %{
  predicate(n->get_int() == -65536);
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

// Constant for decrement
operand immI_M1() %{
  predicate(n->get_int() == -1);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

// Constant for test vs zero
operand immI_0() %{
  predicate(n->get_int() == 0);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

// Constant for increment
operand immI_1() %{
  predicate(n->get_int() == 1);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

// Constants for increment
operand immI_16() %{
  predicate(n->get_int() == 16);
  match(ConI);

  format %{ %}
  interface(CONST_INTER);
%}

operand immI_24() %{
  predicate(n->get_int() == 24);
  match(ConI);

  format %{ %}
  interface(CONST_INTER);
%}

// Constant for long shifts
operand immI_32() %{
  predicate(n->get_int() == 32);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

// Constant for byte-wide masking
operand immI_255() %{
  predicate(n->get_int() == 255);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_65535() %{
  predicate(n->get_int() == 65535);
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_MaxI() %{
  predicate(n->get_int() == 2147483647);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_M32767_32768() %{
  predicate((-32767 <= n->get_int()) && (n->get_int() <= 32768));
  match(ConI);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

// Valid scale values for addressing modes
operand immI_0_3() %{
  predicate(0 <= n->get_int() && (n->get_int() <= 3));
  match(ConI);

  format %{ %}
  interface(CONST_INTER);
%}

operand immI_0_31() %{
  predicate(n->get_int() >= 0 && n->get_int() <= 31);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_0_32767() %{
  predicate(n->get_int() >= 0 && n->get_int() <= 32767);
  match(ConI);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

operand immI_0_65535() %{
  predicate(n->get_int() >= 0 && n->get_int() <= 65535);
  match(ConI);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

operand immI_32_63() %{
  predicate(n->get_int() >= 32 && n->get_int() <= 63);
  match(ConI);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// Operand for non-negtive integer mask
operand immI_nonneg_mask() %{
  predicate((n->get_int() >= 0) && (Assembler::is_int_mask(n->get_int()) != -1));
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

// Long Immediate
operand immL() %{
  match(ConL);

  op_cost(20);
  format %{ %}
  interface(CONST_INTER);
%}

// Long Immediate 8-bit
operand immL8() %{
  predicate(-0x80L <= n->get_long() && n->get_long() < 0x80L);
  match(ConL);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immL16() %{
  predicate((-32768 <= n->get_long()) && (n->get_long() <= 32767));
  match(ConL);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

// Long Immediate 32-bit signed
operand immL32() %{
  predicate(n->get_long() == (int)(n->get_long()));
  match(ConL);

  op_cost(15);
  format %{ %}
  interface(CONST_INTER);
%}

// bit 3..6 zero
operand immL_M121() %{
  predicate(n->get_long() == -121L);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// bit 0..2 zero
operand immL_M8() %{
  predicate(n->get_long() == -8L);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// bit 1..2 zero
operand immL_M7() %{
  predicate(n->get_long() == -7L);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// bit 2 zero
operand immL_M5() %{
  predicate(n->get_long() == -5L);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// bit 0..1 zero
operand immL_M4() %{
  predicate(n->get_long() == -4L);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

operand immL_M1() %{
  predicate(n->get_long() == -1L);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// Long Immediate zero
operand immL_0() %{
  predicate(n->get_long() == 0L);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

operand immL_7() %{
  predicate(n->get_long() == 7L);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// Long Immediate: low 32-bit mask
operand immL_MaxUI() %{
  predicate(n->get_long() == 0xFFFFFFFFL);
  match(ConL);
  op_cost(20);

  format %{ %}
  interface(CONST_INTER);
%}

operand immL_M32767_32768() %{
  predicate((-32767 <= n->get_long()) && (n->get_long() <= 32768));
  match(ConL);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

operand immL_0_65535() %{
  predicate(n->get_long() >= 0 && n->get_long() <= 65535);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// Operand for non-negtive long mask
operand immL_nonneg_mask() %{
  predicate((n->get_long() >= 0) && (Assembler::is_jlong_mask(n->get_long()) != -1));
  match(ConL);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

// Pointer Immediate
operand immP() %{
  match(ConP);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

// NULL Pointer Immediate
operand immP_0() %{
  predicate(n->get_ptr() == 0);
  match(ConP);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// Pointer Immediate: 64-bit
operand immP_no_oop_cheap() %{
  predicate(!n->bottom_type()->isa_oop_ptr() && (MacroAssembler::insts_for_set64(n->get_ptr()) <= 3));
  match(ConP);

  op_cost(5);
  // formats are generated automatically for constants and base registers
  format %{ %}
  interface(CONST_INTER);
%}

// Pointer for polling page
operand immP_poll() %{
  predicate(n->get_ptr() != 0 && n->get_ptr() == (intptr_t)os::get_polling_page());
  match(ConP);
  op_cost(5);

  format %{ %}
  interface(CONST_INTER);
%}

// Pointer Immediate
operand immN() %{
  match(ConN);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

operand immNKlass() %{
  match(ConNKlass);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

// NULL Pointer Immediate
operand immN_0() %{
  predicate(n->get_narrowcon() == 0);
  match(ConN);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

// Single-precision floating-point immediate
operand immF() %{
  match(ConF);

  op_cost(20);
  format %{ %}
  interface(CONST_INTER);
%}

// Single-precision floating-point zero
operand immF_0() %{
  predicate(jint_cast(n->getf()) == 0);
  match(ConF);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

// Double-precision floating-point immediate
operand immD() %{
  match(ConD);

  op_cost(20);
  format %{ %}
  interface(CONST_INTER);
%}

// Double-precision floating-point zero
operand immD_0() %{
  predicate(jlong_cast(n->getd()) == 0);
  match(ConD);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

// Register Operands
// Integer Register
operand mRegI() %{
  constraint(ALLOC_IN_RC(int_reg));
  match(RegI);

  format %{ %}
  interface(REG_INTER);
%}

operand no_Ax_mRegI() %{
  constraint(ALLOC_IN_RC(no_Ax_int_reg));
  match(RegI);
  match(mRegI);

  format %{  %}
  interface(REG_INTER);
%}

operand mS0RegI() %{
  constraint(ALLOC_IN_RC(s0_reg));
  match(RegI);
  match(mRegI);

  format %{ "S0" %}
  interface(REG_INTER);
%}

operand mS1RegI() %{
  constraint(ALLOC_IN_RC(s1_reg));
  match(RegI);
  match(mRegI);

  format %{ "S1" %}
  interface(REG_INTER);
%}

operand mS2RegI() %{
  constraint(ALLOC_IN_RC(s2_reg));
  match(RegI);
  match(mRegI);

  format %{ "S2" %}
  interface(REG_INTER);
%}

operand mS3RegI() %{
  constraint(ALLOC_IN_RC(s3_reg));
  match(RegI);
  match(mRegI);

  format %{ "S3" %}
  interface(REG_INTER);
%}

operand mS4RegI() %{
  constraint(ALLOC_IN_RC(s4_reg));
  match(RegI);
  match(mRegI);

  format %{ "S4" %}
  interface(REG_INTER);
%}

operand mS5RegI() %{
  constraint(ALLOC_IN_RC(s5_reg));
  match(RegI);
  match(mRegI);

  format %{ "S5" %}
  interface(REG_INTER);
%}

operand mS6RegI() %{
  constraint(ALLOC_IN_RC(s6_reg));
  match(RegI);
  match(mRegI);

  format %{ "S6" %}
  interface(REG_INTER);
%}

operand mS7RegI() %{
  constraint(ALLOC_IN_RC(s7_reg));
  match(RegI);
  match(mRegI);

  format %{ "S7" %}
  interface(REG_INTER);
%}


operand mT0RegI() %{
  constraint(ALLOC_IN_RC(t0_reg));
  match(RegI);
  match(mRegI);

  format %{ "T0" %}
  interface(REG_INTER);
%}

operand mT1RegI() %{
  constraint(ALLOC_IN_RC(t1_reg));
  match(RegI);
  match(mRegI);

  format %{ "T1" %}
  interface(REG_INTER);
%}

operand mT2RegI() %{
  constraint(ALLOC_IN_RC(t2_reg));
  match(RegI);
  match(mRegI);

  format %{ "T2" %}
  interface(REG_INTER);
%}

operand mT3RegI() %{
  constraint(ALLOC_IN_RC(t3_reg));
  match(RegI);
  match(mRegI);

  format %{ "T3" %}
  interface(REG_INTER);
%}

operand mT8RegI() %{
  constraint(ALLOC_IN_RC(t8_reg));
  match(RegI);
  match(mRegI);

  format %{ "T8" %}
  interface(REG_INTER);
%}

operand mT9RegI() %{
  constraint(ALLOC_IN_RC(t9_reg));
  match(RegI);
  match(mRegI);

  format %{ "T9" %}
  interface(REG_INTER);
%}

operand mA0RegI() %{
  constraint(ALLOC_IN_RC(a0_reg));
  match(RegI);
  match(mRegI);

  format %{ "A0" %}
  interface(REG_INTER);
%}

operand mA1RegI() %{
  constraint(ALLOC_IN_RC(a1_reg));
  match(RegI);
  match(mRegI);

  format %{ "A1" %}
  interface(REG_INTER);
%}

operand mA2RegI() %{
  constraint(ALLOC_IN_RC(a2_reg));
  match(RegI);
  match(mRegI);

  format %{ "A2" %}
  interface(REG_INTER);
%}

operand mA3RegI() %{
  constraint(ALLOC_IN_RC(a3_reg));
  match(RegI);
  match(mRegI);

  format %{ "A3" %}
  interface(REG_INTER);
%}

operand mA4RegI() %{
  constraint(ALLOC_IN_RC(a4_reg));
  match(RegI);
  match(mRegI);

  format %{ "A4" %}
  interface(REG_INTER);
%}

operand mA5RegI() %{
  constraint(ALLOC_IN_RC(a5_reg));
  match(RegI);
  match(mRegI);

  format %{ "A5" %}
  interface(REG_INTER);
%}

operand mA6RegI() %{
  constraint(ALLOC_IN_RC(a6_reg));
  match(RegI);
  match(mRegI);

  format %{ "A6" %}
  interface(REG_INTER);
%}

operand mA7RegI() %{
  constraint(ALLOC_IN_RC(a7_reg));
  match(RegI);
  match(mRegI);

  format %{ "A7" %}
  interface(REG_INTER);
%}

operand mV0RegI() %{
  constraint(ALLOC_IN_RC(v0_reg));
  match(RegI);
  match(mRegI);

  format %{ "V0" %}
  interface(REG_INTER);
%}

operand mV1RegI() %{
  constraint(ALLOC_IN_RC(v1_reg));
  match(RegI);
  match(mRegI);

  format %{ "V1" %}
  interface(REG_INTER);
%}

operand mRegN() %{
  constraint(ALLOC_IN_RC(int_reg));
  match(RegN);

  format %{ %}
  interface(REG_INTER);
%}

operand t0_RegN() %{
  constraint(ALLOC_IN_RC(t0_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand t1_RegN() %{
  constraint(ALLOC_IN_RC(t1_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand t2_RegN() %{
  constraint(ALLOC_IN_RC(t2_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand t3_RegN() %{
  constraint(ALLOC_IN_RC(t3_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand t8_RegN() %{
  constraint(ALLOC_IN_RC(t8_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand t9_RegN() %{
  constraint(ALLOC_IN_RC(t9_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a0_RegN() %{
  constraint(ALLOC_IN_RC(a0_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a1_RegN() %{
  constraint(ALLOC_IN_RC(a1_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a2_RegN() %{
  constraint(ALLOC_IN_RC(a2_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a3_RegN() %{
  constraint(ALLOC_IN_RC(a3_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a4_RegN() %{
  constraint(ALLOC_IN_RC(a4_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a5_RegN() %{
  constraint(ALLOC_IN_RC(a5_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a6_RegN() %{
  constraint(ALLOC_IN_RC(a6_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a7_RegN() %{
  constraint(ALLOC_IN_RC(a7_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s0_RegN() %{
  constraint(ALLOC_IN_RC(s0_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s1_RegN() %{
  constraint(ALLOC_IN_RC(s1_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s2_RegN() %{
  constraint(ALLOC_IN_RC(s2_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s3_RegN() %{
  constraint(ALLOC_IN_RC(s3_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s4_RegN() %{
  constraint(ALLOC_IN_RC(s4_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s5_RegN() %{
  constraint(ALLOC_IN_RC(s5_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s6_RegN() %{
  constraint(ALLOC_IN_RC(s6_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s7_RegN() %{
  constraint(ALLOC_IN_RC(s7_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand v0_RegN() %{
  constraint(ALLOC_IN_RC(v0_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand v1_RegN() %{
  constraint(ALLOC_IN_RC(v1_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

// Pointer Register
operand mRegP() %{
  constraint(ALLOC_IN_RC(p_reg));
  match(RegP);
  match(a0_RegP);

  format %{  %}
  interface(REG_INTER);
%}

operand no_T8_mRegP() %{
  constraint(ALLOC_IN_RC(no_T8_p_reg));
  match(RegP);
  match(mRegP);

  format %{  %}
  interface(REG_INTER);
%}

operand s0_RegP()
%{
  constraint(ALLOC_IN_RC(s0_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s1_RegP()
%{
  constraint(ALLOC_IN_RC(s1_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s2_RegP()
%{
  constraint(ALLOC_IN_RC(s2_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s3_RegP()
%{
  constraint(ALLOC_IN_RC(s3_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s4_RegP()
%{
  constraint(ALLOC_IN_RC(s4_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s5_RegP()
%{
  constraint(ALLOC_IN_RC(s5_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s6_RegP()
%{
  constraint(ALLOC_IN_RC(s6_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s7_RegP()
%{
  constraint(ALLOC_IN_RC(s7_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand t0_RegP()
%{
  constraint(ALLOC_IN_RC(t0_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand t1_RegP()
%{
  constraint(ALLOC_IN_RC(t1_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand t2_RegP()
%{
  constraint(ALLOC_IN_RC(t2_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand t3_RegP()
%{
  constraint(ALLOC_IN_RC(t3_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand t8_RegP()
%{
  constraint(ALLOC_IN_RC(t8_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand t9_RegP()
%{
  constraint(ALLOC_IN_RC(t9_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a0_RegP()
%{
  constraint(ALLOC_IN_RC(a0_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a1_RegP()
%{
  constraint(ALLOC_IN_RC(a1_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a2_RegP()
%{
  constraint(ALLOC_IN_RC(a2_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a3_RegP()
%{
  constraint(ALLOC_IN_RC(a3_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a4_RegP()
%{
  constraint(ALLOC_IN_RC(a4_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}


operand a5_RegP()
%{
  constraint(ALLOC_IN_RC(a5_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a6_RegP()
%{
  constraint(ALLOC_IN_RC(a6_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a7_RegP()
%{
  constraint(ALLOC_IN_RC(a7_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand v0_RegP()
%{
  constraint(ALLOC_IN_RC(v0_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand v1_RegP()
%{
  constraint(ALLOC_IN_RC(v1_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

/*
operand mSPRegP(mRegP reg) %{
  constraint(ALLOC_IN_RC(sp_reg));
  match(reg);

  format %{ "SP"  %}
  interface(REG_INTER);
%}

operand mFPRegP(mRegP reg) %{
  constraint(ALLOC_IN_RC(fp_reg));
  match(reg);

  format %{ "FP"  %}
  interface(REG_INTER);
%}
*/

operand mRegL() %{
  constraint(ALLOC_IN_RC(long_reg));
  match(RegL);

  format %{ %}
  interface(REG_INTER);
%}

operand v0RegL() %{
  constraint(ALLOC_IN_RC(v0_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand v1RegL() %{
  constraint(ALLOC_IN_RC(v1_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a0RegL() %{
  constraint(ALLOC_IN_RC(a0_long_reg));
  match(RegL);
  match(mRegL);

  format %{ "A0" %}
  interface(REG_INTER);
%}

operand a1RegL() %{
  constraint(ALLOC_IN_RC(a1_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a2RegL() %{
  constraint(ALLOC_IN_RC(a2_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a3RegL() %{
  constraint(ALLOC_IN_RC(a3_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand t0RegL() %{
  constraint(ALLOC_IN_RC(t0_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand t1RegL() %{
  constraint(ALLOC_IN_RC(t1_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand t2RegL() %{
  constraint(ALLOC_IN_RC(t2_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand t3RegL() %{
  constraint(ALLOC_IN_RC(t3_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand t8RegL() %{
  constraint(ALLOC_IN_RC(t8_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a4RegL() %{
  constraint(ALLOC_IN_RC(a4_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a5RegL() %{
  constraint(ALLOC_IN_RC(a5_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a6RegL() %{
  constraint(ALLOC_IN_RC(a6_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a7RegL() %{
  constraint(ALLOC_IN_RC(a7_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand s0RegL() %{
  constraint(ALLOC_IN_RC(s0_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand s1RegL() %{
  constraint(ALLOC_IN_RC(s1_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand s2RegL() %{
  constraint(ALLOC_IN_RC(s2_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand s3RegL() %{
  constraint(ALLOC_IN_RC(s3_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand s4RegL() %{
  constraint(ALLOC_IN_RC(s4_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand s7RegL() %{
  constraint(ALLOC_IN_RC(s7_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

// Floating register operands
operand regF() %{
  constraint(ALLOC_IN_RC(flt_reg));
  match(RegF);

  format %{ %}
  interface(REG_INTER);
%}

//Double Precision Floating register operands
operand regD() %{
  constraint(ALLOC_IN_RC(dbl_reg));
  match(RegD);

  format %{ %}
  interface(REG_INTER);
%}

//----------Memory Operands----------------------------------------------------
// Indirect Memory Operand
operand indirect(mRegP reg) %{
  constraint(ALLOC_IN_RC(p_reg));
  match(reg);

  format %{ "[$reg] @ indirect" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);  /* NO_INDEX */
    scale(0x0);
    disp(0x0);
  %}
%}

// Indirect Memory Plus Short Offset Operand
operand indOffset8(mRegP reg, immL8 off)
%{
  constraint(ALLOC_IN_RC(p_reg));
  match(AddP reg off);

  op_cost(10);
  format %{ "[$reg + $off (8-bit)] @ indOffset8" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0); /* NO_INDEX */
    scale(0x0);
    disp($off);
  %}
%}

// Indirect Memory Times Scale Plus Index Register
operand indIndexScale(mRegP reg, mRegL lreg, immI_0_3 scale)
%{
  constraint(ALLOC_IN_RC(p_reg));
  match(AddP reg (LShiftL lreg scale));

  op_cost(10);
  format %{"[$reg + $lreg << $scale] @ indIndexScale" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index($lreg);
    scale($scale);
    disp(0x0);
  %}
%}


// [base + index + offset]
operand baseIndexOffset8(mRegP base, mRegL index, immL8 off)
%{
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(5);
  match(AddP (AddP base index) off);

  format %{ "[$base + $index + $off (8-bit)] @ baseIndexOffset8" %}
  interface(MEMORY_INTER) %{
    base($base);
    index($index);
    scale(0x0);
    disp($off);
  %}
%}

// [base + index + offset]
operand baseIndexOffset8_convI2L(mRegP base, mRegI index, immL8 off)
%{
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(5);
  match(AddP (AddP base (ConvI2L index)) off);

  format %{ "[$base + $index + $off (8-bit)] @ baseIndexOffset8_convI2L" %}
  interface(MEMORY_INTER) %{
    base($base);
    index($index);
    scale(0x0);
    disp($off);
  %}
%}

// Indirect Memory Times Scale Plus Index Register Plus Offset Operand
operand indIndexScaleOffset8(mRegP reg, immL8 off, mRegL lreg, immI_0_3 scale)
%{
  constraint(ALLOC_IN_RC(p_reg));
  match(AddP (AddP reg (LShiftL lreg scale)) off);

  op_cost(10);
  format %{"[$reg + $off + $lreg << $scale] @ indIndexScaleOffset8" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index($lreg);
    scale($scale);
    disp($off);
  %}
%}

operand indIndexScaleOffset8_convI2L(mRegP reg, immL8 off, mRegI ireg, immI_0_3 scale)
%{
  constraint(ALLOC_IN_RC(p_reg));
  match(AddP (AddP reg (LShiftL (ConvI2L ireg) scale)) off);

  op_cost(10);
  format %{"[$reg + $off + $ireg << $scale] @ indIndexScaleOffset8_convI2L" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index($ireg);
    scale($scale);
    disp($off);
  %}
%}

// [base + index<<scale + offset]
operand basePosIndexScaleOffset8(mRegP base, mRegI index, immL8 off, immI_0_31 scale)
%{
  constraint(ALLOC_IN_RC(p_reg));
  //predicate(n->in(2)->in(3)->in(1)->as_Type()->type()->is_long()->_lo >= 0);
  op_cost(10);
  match(AddP (AddP base (LShiftL (ConvI2L index) scale)) off);

  format %{ "[$base + $index << $scale + $off (8-bit)] @ basePosIndexScaleOffset8" %}
  interface(MEMORY_INTER) %{
    base($base);
    index($index);
    scale($scale);
    disp($off);
  %}
%}

// Indirect Memory Times Scale Plus Index Register Plus Offset Operand
operand indIndexScaleOffsetNarrow(mRegN reg, immL8 off, mRegL lreg, immI_0_3 scale)
%{
  predicate(Universe::narrow_oop_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  match(AddP (AddP (DecodeN reg) (LShiftL lreg scale)) off);

  op_cost(10);
  format %{"[$reg + $off + $lreg << $scale] @ indIndexScaleOffsetNarrow" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index($lreg);
    scale($scale);
    disp($off);
  %}
%}

// [base + index<<scale + offset] for compressd Oops
operand indPosIndexI2LScaleOffset8Narrow(mRegN base, mRegI index, immL8 off, immI_0_31 scale)
%{
  constraint(ALLOC_IN_RC(p_reg));
  //predicate(Universe::narrow_oop_shift() == 0 && n->in(2)->in(3)->in(1)->as_Type()->type()->is_long()->_lo >= 0);
  predicate(Universe::narrow_oop_shift() == 0);
  op_cost(10);
  match(AddP (AddP (DecodeN base) (LShiftL (ConvI2L index) scale)) off);

  format %{ "[$base + $index << $scale + $off (8-bit)] @ indPosIndexI2LScaleOffset8Narrow" %}
  interface(MEMORY_INTER) %{
    base($base);
    index($index);
    scale($scale);
    disp($off);
  %}
%}

//FIXME: I think it's better to limit the immI to be 16-bit at most!
// Indirect Memory Plus Long Offset Operand
operand indOffset32(mRegP reg, immL32 off) %{
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(20);
  match(AddP reg off);

  format %{ "[$reg + $off (32-bit)] @ indOffset32" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);   /* NO_INDEX */
    scale(0x0);
    disp($off);
  %}
%}

// Indirect Memory Plus Index Register
operand indIndex(mRegP addr, mRegL index) %{
  constraint(ALLOC_IN_RC(p_reg));
  match(AddP addr index);

  op_cost(20);
  format %{"[$addr + $index] @ indIndex" %}
  interface(MEMORY_INTER) %{
    base($addr);
    index($index);
    scale(0x0);
    disp(0x0);
  %}
%}

operand indirectNarrowKlass(mRegN reg)
%{
  predicate(Universe::narrow_klass_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(10);
  match(DecodeNKlass reg);

  format %{ "[$reg] @ indirectNarrowKlass" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);
    scale(0x0);
    disp(0x0);
  %}
%}

operand indOffset8NarrowKlass(mRegN reg, immL8 off)
%{
  predicate(Universe::narrow_klass_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(10);
  match(AddP (DecodeNKlass reg) off);

  format %{ "[$reg + $off (8-bit)] @ indOffset8NarrowKlass" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);
    scale(0x0);
    disp($off);
  %}
%}

operand indOffset32NarrowKlass(mRegN reg, immL32 off)
%{
  predicate(Universe::narrow_klass_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(10);
  match(AddP (DecodeNKlass reg) off);

  format %{ "[$reg + $off (32-bit)] @ indOffset32NarrowKlass" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);
    scale(0x0);
    disp($off);
  %}
%}

operand indIndexOffsetNarrowKlass(mRegN reg, mRegL lreg, immL32 off)
%{
  predicate(Universe::narrow_klass_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  match(AddP (AddP (DecodeNKlass reg) lreg) off);

  op_cost(10);
  format %{"[$reg + $off + $lreg] @ indIndexOffsetNarrowKlass" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index($lreg);
    scale(0x0);
    disp($off);
  %}
%}

operand indIndexNarrowKlass(mRegN reg, mRegL lreg)
%{
  predicate(Universe::narrow_klass_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  match(AddP (DecodeNKlass reg) lreg);

  op_cost(10);
  format %{"[$reg + $lreg] @ indIndexNarrowKlass" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index($lreg);
    scale(0x0);
    disp(0x0);
  %}
%}

// Indirect Memory Operand
operand indirectNarrow(mRegN reg)
%{
  predicate(Universe::narrow_oop_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(10);
  match(DecodeN reg);

  format %{ "[$reg] @ indirectNarrow" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);
    scale(0x0);
    disp(0x0);
  %}
%}

// Indirect Memory Plus Short Offset Operand
operand indOffset8Narrow(mRegN reg, immL8 off)
%{
  predicate(Universe::narrow_oop_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(10);
  match(AddP (DecodeN reg) off);

  format %{ "[$reg + $off (8-bit)] @ indOffset8Narrow" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);
    scale(0x0);
    disp($off);
  %}
%}

// Indirect Memory Plus Index Register Plus Offset Operand
operand indIndexOffset8Narrow(mRegN reg, mRegL lreg, immL8 off)
%{
  predicate(Universe::narrow_oop_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  match(AddP (AddP (DecodeN reg) lreg) off);

  op_cost(10);
  format %{"[$reg + $off + $lreg] @ indIndexOffset8Narrow" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index($lreg);
    scale(0x0);
    disp($off);
  %}
%}

//----------Load Long Memory Operands------------------------------------------
// The load-long idiom will use it's address expression again after loading
// the first word of the long.  If the load-long destination overlaps with
// registers used in the addressing expression, the 2nd half will be loaded
// from a clobbered address.  Fix this by requiring that load-long use
// address registers that do not overlap with the load-long target.

// load-long support
operand load_long_RegP() %{
  constraint(ALLOC_IN_RC(p_reg));
  match(RegP);
  match(mRegP);
  op_cost(100);
  format %{  %}
  interface(REG_INTER);
%}

// Indirect Memory Operand Long
operand load_long_indirect(load_long_RegP reg) %{
  constraint(ALLOC_IN_RC(p_reg));
  match(reg);

  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);
    scale(0x0);
    disp(0x0);
  %}
%}

// Indirect Memory Plus Long Offset Operand
operand load_long_indOffset32(load_long_RegP reg, immL32 off) %{
  match(AddP reg off);

  format %{ "[$reg + $off]" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);
    scale(0x0);
    disp($off);
  %}
%}

//----------Conditional Branch Operands----------------------------------------
// Comparison Op  - This is the operation of the comparison, and is limited to
//                  the following set of codes:
//                  L (<), LE (<=), G (>), GE (>=), E (==), NE (!=)
//
// Other attributes of the comparison, such as unsignedness, are specified
// by the comparison instruction that sets a condition code flags register.
// That result is represented by a flags operand whose subtype is appropriate
// to the unsignedness (etc.) of the comparison.
//
// Later, the instruction which matches both the Comparison Op (a Bool) and
// the flags (produced by the Cmp) specifies the coding of the comparison op
// by matching a specific subtype of Bool operand below, such as cmpOpU.

// Comparision Code
operand cmpOp() %{
  match(Bool);

  format %{ "" %}
  interface(COND_INTER) %{
    equal(0x01);
    not_equal(0x02);
    greater(0x03);
    greater_equal(0x04);
    less(0x05);
    less_equal(0x06);
    overflow(0x7);
    no_overflow(0x8);
  %}
%}


// Comparision Code
// Comparison Code, unsigned compare.  Used by FP also, with
// C2 (unordered) turned into GT or LT already.  The other bits
// C0 and C3 are turned into Carry & Zero flags.
operand cmpOpU() %{
  match(Bool);

  format %{ "" %}
  interface(COND_INTER) %{
    equal(0x01);
    not_equal(0x02);
    greater(0x03);
    greater_equal(0x04);
    less(0x05);
    less_equal(0x06);
    overflow(0x7);
    no_overflow(0x8);
  %}
%}


//----------Special Memory Operands--------------------------------------------
// Stack Slot Operand - This operand is used for loading and storing temporary
//                      values on the stack where a match requires a value to
//                      flow through memory.
operand stackSlotP(sRegP reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  op_cost(50);
  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base(0x1d);  // SP
    index(0x0);  // No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

operand stackSlotI(sRegI reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  op_cost(50);
  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base(0x1d);  // SP
    index(0x0);  // No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

operand stackSlotF(sRegF reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  op_cost(50);
  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base(0x1d);  // SP
    index(0x0);  // No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

operand stackSlotD(sRegD reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  op_cost(50);
  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base(0x1d);  // SP
    index(0x0);  // No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

operand stackSlotL(sRegL reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  op_cost(50);
  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base(0x1d);  // SP
    index(0x0);  // No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}


//------------------------OPERAND CLASSES--------------------------------------
//opclass memory( direct, indirect, indOffset16, indOffset32, indOffset32X, indIndexOffset );
opclass memory( indirect, indirectNarrow, indOffset8, indOffset32, indIndex, indIndexScale, load_long_indirect, load_long_indOffset32, baseIndexOffset8, baseIndexOffset8_convI2L, indIndexScaleOffset8, indIndexScaleOffset8_convI2L, basePosIndexScaleOffset8, indIndexScaleOffsetNarrow, indPosIndexI2LScaleOffset8Narrow, indOffset8Narrow, indIndexOffset8Narrow);


//----------PIPELINE-----------------------------------------------------------
// Rules which define the behavior of the target architectures pipeline.

pipeline %{

  //----------ATTRIBUTES---------------------------------------------------------
  attributes %{
    fixed_size_instructions;          // Fixed size instructions
    branch_has_delay_slot;      // branch have delay slot in gs2
    max_instructions_per_bundle = 1;     // 1 instruction per bundle
    max_bundles_per_cycle = 4;         // Up to 4 bundles per cycle
         bundle_unit_size=4;
    instruction_unit_size = 4;           // An instruction is 4 bytes long
    instruction_fetch_unit_size = 16;    // The processor fetches one line
    instruction_fetch_units = 1;         // of 16 bytes

    // List of nop instructions
    nops( MachNop );
  %}

  //----------RESOURCES----------------------------------------------------------
  // Resources are the functional units available to the machine

  resources(D1, D2, D3, D4, DECODE = D1 | D2 | D3| D4,  ALU1, ALU2,  ALU = ALU1 | ALU2,  FPU1, FPU2, FPU = FPU1 | FPU2,  MEM,  BR);

  //----------PIPELINE DESCRIPTION-----------------------------------------------
  // Pipeline Description specifies the stages in the machine's pipeline

  // IF: fetch
  // ID: decode
  // RD: read
  // CA: caculate
  // WB: write back
  // CM: commit

  pipe_desc(IF, ID, RD, CA, WB, CM);


  //----------PIPELINE CLASSES---------------------------------------------------
  // Pipeline Classes describe the stages in which input and output are
  // referenced by the hardware pipeline.

  //No.1 Integer ALU reg-reg operation : dst <-- reg1 op reg2
  pipe_class ialu_regI_regI(mRegI dst, mRegI src1, mRegI src2) %{
    single_instruction;
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write)+1;
    DECODE : ID;
    ALU    : CA;
  %}

  //No.19 Integer mult operation : dst <-- reg1 mult reg2
  pipe_class ialu_mult(mRegI dst, mRegI src1, mRegI src2) %{
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write)+5;
    DECODE : ID;
    ALU2   : CA;
  %}

  pipe_class mulL_reg_reg(mRegL dst, mRegL src1, mRegL src2) %{
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write)+10;
    DECODE : ID;
    ALU2   : CA;
  %}

  //No.19 Integer div operation : dst <-- reg1 div reg2
  pipe_class ialu_div(mRegI dst, mRegI src1, mRegI src2) %{
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write)+10;
    DECODE : ID;
    ALU2   : CA;
  %}

  //No.19 Integer mod operation : dst <-- reg1 mod reg2
  pipe_class ialu_mod(mRegI dst, mRegI src1, mRegI src2) %{
    instruction_count(2);
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write)+10;
    DECODE : ID;
    ALU2   : CA;
  %}

  //No.15 Long ALU reg-reg operation : dst <-- reg1 op reg2
  pipe_class ialu_regL_regL(mRegL dst, mRegL src1, mRegL src2) %{
    instruction_count(2);
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write);
    DECODE : ID;
    ALU    : CA;
  %}

  //No.18 Long ALU reg-imm16 operation : dst <-- reg1 op imm16
  pipe_class ialu_regL_imm16(mRegL dst, mRegL src) %{
    instruction_count(2);
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    ALU    : CA;
  %}

  //no.16 load Long from memory :
  pipe_class ialu_loadL(mRegL dst, memory mem) %{
    instruction_count(2);
    mem    : RD(read);
    dst    : WB(write)+5;
    DECODE : ID;
    MEM    : RD;
  %}

  //No.17 Store Long to Memory :
  pipe_class ialu_storeL(mRegL src, memory mem) %{
    instruction_count(2);
    mem    : RD(read);
    src    : RD(read);
    DECODE : ID;
    MEM    : RD;
  %}

  //No.2 Integer ALU reg-imm16 operation : dst <-- reg1 op imm16
  pipe_class ialu_regI_imm16(mRegI dst, mRegI src) %{
         single_instruction;
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    ALU    : CA;
  %}

  //No.3 Integer move operation : dst <-- reg
  pipe_class ialu_regI_mov(mRegI dst, mRegI src) %{
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    ALU    : CA;
  %}

  //No.4 No instructions : do nothing
  pipe_class empty( ) %{
    instruction_count(0);
  %}

  //No.5 UnConditional branch :
  pipe_class pipe_jump( label labl ) %{
    multiple_bundles;
    DECODE : ID;
    BR     : RD;
  %}

  //No.6 ALU Conditional branch :
  pipe_class pipe_alu_branch(mRegI src1, mRegI src2, label labl ) %{
    multiple_bundles;
    src1   : RD(read);
    src2   : RD(read);
    DECODE : ID;
    BR     : RD;
  %}

  //no.7 load integer from memory :
  pipe_class ialu_loadI(mRegI dst, memory mem) %{
    mem    : RD(read);
    dst    : WB(write)+3;
    DECODE : ID;
    MEM    : RD;
  %}

  //No.8 Store Integer to Memory :
  pipe_class ialu_storeI(mRegI src, memory mem) %{
    mem    : RD(read);
    src    : RD(read);
    DECODE : ID;
    MEM    : RD;
  %}


  //No.10 Floating FPU reg-reg operation : dst <-- reg1 op reg2
  pipe_class fpu_regF_regF(regF dst, regF src1, regF src2) %{
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write);
    DECODE : ID;
    FPU    : CA;
  %}

  //No.22 Floating div operation : dst <-- reg1 div reg2
  pipe_class fpu_div(regF dst, regF src1, regF src2) %{
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write);
    DECODE : ID;
    FPU2   : CA;
  %}

  pipe_class fcvt_I2D(regD dst, mRegI src) %{
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    FPU1   : CA;
  %}

  pipe_class fcvt_D2I(mRegI dst, regD src) %{
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    FPU1   : CA;
  %}

  pipe_class pipe_mfc1(mRegI dst, regD src) %{
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    MEM    : RD;
  %}

  pipe_class pipe_mtc1(regD dst, mRegI src) %{
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    MEM    : RD(5);
  %}

  //No.23 Floating sqrt operation : dst <-- reg1 sqrt reg2
  pipe_class fpu_sqrt(regF dst, regF src1, regF src2) %{
    multiple_bundles;
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write);
    DECODE : ID;
    FPU2   : CA;
  %}

  //No.11 Load Floating from Memory :
  pipe_class fpu_loadF(regF dst, memory mem) %{
    instruction_count(1);
    mem    : RD(read);
    dst    : WB(write)+3;
    DECODE : ID;
    MEM    : RD;
  %}

  //No.12 Store Floating to Memory :
  pipe_class fpu_storeF(regF src, memory mem) %{
    instruction_count(1);
    mem    : RD(read);
    src    : RD(read);
    DECODE : ID;
    MEM    : RD;
  %}

  //No.13 FPU Conditional branch :
  pipe_class pipe_fpu_branch(regF src1, regF src2, label labl ) %{
    multiple_bundles;
    src1   : RD(read);
    src2   : RD(read);
    DECODE : ID;
    BR     : RD;
  %}

//No.14 Floating FPU reg operation : dst <-- op reg
  pipe_class fpu1_regF(regF dst, regF src) %{
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    FPU    : CA;
  %}

  pipe_class long_memory_op() %{
    instruction_count(10); multiple_bundles; force_serialization;
    fixed_latency(30);
  %}

  pipe_class simple_call() %{
   instruction_count(10); multiple_bundles; force_serialization;
   fixed_latency(200);
   BR     : RD;
  %}

  pipe_class call() %{
    instruction_count(10); multiple_bundles; force_serialization;
    fixed_latency(200);
  %}

  //FIXME:
  //No.9 Piple slow : for multi-instructions
  pipe_class pipe_slow(  ) %{
    instruction_count(20);
    force_serialization;
    multiple_bundles;
    fixed_latency(50);
  %}

%}



//----------INSTRUCTIONS-------------------------------------------------------
//
// match      -- States which machine-independent subtree may be replaced
//               by this instruction.
// ins_cost   -- The estimated cost of this instruction is used by instruction
//               selection to identify a minimum cost tree of machine
//               instructions that matches a tree of machine-independent
//               instructions.
// format     -- A string providing the disassembly for this instruction.
//               The value of an instruction's operand may be inserted
//               by referring to it with a '$' prefix.
// opcode     -- Three instruction opcodes may be provided.  These are referred
//               to within an encode class as $primary, $secondary, and $tertiary
//               respectively.  The primary opcode is commonly used to
//               indicate the type of machine instruction, while secondary
//               and tertiary are often used for prefix options or addressing
//               modes.
// ins_encode -- A list of encode classes with parameters. The encode class
//               name must have been defined in an 'enc_class' specification
//               in the encode section of the architecture description.


// Load Integer
instruct loadI(mRegI dst, memory mem) %{
  match(Set dst (LoadI mem));

  ins_cost(125);
  format %{ "lw    $dst, $mem   #@loadI" %}
  ins_encode (load_I_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

instruct loadI_convI2L(mRegL dst, memory mem) %{
  match(Set dst (ConvI2L (LoadI mem)));

  ins_cost(125);
  format %{ "lw    $dst, $mem   #@loadI_convI2L" %}
  ins_encode (load_I_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Load Integer (32 bit signed) to Byte (8 bit signed)
instruct loadI2B(mRegI dst, memory mem, immI_24 twentyfour) %{
  match(Set dst (RShiftI (LShiftI (LoadI mem) twentyfour) twentyfour));

  ins_cost(125);
  format %{ "lb  $dst, $mem\t# int -> byte #@loadI2B" %}
  ins_encode(load_B_enc(dst, mem));
  ins_pipe(ialu_loadI);
%}

// Load Integer (32 bit signed) to Unsigned Byte (8 bit UNsigned)
instruct loadI2UB(mRegI dst, memory mem, immI_255 mask) %{
  match(Set dst (AndI (LoadI mem) mask));

  ins_cost(125);
  format %{ "lbu  $dst, $mem\t# int -> ubyte #@loadI2UB" %}
  ins_encode(load_UB_enc(dst, mem));
  ins_pipe(ialu_loadI);
%}

// Load Integer (32 bit signed) to Short (16 bit signed)
instruct loadI2S(mRegI dst, memory mem, immI_16 sixteen) %{
  match(Set dst (RShiftI (LShiftI (LoadI mem) sixteen) sixteen));

  ins_cost(125);
  format %{ "lh  $dst, $mem\t# int -> short #@loadI2S" %}
  ins_encode(load_S_enc(dst, mem));
  ins_pipe(ialu_loadI);
%}

// Load Integer (32 bit signed) to Unsigned Short/Char (16 bit UNsigned)
instruct loadI2US(mRegI dst, memory mem, immI_65535 mask) %{
  match(Set dst (AndI (LoadI mem) mask));

  ins_cost(125);
  format %{ "lhu  $dst, $mem\t# int -> ushort/char #@loadI2US" %}
  ins_encode(load_C_enc(dst, mem));
  ins_pipe(ialu_loadI);
%}

// Load Long.
instruct loadL(mRegL dst, memory mem) %{
//  predicate(!((LoadLNode*)n)->require_atomic_access());
  match(Set dst (LoadL mem));

  ins_cost(250);
  format %{ "ld    $dst, $mem   #@loadL" %}
  ins_encode(load_L_enc(dst, mem));
  ins_pipe( ialu_loadL );
%}

// Load Long - UNaligned
instruct loadL_unaligned(mRegL dst, memory mem) %{
  match(Set dst (LoadL_unaligned mem));

  // FIXME: Need more effective ldl/ldr
  ins_cost(450);
  format %{ "ld    $dst, $mem   #@loadL_unaligned\n\t" %}
  ins_encode(load_L_enc(dst, mem));
  ins_pipe( ialu_loadL );
%}

// Store Long
instruct storeL_reg(memory mem, mRegL src) %{
  match(Set mem (StoreL mem src));

  ins_cost(200);
  format %{ "sd    $mem,   $src #@storeL_reg\n" %}
  ins_encode(store_L_reg_enc(mem, src));
  ins_pipe( ialu_storeL );
%}

instruct storeL_immL_0(memory mem, immL_0 zero) %{
  match(Set mem (StoreL mem zero));

  ins_cost(180);
  format %{ "sd    zero, $mem #@storeL_immL_0" %}
  ins_encode(store_L_immL_0_enc(mem, zero));
  ins_pipe( ialu_storeL );
%}

instruct storeL_imm(memory mem, immL src) %{
  match(Set mem (StoreL mem src));

  ins_cost(200);
  format %{ "sd    $src, $mem #@storeL_imm" %}
  ins_encode(store_L_immL_enc(mem, src));
  ins_pipe( ialu_storeL );
%}

// Load Compressed Pointer
instruct loadN(mRegN dst, memory mem)
%{
   match(Set dst (LoadN mem));

   ins_cost(125); // XXX
   format %{ "lwu    $dst, $mem\t# compressed ptr @ loadN" %}
   ins_encode (load_N_enc(dst, mem));
   ins_pipe( ialu_loadI ); // XXX
%}

instruct loadN2P(mRegP dst, memory mem)
%{
   match(Set dst (DecodeN (LoadN mem)));
   predicate(Universe::narrow_oop_base() == NULL && Universe::narrow_oop_shift() == 0);

   ins_cost(125); // XXX
   format %{ "lwu    $dst, $mem\t# @ loadN2P" %}
   ins_encode (load_N_enc(dst, mem));
   ins_pipe( ialu_loadI ); // XXX
%}

// Load Pointer
instruct loadP(mRegP dst, memory mem) %{
  match(Set dst (LoadP mem));

  ins_cost(125);
  format %{ "ld    $dst, $mem #@loadP" %}
  ins_encode (load_P_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Load Klass Pointer
instruct loadKlass(mRegP dst, memory mem) %{
  match(Set dst (LoadKlass mem));

  ins_cost(125);
  format %{ "MOV    $dst,$mem @ loadKlass" %}
  ins_encode (load_P_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Load narrow Klass Pointer
instruct loadNKlass(mRegN dst, memory mem)
%{
  match(Set dst (LoadNKlass mem));

  ins_cost(125); // XXX
  format %{ "lwu    $dst, $mem\t# compressed klass ptr @ loadNKlass" %}
  ins_encode (load_N_enc(dst, mem));
  ins_pipe( ialu_loadI ); // XXX
%}

instruct loadN2PKlass(mRegP dst, memory mem)
%{
  match(Set dst (DecodeNKlass (LoadNKlass mem)));
  predicate(Universe::narrow_klass_base() == NULL && Universe::narrow_klass_shift() == 0);

  ins_cost(125); // XXX
  format %{ "lwu    $dst, $mem\t# compressed klass ptr @ loadN2PKlass" %}
  ins_encode (load_N_enc(dst, mem));
  ins_pipe( ialu_loadI ); // XXX
%}

// Load Constant
instruct loadConI(mRegI dst, immI src) %{
  match(Set dst src);

  ins_cost(150);
  format %{ "mov    $dst, $src #@loadConI" %}
  ins_encode %{
    Register dst = $dst$$Register;
    int    value = $src$$constant;
    __ move(dst, value);
  %}
  ins_pipe( ialu_regI_regI );
%}


instruct loadConL_set64(mRegL dst, immL src) %{
  match(Set dst src);
  ins_cost(120);
  format %{ "li   $dst, $src @ loadConL_set64" %}
  ins_encode %{
    __ set64($dst$$Register, $src$$constant);
  %}
  ins_pipe(ialu_regL_regL);
%}

instruct loadConL16(mRegL dst, immL16 src) %{
  match(Set dst src);
  ins_cost(105);
  format %{ "mov    $dst, $src #@loadConL16" %}
  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    int      value   = $src$$constant;
    __ daddiu(dst_reg, R0, value);
  %}
  ins_pipe( ialu_regL_regL );
%}


instruct loadConL_immL_0(mRegL dst, immL_0 src) %{
  match(Set dst src);
  ins_cost(100);
  format %{ "mov    $dst, zero #@loadConL_immL_0" %}
  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    __ daddu(dst_reg, R0, R0);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Load Range
instruct loadRange(mRegI dst, memory mem) %{
  match(Set dst (LoadRange mem));

  ins_cost(125);
  format %{ "MOV    $dst,$mem @ loadRange" %}
  ins_encode(load_I_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}


instruct storeP(memory mem, mRegP src ) %{
  match(Set mem (StoreP mem src));

  ins_cost(125);
  format %{ "sd    $src, $mem #@storeP" %}
  ins_encode(store_P_reg_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

// Store NULL Pointer, mark word, or other simple pointer constant.
instruct storeImmP_immP_0(memory mem, immP_0 zero) %{
  match(Set mem (StoreP mem zero));

  ins_cost(125);
  format %{ "mov    $mem, $zero #@storeImmP_immP_0" %}
  ins_encode(store_P_immP0_enc(mem));
  ins_pipe( ialu_storeI );
%}

// Store Byte Immediate
instruct storeImmB(memory mem, immI8 src) %{
  match(Set mem (StoreB mem src));

  ins_cost(150);
  format %{ "movb   $mem, $src #@storeImmB" %}
  ins_encode(store_B_immI_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

// Store Compressed Pointer
instruct storeN(memory mem, mRegN src)
%{
  match(Set mem (StoreN mem src));

  ins_cost(125); // XXX
  format %{ "sw    $mem, $src\t# compressed ptr @ storeN" %}
  ins_encode(store_N_reg_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

instruct storeP2N(memory mem, mRegP src)
%{
  match(Set mem (StoreN mem (EncodeP src)));
  predicate(Universe::narrow_oop_base() == NULL && Universe::narrow_oop_shift() == 0);

  ins_cost(125); // XXX
  format %{ "sw    $mem, $src\t# @ storeP2N" %}
  ins_encode(store_N_reg_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

instruct storeNKlass(memory mem, mRegN src)
%{
  match(Set mem (StoreNKlass mem src));

  ins_cost(125); // XXX
  format %{ "sw    $mem, $src\t# compressed klass ptr @ storeNKlass" %}
  ins_encode(store_N_reg_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

instruct storeP2NKlass(memory mem, mRegP src)
%{
  match(Set mem (StoreNKlass mem (EncodePKlass src)));
  predicate(Universe::narrow_klass_base() == NULL && Universe::narrow_klass_shift() == 0);

  ins_cost(125); // XXX
  format %{ "sw    $mem, $src\t# @ storeP2NKlass" %}
  ins_encode(store_N_reg_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

instruct storeImmN_immN_0(memory mem, immN_0 zero)
%{
  match(Set mem (StoreN mem zero));

  ins_cost(125); // XXX
  format %{ "storeN0    zero, $mem\t# compressed ptr" %}
  ins_encode(storeImmN0_enc(mem, zero));
  ins_pipe( ialu_storeI );
%}

// Store Byte
instruct storeB(memory mem, mRegI src) %{
  match(Set mem (StoreB mem src));

  ins_cost(125);
  format %{ "sb    $src, $mem #@storeB" %}
  ins_encode(store_B_reg_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

instruct storeB_convL2I(memory mem, mRegL src) %{
  match(Set mem (StoreB mem (ConvL2I src)));

  ins_cost(125);
  format %{ "sb    $src, $mem #@storeB_convL2I" %}
  ins_encode(store_B_reg_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

// Load Byte (8bit signed)
instruct loadB(mRegI dst, memory mem) %{
  match(Set dst (LoadB mem));

  ins_cost(125);
  format %{ "lb   $dst, $mem #@loadB" %}
  ins_encode(load_B_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

instruct loadB_convI2L(mRegL dst, memory mem) %{
  match(Set dst (ConvI2L (LoadB mem)));

  ins_cost(125);
  format %{ "lb   $dst, $mem #@loadB_convI2L" %}
  ins_encode(load_B_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Load Byte (8bit UNsigned)
instruct loadUB(mRegI dst, memory mem) %{
  match(Set dst (LoadUB mem));

  ins_cost(125);
  format %{ "lbu   $dst, $mem #@loadUB" %}
  ins_encode(load_UB_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

instruct loadUB_convI2L(mRegL dst, memory mem) %{
  match(Set dst (ConvI2L (LoadUB mem)));

  ins_cost(125);
  format %{ "lbu   $dst, $mem #@loadUB_convI2L" %}
  ins_encode(load_UB_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Load Short (16bit signed)
instruct loadS(mRegI dst, memory mem) %{
  match(Set dst (LoadS mem));

  ins_cost(125);
  format %{ "lh   $dst, $mem #@loadS" %}
  ins_encode(load_S_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Load Short (16 bit signed) to Byte (8 bit signed)
instruct loadS2B(mRegI dst, memory mem, immI_24 twentyfour) %{
  match(Set dst (RShiftI (LShiftI (LoadS mem) twentyfour) twentyfour));

  ins_cost(125);
  format %{ "lb $dst, $mem\t# short -> byte #@loadS2B" %}
  ins_encode(load_B_enc(dst, mem));
  ins_pipe(ialu_loadI);
%}

instruct loadS_convI2L(mRegL dst, memory mem) %{
  match(Set dst (ConvI2L (LoadS mem)));

  ins_cost(125);
  format %{ "lh   $dst, $mem #@loadS_convI2L" %}
  ins_encode(load_S_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Store Integer Immediate
instruct storeImmI(memory mem, immI src) %{
  match(Set mem (StoreI mem src));

  ins_cost(150);
  format %{ "mov    $mem, $src #@storeImmI" %}
  ins_encode(store_I_immI_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

// Store Integer
instruct storeI(memory mem, mRegI src) %{
  match(Set mem (StoreI mem src));

  ins_cost(125);
  format %{ "sw    $mem, $src #@storeI" %}
  ins_encode(store_I_reg_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

instruct storeI_convL2I(memory mem, mRegL src) %{
  match(Set mem (StoreI mem (ConvL2I src)));

  ins_cost(125);
  format %{ "sw    $mem, $src #@storeI_convL2I" %}
  ins_encode(store_I_reg_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

// Load Float
instruct loadF(regF dst, memory mem) %{
  match(Set dst (LoadF mem));

  ins_cost(150);
  format %{ "loadF $dst, $mem #@loadF" %}
  ins_encode(load_F_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

instruct loadConP_general(mRegP dst, immP src) %{
  match(Set dst src);

  ins_cost(120);
  format %{ "li   $dst, $src #@loadConP_general" %}

  ins_encode %{
    Register dst = $dst$$Register;
    long* value = (long*)$src$$constant;

    if($src->constant_reloc() == relocInfo::metadata_type){
      int klass_index = __ oop_recorder()->find_index((Klass*)value);
      RelocationHolder rspec = metadata_Relocation::spec(klass_index);

      __ relocate(rspec);
      __ patchable_set48(dst, (long)value);
    } else if($src->constant_reloc() == relocInfo::oop_type){
      int oop_index = __ oop_recorder()->find_index((jobject)value);
      RelocationHolder rspec = oop_Relocation::spec(oop_index);

      __ relocate(rspec);
      __ patchable_set48(dst, (long)value);
    } else if ($src->constant_reloc() == relocInfo::none) {
        __ set64(dst, (long)value);
    }
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct loadConP_no_oop_cheap(mRegP dst, immP_no_oop_cheap src) %{
  match(Set dst src);

  ins_cost(80);
  format %{ "li    $dst, $src @ loadConP_no_oop_cheap" %}

  ins_encode %{
    __ set64($dst$$Register, $src$$constant);
  %}

  ins_pipe(ialu_regI_regI);
%}


instruct loadConP_poll(mRegP dst, immP_poll src) %{
  match(Set dst src);

  ins_cost(50);
  format %{ "li   $dst, $src #@loadConP_poll" %}

  ins_encode %{
    Register dst = $dst$$Register;
    intptr_t value = (intptr_t)$src$$constant;

    __ set64(dst, (jlong)value);
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct loadConP_immP_0(mRegP dst, immP_0 src)
%{
  match(Set dst src);

  ins_cost(50);
  format %{ "mov    $dst, R0\t# ptr" %}
  ins_encode %{
     Register dst_reg = $dst$$Register;
     __ daddu(dst_reg, R0, R0);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct loadConN_immN_0(mRegN dst, immN_0 src) %{
  match(Set dst src);
  format %{ "move    $dst, R0\t# compressed NULL ptr" %}
  ins_encode %{
    __ move($dst$$Register, R0);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct loadConN(mRegN dst, immN src) %{
  match(Set dst src);

  ins_cost(125);
  format %{ "li    $dst, $src\t# compressed ptr @ loadConN" %}
  ins_encode %{
    Register dst = $dst$$Register;
    __ set_narrow_oop(dst, (jobject)$src$$constant);
  %}
  ins_pipe( ialu_regI_regI ); // XXX
%}

instruct loadConNKlass(mRegN dst, immNKlass src) %{
  match(Set dst src);

  ins_cost(125);
  format %{ "li    $dst, $src\t# compressed klass ptr @ loadConNKlass" %}
  ins_encode %{
    Register dst = $dst$$Register;
    __ set_narrow_klass(dst, (Klass*)$src$$constant);
  %}
  ins_pipe( ialu_regI_regI ); // XXX
%}

//FIXME
// Tail Call; Jump from runtime stub to Java code.
// Also known as an 'interprocedural jump'.
// Target of jump will eventually return to caller.
// TailJump below removes the return address.
instruct TailCalljmpInd(mRegP jump_target, mRegP method_oop) %{
  match(TailCall jump_target method_oop );
  ins_cost(300);
  format %{ "JMP    $jump_target \t# @TailCalljmpInd" %}

  ins_encode %{
    Register target = $jump_target$$Register;
    Register    oop = $method_oop$$Register;

    // RA will be used in generate_forward_exception()
    __ push(RA);

    __ move(S3, oop);
    __ jr(target);
    __ delayed()->nop();
  %}

  ins_pipe( pipe_jump );
%}

// Create exception oop: created by stack-crawling runtime code.
// Created exception is now available to this handler, and is setup
// just prior to jumping to this handler.  No code emitted.
instruct CreateException( a0_RegP ex_oop )
%{
  match(Set ex_oop (CreateEx));

  // use the following format syntax
  format %{ "# exception oop is in A0; no code emitted @CreateException" %}
  ins_encode %{
    // X86 leaves this function empty
    __ block_comment("CreateException is empty in MIPS");
  %}
  ins_pipe( empty );
//  ins_pipe( pipe_jump );
%}


/* The mechanism of exception handling is clear now.

- Common try/catch:
  [stubGenerator_mips.cpp] generate_forward_exception()
      |- V0, V1 are created
      |- T9 <= SharedRuntime::exception_handler_for_return_address
      `- jr T9
           `- the caller's exception_handler
                 `- jr OptoRuntime::exception_blob
                        `- here
- Rethrow(e.g. 'unwind'):
  * The callee:
     |- an exception is triggered during execution
     `- exits the callee method through RethrowException node
          |- The callee pushes exception_oop(T0) and exception_pc(RA)
          `- The callee jumps to OptoRuntime::rethrow_stub()
  * In OptoRuntime::rethrow_stub:
     |- The VM calls _rethrow_Java to determine the return address in the caller method
     `- exits the stub with tailjmpInd
          |- pops exception_oop(V0) and exception_pc(V1)
          `- jumps to the return address(usually an exception_handler)
  * The caller:
     `- continues processing the exception_blob with V0/V1
*/

/*
Disassembling OptoRuntime::rethrow_stub()

; locals
   0x2d3bf320: addiu sp, sp, 0xfffffff8
   0x2d3bf324: sw ra, 0x4(sp)
   0x2d3bf328: sw fp, 0x0(sp)
   0x2d3bf32c: addu fp, sp, zero
   0x2d3bf330: addiu sp, sp, 0xfffffff0
   0x2d3bf334: sw ra, 0x8(sp)
   0x2d3bf338: sw t0, 0x4(sp)
   0x2d3bf33c: sw sp, 0x0(sp)

; get_thread(S2)
   0x2d3bf340: addu s2, sp, zero
   0x2d3bf344: srl s2, s2, 12
   0x2d3bf348: sll s2, s2, 2
   0x2d3bf34c: lui at, 0x2c85
   0x2d3bf350: addu at, at, s2
   0x2d3bf354: lw s2, 0xffffcc80(at)

   0x2d3bf358: lw s0, 0x0(sp)
   0x2d3bf35c: sw s0, 0x118(s2)    // last_sp -> threa
   0x2d3bf360: sw s2, 0xc(sp)

; OptoRuntime::rethrow_C(oopDesc* exception, JavaThread* thread, address ret_pc)
   0x2d3bf364: lw a0, 0x4(sp)
   0x2d3bf368: lw a1, 0xc(sp)
   0x2d3bf36c: lw a2, 0x8(sp)
  ;; Java_To_Runtime
   0x2d3bf370: lui t9, 0x2c34
   0x2d3bf374: addiu t9, t9, 0xffff8a48
   0x2d3bf378: jalr t9
   0x2d3bf37c: nop

   0x2d3bf380: addu s3, v0, zero     ; S3: SharedRuntime::raw_exception_handler_for_return_address()

   0x2d3bf384: lw s0, 0xc(sp)
   0x2d3bf388: sw zero, 0x118(s0)
   0x2d3bf38c: sw zero, 0x11c(s0)
   0x2d3bf390: lw s1, 0x144(s0)      ; ex_oop: S1
   0x2d3bf394: addu s2, s0, zero
   0x2d3bf398: sw zero, 0x144(s2)
   0x2d3bf39c: lw s0, 0x4(s2)
   0x2d3bf3a0: addiu s4, zero, 0x0
   0x2d3bf3a4: bne s0, s4, 0x2d3bf3d4
   0x2d3bf3a8: nop
   0x2d3bf3ac: addiu sp, sp, 0x10
   0x2d3bf3b0: addiu sp, sp, 0x8
   0x2d3bf3b4: lw ra, 0xfffffffc(sp)
   0x2d3bf3b8: lw fp, 0xfffffff8(sp)
   0x2d3bf3bc: lui at, 0x2b48
   0x2d3bf3c0: lw at, 0x100(at)

; tailjmpInd: Restores exception_oop & exception_pc
   0x2d3bf3c4: addu v1, ra, zero
   0x2d3bf3c8: addu v0, s1, zero
   0x2d3bf3cc: jr s3
   0x2d3bf3d0: nop
; Exception:
   0x2d3bf3d4: lui s1, 0x2cc8    ; generate_forward_exception()
   0x2d3bf3d8: addiu s1, s1, 0x40
   0x2d3bf3dc: addiu s2, zero, 0x0
   0x2d3bf3e0: addiu sp, sp, 0x10
   0x2d3bf3e4: addiu sp, sp, 0x8
   0x2d3bf3e8: lw ra, 0xfffffffc(sp)
   0x2d3bf3ec: lw fp, 0xfffffff8(sp)
   0x2d3bf3f0: lui at, 0x2b48
   0x2d3bf3f4: lw at, 0x100(at)
; TailCalljmpInd
              __ push(RA);    ; to be used in generate_forward_exception()
   0x2d3bf3f8: addu t7, s2, zero
   0x2d3bf3fc: jr s1
   0x2d3bf400: nop
*/
// Rethrow exception:
// The exception oop will come in the first argument position.
// Then JUMP (not call) to the rethrow stub code.
instruct RethrowException()
%{
  match(Rethrow);

  // use the following format syntax
  format %{ "JMP    rethrow_stub #@RethrowException" %}
  ins_encode %{
    __ block_comment("@ RethrowException");

    cbuf.set_insts_mark();
    cbuf.relocate(cbuf.insts_mark(), runtime_call_Relocation::spec());

    // call OptoRuntime::rethrow_stub to get the exception handler in parent method
    __ patchable_jump((address)OptoRuntime::rethrow_stub());
  %}
  ins_pipe( pipe_jump );
%}

// ============================================================================
// Branch Instructions --- long offset versions

// Jump Direct
instruct jmpDir_long(label labl) %{
  match(Goto);
  effect(USE labl);

  ins_cost(300);
  format %{ "JMP    $labl #@jmpDir_long" %}

  ins_encode %{
    Label* L = $labl$$label;
    __ jmp_far(*L);
  %}

  ins_pipe( pipe_jump );
  //ins_pc_relative(1);
%}

// Jump Direct Conditional - Label defines a relative address from Jcc+1
instruct  jmpLoopEnd_long(cmpOp cop, mRegI src1, mRegI src2, label labl) %{
  match(CountedLoopEnd cop (CmpI src1 src2));
  effect(USE labl);

  ins_cost(300);
  format %{ "J$cop  $src1, $src2,  $labl\t# Loop end @ jmpLoopEnd_long" %}
  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = $src2$$Register;
    Label*     L = $labl$$label;
    int     flag = $cop$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, op2, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, op2, *L);
        break;
      case 0x03: //above
        __ slt(AT, op2, op1);
        __ bne_long(AT, R0, *L);
        break;
      case 0x04: //above_equal
        __ slt(AT, op1, op2);
        __ beq_long(AT, R0, *L);
        break;
      case 0x05: //below
        __ slt(AT, op1, op2);
        __ bne_long(AT, R0, *L);
        break;
      case 0x06: //below_equal
        __ slt(AT, op2, op1);
        __ beq_long(AT, R0, *L);
        break;
      default:
        Unimplemented();
    }
  %}
  ins_pipe( pipe_jump );
  ins_pc_relative(1);
%}

instruct  jmpLoopEnd_reg_immI_long(cmpOp cop, mRegI src1, immI src2, label labl) %{
  match(CountedLoopEnd cop (CmpI src1 src2));
  effect(USE labl);

  ins_cost(300);
  format %{ "J$cop  $src1, $src2,  $labl\t# Loop end @ jmpLoopEnd_reg_immI_long" %}
  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = AT;
    Label*     L = $labl$$label;
    int     flag = $cop$$cmpcode;

    __ move(op2, $src2$$constant);

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, op2, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, op2, *L);
        break;
      case 0x03: //above
        __ slt(AT, op2, op1);
        __ bne_long(AT, R0, *L);
        break;
      case 0x04: //above_equal
        __ slt(AT, op1, op2);
        __ beq_long(AT, R0, *L);
        break;
      case 0x05: //below
        __ slt(AT, op1, op2);
        __ bne_long(AT, R0, *L);
        break;
      case 0x06: //below_equal
        __ slt(AT, op2, op1);
        __ beq_long(AT, R0, *L);
        break;
      default:
        Unimplemented();
    }
  %}
  ins_pipe( pipe_jump );
  ins_pc_relative(1);
%}


// This match pattern is created for StoreIConditional since I cannot match IfNode without a RegFlags!
instruct jmpCon_flags_long(cmpOp cop, FlagsReg cr, label labl) %{
  match(If cop cr);
  effect(USE labl);

  ins_cost(300);
  format %{ "J$cop    $labl  #mips uses AT as eflag @jmpCon_flags_long" %}

  ins_encode %{
    Label*    L =  $labl$$label;
    switch($cop$$cmpcode) {
      case 0x01: //equal
        __ bne_long(AT, R0, *L);
        break;
      case 0x02: //not equal
        __ beq_long(AT, R0, *L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pipe( pipe_jump );
  ins_pc_relative(1);
%}

// Conditional jumps
instruct branchConP_zero_long(cmpOpU cmp, mRegP op1, immP_0 zero, label labl) %{
  match(If cmp (CmpP op1 zero));
  effect(USE labl);

  ins_cost(180);
  format %{ "b$cmp   $op1, R0, $labl #@branchConP_zero_long" %}

  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = R0;
    Label*    L  = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, op2, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, op2, *L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConN2P_zero_long(cmpOpU cmp, mRegN op1, immP_0 zero, label labl) %{
  match(If cmp (CmpP (DecodeN op1) zero));
  predicate(Universe::narrow_oop_base() == NULL && Universe::narrow_oop_shift() == 0);
  effect(USE labl);

  ins_cost(180);
  format %{ "b$cmp   $op1, R0, $labl #@branchConN2P_zero_long" %}

  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = R0;
    Label*    L  = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ beq_long(op1, op2, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, op2, *L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}


instruct branchConP_long(cmpOpU cmp, mRegP op1, mRegP op2, label labl) %{
  match(If cmp (CmpP op1 op2));
//  predicate(can_branch_register(_kids[0]->_leaf, _kids[1]->_leaf));
  effect(USE labl);

  ins_cost(200);
  format %{ "b$cmp   $op1, $op2, $labl #@branchConP_long" %}

  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = $op2$$Register;
    Label*    L  = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, op2, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, op2, *L);
        break;
      case 0x03: //above
        __ sltu(AT, op2, op1);
        __ bne_long(R0, AT, *L);
        break;
      case 0x04: //above_equal
        __ sltu(AT, op1, op2);
        __ beq_long(AT, R0, *L);
        break;
      case 0x05: //below
        __ sltu(AT, op1, op2);
        __ bne_long(R0, AT, *L);
        break;
      case 0x06: //below_equal
        __ sltu(AT, op2, op1);
        __ beq_long(AT, R0, *L);
       break;
      default:
          Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct cmpN_null_branch_long(cmpOp cmp, mRegN op1, immN_0 null, label labl) %{
  match(If cmp (CmpN op1 null));
  effect(USE labl);

  ins_cost(180);
  format %{ "CMP    $op1,0\t! compressed ptr\n\t"
            "BP$cmp   $labl @ cmpN_null_branch_long" %}
  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = R0;
    Label*    L  = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
    case 0x01: //equal
      __ beq_long(op1, op2, *L);
      break;
    case 0x02: //not_equal
      __ bne_long(op1, op2, *L);
      break;
    default:
          Unimplemented();
    }
  %}
//TODO: pipe_branchP or create pipe_branchN LEE
  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct cmpN_reg_branch_long(cmpOp cmp, mRegN op1, mRegN op2, label labl) %{
  match(If cmp (CmpN op1 op2));
  effect(USE labl);

  ins_cost(180);
  format %{ "CMP    $op1,$op2\t! compressed ptr\n\t"
            "BP$cmp   $labl @ cmpN_reg_branch_long" %}
  ins_encode %{
    Register op1_reg = $op1$$Register;
    Register op2_reg = $op2$$Register;
    Label*    L  = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
    case 0x01: //equal
      __ beq_long(op1_reg, op2_reg, *L);
      break;
    case 0x02: //not_equal
      __ bne_long(op1_reg, op2_reg, *L);
      break;
    case 0x03: //above
      __ sltu(AT, op2_reg, op1_reg);
      __ bne_long(R0, AT, *L);
      break;
    case 0x04: //above_equal
      __ sltu(AT, op1_reg, op2_reg);
      __ beq_long(AT, R0, *L);
      break;
    case 0x05: //below
      __ sltu(AT, op1_reg, op2_reg);
      __ bne_long(R0, AT, *L);
      break;
    case 0x06: //below_equal
      __ sltu(AT, op2_reg, op1_reg);
      __ beq_long(AT, R0, *L);
      break;
    default:
      Unimplemented();
    }
  %}
  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConIU_reg_reg_long(cmpOpU cmp, mRegI src1, mRegI src2, label labl) %{
  match( If cmp (CmpU src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConIU_reg_reg_long" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = $src2$$Register;
    Label*     L = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, op2, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, op2, *L);
        break;
      case 0x03: //above
        __ sltu(AT, op2, op1);
        __ bne_long(AT, R0, *L);
        break;
      case 0x04: //above_equal
        __ sltu(AT, op1, op2);
        __ beq_long(AT, R0, *L);
        break;
      case 0x05: //below
        __ sltu(AT, op1, op2);
        __ bne_long(AT, R0, *L);
        break;
      case 0x06: //below_equal
        __ sltu(AT, op2, op1);
        __ beq_long(AT, R0, *L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}


instruct branchConIU_reg_imm_long(cmpOpU cmp, mRegI src1, immI src2, label labl) %{
  match( If cmp (CmpU src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConIU_reg_imm_long" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    int      val = $src2$$constant;
    Label*     L = $labl$$label;
    int     flag = $cmp$$cmpcode;

    __ move(AT, val);
    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, AT, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, AT, *L);
        break;
      case 0x03: //above
        __ sltu(AT, AT, op1);
        __ bne_long(R0, AT, *L);
        break;
      case 0x04: //above_equal
        __ sltu(AT, op1, AT);
        __ beq_long(AT, R0, *L);
        break;
      case 0x05: //below
        __ sltu(AT, op1, AT);
        __ bne_long(R0, AT, *L);
        break;
      case 0x06: //below_equal
        __ sltu(AT, AT, op1);
        __ beq_long(AT, R0, *L);
       break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConI_reg_reg_long(cmpOp cmp, mRegI src1, mRegI src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_reg_long" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = $src2$$Register;
    Label*     L = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, op2, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, op2, *L);
        break;
      case 0x03: //above
        __ slt(AT, op2, op1);
        __ bne_long(R0, AT, *L);
        break;
      case 0x04: //above_equal
        __ slt(AT, op1, op2);
        __ beq_long(AT, R0, *L);
        break;
      case 0x05: //below
        __ slt(AT, op1, op2);
        __ bne_long(R0, AT, *L);
        break;
      case 0x06: //below_equal
        __ slt(AT, op2, op1);
        __ beq_long(AT, R0, *L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConI_reg_immI_0_long(cmpOp cmp, mRegI src1, immI_0 src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  ins_cost(170);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_immI_0_long" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Label*     L =  $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, R0, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, R0, *L);
        break;
      case 0x03: //greater
        __ slt(AT, R0, op1);
        __ bne_long(R0, AT, *L);
        break;
      case 0x04: //greater_equal
        __ slt(AT, op1, R0);
        __ beq_long(AT, R0, *L);
        break;
      case 0x05: //less
        __ slt(AT, op1, R0);
        __ bne_long(R0, AT, *L);
        break;
      case 0x06: //less_equal
        __ slt(AT, R0, op1);
        __ beq_long(AT, R0, *L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConI_reg_imm_long(cmpOp cmp, mRegI src1, immI src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  ins_cost(200);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_imm_long" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    int      val = $src2$$constant;
    Label*     L =  $labl$$label;
    int     flag = $cmp$$cmpcode;

    __ move(AT, val);
    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, AT, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, AT, *L);
        break;
      case 0x03: //greater
        __ slt(AT, AT, op1);
        __ bne_long(R0, AT, *L);
        break;
      case 0x04: //greater_equal
        __ slt(AT, op1, AT);
        __ beq_long(AT, R0, *L);
        break;
      case 0x05: //less
        __ slt(AT, op1, AT);
        __ bne_long(R0, AT, *L);
        break;
      case 0x06: //less_equal
        __ slt(AT, AT, op1);
        __ beq_long(AT, R0, *L);
       break;
      default:
          Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConIU_reg_immI_0_long(cmpOpU cmp, mRegI src1, immI_0 zero, label labl) %{
  match( If cmp (CmpU src1 zero) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, zero, $labl #@branchConIU_reg_immI_0_long" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Label*     L = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, R0, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, R0, *L);
        break;
      case 0x03: //above
        __ bne_long(R0, op1, *L);
        break;
      case 0x04: //above_equal
        __ beq_long(R0, R0, *L);
        break;
      case 0x05: //below
        return;
        break;
      case 0x06: //below_equal
        __ beq_long(op1, R0, *L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}


instruct branchConIU_reg_immI16_long(cmpOpU cmp, mRegI src1, immI16 src2, label labl) %{
  match( If cmp (CmpU src1 src2) );
  effect(USE labl);
  ins_cost(180);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConIU_reg_immI16_long" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    int      val = $src2$$constant;
    Label*     L = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ move(AT, val);
        __ beq_long(op1, AT, *L);
        break;
      case 0x02: //not_equal
        __ move(AT, val);
        __ bne_long(op1, AT, *L);
        break;
      case 0x03: //above
        __ move(AT, val);
        __ sltu(AT, AT, op1);
        __ bne_long(R0, AT, *L);
        break;
      case 0x04: //above_equal
        __ sltiu(AT, op1, val);
        __ beq_long(AT, R0, *L);
        break;
      case 0x05: //below
        __ sltiu(AT, op1, val);
        __ bne_long(R0, AT, *L);
        break;
      case 0x06: //below_equal
        __ move(AT, val);
        __ sltu(AT, AT, op1);
        __ beq_long(AT, R0, *L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}


instruct branchConL_regL_regL_long(cmpOp cmp, mRegL src1, mRegL src2, label labl) %{
  match( If cmp (CmpL src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConL_regL_regL_long" %}
  ins_cost(250);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = as_Register($src2$$reg);

    Label*   target = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x02: //not_equal
        __ bne_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x03: //greater
        __ slt(AT, opr2_reg, opr1_reg);
        __ bne_long(AT, R0, *target);
        break;

      case 0x04: //greater_equal
        __ slt(AT, opr1_reg, opr2_reg);
        __ beq_long(AT, R0, *target);
        break;

      case 0x05: //less
        __ slt(AT, opr1_reg, opr2_reg);
        __ bne_long(AT, R0, *target);
        break;

      case 0x06: //less_equal
        __ slt(AT, opr2_reg, opr1_reg);
        __ beq_long(AT, R0, *target);
        break;

      default:
        Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConL_regL_immL_0_long(cmpOp cmp, mRegL src1, immL_0 zero, label labl) %{
  match( If cmp (CmpL src1 zero) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, zero, $labl #@branchConL_regL_immL_0_long" %}
  ins_cost(150);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = R0;

    Label*   target = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x02: //not_equal
        __ bne_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x03: //greater
        __ slt(AT, opr2_reg, opr1_reg);
        __ bne_long(AT, R0, *target);
        break;

      case 0x04: //greater_equal
        __ slt(AT, opr1_reg, opr2_reg);
        __ beq_long(AT, R0, *target);
        break;

      case 0x05: //less
        __ slt(AT, opr1_reg, opr2_reg);
        __ bne_long(AT, R0, *target);
        break;

      case 0x06: //less_equal
        __ slt(AT, opr2_reg, opr1_reg);
        __ beq_long(AT, R0, *target);
        break;

      default:
        Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConL_regL_immL_long(cmpOp cmp, mRegL src1, immL src2, label labl) %{
  match( If cmp (CmpL src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConL_regL_immL_long" %}
  ins_cost(180);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = AT;

    Label*   target = $labl$$label;
    int     flag = $cmp$$cmpcode;

    __ set64(opr2_reg, $src2$$constant);

    switch(flag) {
      case 0x01: //equal
        __ beq_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x02: //not_equal
        __ bne_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x03: //greater
        __ slt(AT, opr2_reg, opr1_reg);
        __ bne_long(AT, R0, *target);
        break;

      case 0x04: //greater_equal
        __ slt(AT, opr1_reg, opr2_reg);
        __ beq_long(AT, R0, *target);
        break;

      case 0x05: //less
        __ slt(AT, opr1_reg, opr2_reg);
        __ bne_long(AT, R0, *target);
        break;

      case 0x06: //less_equal
        __ slt(AT, opr2_reg, opr1_reg);
        __ beq_long(AT, R0, *target);
        break;

      default:
        Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}


//FIXME
instruct branchConF_reg_reg_long(cmpOp cmp, regF src1, regF src2, label labl) %{
  match( If cmp (CmpF src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConF_reg_reg_long" %}

  ins_encode %{
    FloatRegister reg_op1 = $src1$$FloatRegister;
    FloatRegister reg_op2 = $src2$$FloatRegister;
    Label* L = $labl$$label;
    int flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: // equal
        __ c_eq_s(reg_op1, reg_op2);
        __ bc1t_long(*L);
        break;
      case 0x02: // not_equal
        __ c_eq_s(reg_op1, reg_op2);
        __ bc1f_long(*L);
        break;
      case 0x03: // greater
        __ c_ule_s(reg_op1, reg_op2);
        __ bc1f_long(*L);
        break;
      case 0x04: // greater_equal
        __ c_ult_s(reg_op1, reg_op2);
        __ bc1f_long(*L);
        break;
      case 0x05: // less
        __ c_ult_s(reg_op1, reg_op2);
        __ bc1t_long(*L);
        break;
      case 0x06: // less_equal
        __ c_ule_s(reg_op1, reg_op2);
        __ bc1t_long(*L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe(pipe_slow);
%}

instruct branchConD_reg_reg_long(cmpOp cmp, regD src1, regD src2, label labl) %{
  match( If cmp (CmpD src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConD_reg_reg_long" %}

  ins_encode %{
    FloatRegister reg_op1 = $src1$$FloatRegister;
    FloatRegister reg_op2 = $src2$$FloatRegister;
    Label* L = $labl$$label;
    int flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: // equal
        __ c_eq_d(reg_op1, reg_op2);
        __ bc1t_long(*L);
        break;
      case 0x02: // not_equal
        // c_ueq_d cannot distinguish NaN from equal. Double.isNaN(Double) is implemented by 'f != f', so the use of c_ueq_d causes bugs.
        __ c_eq_d(reg_op1, reg_op2);
        __ bc1f_long(*L);
        break;
      case 0x03: // greater
        __ c_ule_d(reg_op1, reg_op2);
        __ bc1f_long(*L);
        break;
      case 0x04: // greater_equal
        __ c_ult_d(reg_op1, reg_op2);
        __ bc1f_long(*L);
        break;
      case 0x05: // less
        __ c_ult_d(reg_op1, reg_op2);
        __ bc1t_long(*L);
        break;
      case 0x06: // less_equal
        __ c_ule_d(reg_op1, reg_op2);
        __ bc1t_long(*L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe(pipe_slow);
%}


// ============================================================================
// Branch Instructions -- short offset versions

// Jump Direct
instruct jmpDir_short(label labl) %{
  match(Goto);
  effect(USE labl);

  ins_cost(300);
  format %{ "JMP    $labl #@jmpDir_short" %}

  ins_encode %{
    Label &L = *($labl$$label);
    if(&L)
       __ b(L);
    else
       __ b(int(0));
    __ delayed()->nop();
  %}

    ins_pipe( pipe_jump );
    ins_pc_relative(1);
    ins_short_branch(1);
%}

// Jump Direct Conditional - Label defines a relative address from Jcc+1
instruct  jmpLoopEnd_short(cmpOp cop, mRegI src1, mRegI src2, label labl) %{
  match(CountedLoopEnd cop (CmpI src1 src2));
  effect(USE labl);

  ins_cost(300);
  format %{ "J$cop  $src1, $src2,  $labl\t# Loop end @ jmpLoopEnd_short" %}
  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = $src2$$Register;
    Label     &L = *($labl$$label);
    int     flag = $cop$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, op2, L);
        else
          __ beq(op1, op2, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, op2, L);
        else
          __ bne(op1, op2, (int)0);
        break;
      case 0x03: //above
        __ slt(AT, op2, op1);
        if(&L)
          __ bne(AT, R0, L);
        else
          __ bne(AT, R0, (int)0);
        break;
      case 0x04: //above_equal
        __ slt(AT, op1, op2);
        if(&L)
          __ beq(AT, R0, L);
        else
          __ beq(AT, R0, (int)0);
        break;
      case 0x05: //below
        __ slt(AT, op1, op2);
        if(&L)
          __ bne(AT, R0, L);
        else
          __ bne(AT, R0, (int)0);
        break;
      case 0x06: //below_equal
        __ slt(AT, op2, op1);
        if(&L)
          __ beq(AT, R0, L);
        else
          __ beq(AT, R0, (int)0);
        break;
      default:
        Unimplemented();
    }
    __ delayed()->nop();
  %}
  ins_pipe( pipe_jump );
  ins_pc_relative(1);
  ins_short_branch(1);
%}

instruct  jmpLoopEnd_reg_immI_short(cmpOp cop, mRegI src1, immI src2, label labl) %{
  match(CountedLoopEnd cop (CmpI src1 src2));
  effect(USE labl);

  ins_cost(300);
  format %{ "J$cop  $src1, $src2,  $labl\t# Loop end @ jmpLoopEnd_reg_immI_short" %}
  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = AT;
    Label     &L = *($labl$$label);
    int     flag = $cop$$cmpcode;

    __ move(op2, $src2$$constant);

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, op2, L);
        else
          __ beq(op1, op2, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, op2, L);
        else
          __ bne(op1, op2, (int)0);
        break;
      case 0x03: //above
        __ slt(AT, op2, op1);
        if(&L)
          __ bne(AT, R0, L);
        else
          __ bne(AT, R0, (int)0);
        break;
      case 0x04: //above_equal
        __ slt(AT, op1, op2);
        if(&L)
          __ beq(AT, R0, L);
        else
          __ beq(AT, R0, (int)0);
        break;
      case 0x05: //below
        __ slt(AT, op1, op2);
        if(&L)
          __ bne(AT, R0, L);
        else
          __ bne(AT, R0, (int)0);
        break;
      case 0x06: //below_equal
        __ slt(AT, op2, op1);
        if(&L)
          __ beq(AT, R0, L);
        else
          __ beq(AT, R0, (int)0);
        break;
      default:
        Unimplemented();
    }
    __ delayed()->nop();
  %}
  ins_pipe( pipe_jump );
  ins_pc_relative(1);
  ins_short_branch(1);
%}


// This match pattern is created for StoreIConditional since I cannot match IfNode without a RegFlags!
instruct jmpCon_flags_short(cmpOp cop, FlagsReg cr, label labl) %{
  match(If cop cr);
  effect(USE labl);

  ins_cost(300);
  format %{ "J$cop    $labl  #mips uses AT as eflag @jmpCon_flags_short" %}

  ins_encode %{
    Label    &L =  *($labl$$label);
    switch($cop$$cmpcode) {
      case 0x01: //equal
        if (&L)
          __ bne(AT, R0, L);
        else
          __ bne(AT, R0, (int)0);
        break;
      case 0x02: //not equal
        if (&L)
          __ beq(AT, R0, L);
        else
          __ beq(AT, R0, (int)0);
        break;
      default:
        Unimplemented();
    }
    __ delayed()->nop();
  %}

  ins_pipe( pipe_jump );
  ins_pc_relative(1);
  ins_short_branch(1);
%}

// Conditional jumps
instruct branchConP_zero_short(cmpOpU cmp, mRegP op1, immP_0 zero, label labl) %{
  match(If cmp (CmpP op1 zero));
  effect(USE labl);

  ins_cost(180);
  format %{ "b$cmp   $op1, R0, $labl #@branchConP_zero_short" %}

  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = R0;
    Label    &L  = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, op2, L);
        else
          __ beq(op1, op2, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, op2, L);
        else
          __ bne(op1, op2, (int)0);
        break;
      default:
        Unimplemented();
    }
    __ delayed()->nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConN2P_zero_short(cmpOpU cmp, mRegN op1, immP_0 zero, label labl) %{
  match(If cmp (CmpP (DecodeN op1) zero));
  predicate(Universe::narrow_oop_base() == NULL && Universe::narrow_oop_shift() == 0);
  effect(USE labl);

  ins_cost(180);
  format %{ "b$cmp   $op1, R0, $labl #@branchConN2P_zero_short" %}

  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = R0;
    Label    &L  = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        if (&L)
          __ beq(op1, op2, L);
        else
          __ beq(op1, op2, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, op2, L);
        else
          __ bne(op1, op2, (int)0);
        break;
      default:
        Unimplemented();
    }
    __ delayed()->nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}


instruct branchConP_short(cmpOpU cmp, mRegP op1, mRegP op2, label labl) %{
  match(If cmp (CmpP op1 op2));
//  predicate(can_branch_register(_kids[0]->_leaf, _kids[1]->_leaf));
  effect(USE labl);

  ins_cost(200);
  format %{ "b$cmp   $op1, $op2, $labl #@branchConP_short" %}

  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = $op2$$Register;
    Label    &L  = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, op2, L);
        else
          __ beq(op1, op2, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, op2, L);
        else
          __ bne(op1, op2, (int)0);
        break;
      case 0x03: //above
        __ sltu(AT, op2, op1);
        if(&L)
          __ bne(R0, AT, L);
        else
                __ bne(R0, AT, (int)0);
        break;
      case 0x04: //above_equal
        __ sltu(AT, op1, op2);
        if(&L)
                 __ beq(AT, R0, L);
        else
                 __ beq(AT, R0, (int)0);
        break;
      case 0x05: //below
        __ sltu(AT, op1, op2);
        if(&L)
           __ bne(R0, AT, L);
        else
           __ bne(R0, AT, (int)0);
        break;
      case 0x06: //below_equal
        __ sltu(AT, op2, op1);
        if(&L)
          __ beq(AT, R0, L);
        else
          __ beq(AT, R0, (int)0);
       break;
      default:
          Unimplemented();
    }
    __ delayed()->nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct cmpN_null_branch_short(cmpOp cmp, mRegN op1, immN_0 null, label labl) %{
  match(If cmp (CmpN op1 null));
  effect(USE labl);

  ins_cost(180);
  format %{ "CMP    $op1,0\t! compressed ptr\n\t"
            "BP$cmp   $labl @ cmpN_null_branch_short" %}
  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = R0;
    Label    &L  = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
    case 0x01: //equal
      if (&L)
        __ beq(op1, op2, L);
      else
        __ beq(op1, op2, (int)0);
      break;
    case 0x02: //not_equal
      if (&L)
        __ bne(op1, op2, L);
      else
        __ bne(op1, op2, (int)0);
      break;
    default:
          Unimplemented();
    }
    __ delayed()->nop();
  %}
//TODO: pipe_branchP or create pipe_branchN LEE
  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct cmpN_reg_branch_short(cmpOp cmp, mRegN op1, mRegN op2, label labl) %{
  match(If cmp (CmpN op1 op2));
  effect(USE labl);

  ins_cost(180);
  format %{ "CMP    $op1,$op2\t! compressed ptr\n\t"
            "BP$cmp   $labl @ cmpN_reg_branch_short" %}
  ins_encode %{
    Register op1_reg = $op1$$Register;
    Register op2_reg = $op2$$Register;
    Label    &L  = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
    case 0x01: //equal
      if (&L)
        __ beq(op1_reg, op2_reg, L);
      else
        __ beq(op1_reg, op2_reg, (int)0);
      break;
    case 0x02: //not_equal
      if (&L)
        __ bne(op1_reg, op2_reg, L);
      else
        __ bne(op1_reg, op2_reg, (int)0);
      break;
    case 0x03: //above
      __ sltu(AT, op2_reg, op1_reg);
      if(&L)
        __ bne(R0, AT, L);
      else
        __ bne(R0, AT, (int)0);
      break;
    case 0x04: //above_equal
      __ sltu(AT, op1_reg, op2_reg);
      if(&L)
        __ beq(AT, R0, L);
      else
        __ beq(AT, R0, (int)0);
      break;
    case 0x05: //below
      __ sltu(AT, op1_reg, op2_reg);
      if(&L)
        __ bne(R0, AT, L);
      else
        __ bne(R0, AT, (int)0);
      break;
    case 0x06: //below_equal
      __ sltu(AT, op2_reg, op1_reg);
      if(&L)
        __ beq(AT, R0, L);
      else
        __ beq(AT, R0, (int)0);
      break;
    default:
      Unimplemented();
    }
    __ delayed()->nop();
  %}
  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConIU_reg_reg_short(cmpOpU cmp, mRegI src1, mRegI src2, label labl) %{
  match( If cmp (CmpU src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConIU_reg_reg_short" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = $src2$$Register;
    Label     &L = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, op2, L);
        else
          __ beq(op1, op2, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, op2, L);
        else
          __ bne(op1, op2, (int)0);
        break;
      case 0x03: //above
        __ sltu(AT, op2, op1);
        if(&L)
          __ bne(AT, R0, L);
        else
                __ bne(AT, R0, (int)0);
        break;
      case 0x04: //above_equal
        __ sltu(AT, op1, op2);
        if(&L)
          __ beq(AT, R0, L);
        else
                __ beq(AT, R0, (int)0);
        break;
      case 0x05: //below
        __ sltu(AT, op1, op2);
        if(&L)
           __ bne(AT, R0, L);
        else
           __ bne(AT, R0, (int)0);
        break;
      case 0x06: //below_equal
        __ sltu(AT, op2, op1);
        if(&L)
          __ beq(AT, R0, L);
        else
          __ beq(AT, R0, (int)0);
        break;
      default:
        Unimplemented();
    }
    __ delayed()->nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}


instruct branchConIU_reg_imm_short(cmpOpU cmp, mRegI src1, immI src2, label labl) %{
  match( If cmp (CmpU src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConIU_reg_imm_short" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    int      val = $src2$$constant;
    Label     &L = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    __ move(AT, val);
    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, AT, L);
        else
          __ beq(op1, AT, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, AT, L);
        else
          __ bne(op1, AT, (int)0);
        break;
      case 0x03: //above
        __ sltu(AT, AT, op1);
        if(&L)
          __ bne(R0, AT, L);
        else
                __ bne(R0, AT, (int)0);
        break;
      case 0x04: //above_equal
        __ sltu(AT, op1, AT);
        if(&L)
          __ beq(AT, R0, L);
        else
                __ beq(AT, R0, (int)0);
        break;
      case 0x05: //below
        __ sltu(AT, op1, AT);
        if(&L)
           __ bne(R0, AT, L);
        else
           __ bne(R0, AT, (int)0);
        break;
      case 0x06: //below_equal
        __ sltu(AT, AT, op1);
        if(&L)
          __ beq(AT, R0, L);
        else
          __ beq(AT, R0, (int)0);
       break;
      default:
        Unimplemented();
    }
    __ delayed()->nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConI_reg_reg_short(cmpOp cmp, mRegI src1, mRegI src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_reg_short" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = $src2$$Register;
    Label     &L = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, op2, L);
        else
          __ beq(op1, op2, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, op2, L);
        else
          __ bne(op1, op2, (int)0);
        break;
      case 0x03: //above
        __ slt(AT, op2, op1);
        if(&L)
          __ bne(R0, AT, L);
        else
                __ bne(R0, AT, (int)0);
        break;
      case 0x04: //above_equal
        __ slt(AT, op1, op2);
        if(&L)
          __ beq(AT, R0, L);
        else
                __ beq(AT, R0, (int)0);
        break;
      case 0x05: //below
        __ slt(AT, op1, op2);
        if(&L)
           __ bne(R0, AT, L);
        else
           __ bne(R0, AT, (int)0);
        break;
      case 0x06: //below_equal
        __ slt(AT, op2, op1);
        if(&L)
          __ beq(AT, R0, L);
        else
          __ beq(AT, R0, (int)0);
       break;
      default:
        Unimplemented();
    }
    __ delayed()->nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConI_reg_immI_0_short(cmpOp cmp, mRegI src1, immI_0 src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  ins_cost(170);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_immI_0_short" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Label     &L =  *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, R0, L);
        else
          __ beq(op1, R0, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, R0, L);
        else
          __ bne(op1, R0, (int)0);
        break;
      case 0x03: //greater
        if(&L)
               __ bgtz(op1, L);
        else
               __ bgtz(op1, (int)0);
        break;
      case 0x04: //greater_equal
        if(&L)
               __ bgez(op1, L);
        else
               __ bgez(op1, (int)0);
        break;
      case 0x05: //less
        if(&L)
                __ bltz(op1, L);
        else
                __ bltz(op1, (int)0);
        break;
      case 0x06: //less_equal
        if(&L)
               __ blez(op1, L);
        else
               __ blez(op1, (int)0);
       break;
      default:
        Unimplemented();
    }
    __ delayed()->nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}


instruct branchConI_reg_imm_short(cmpOp cmp, mRegI src1, immI src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  ins_cost(200);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_imm_short" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    int      val = $src2$$constant;
    Label     &L =  *($labl$$label);
    int     flag = $cmp$$cmpcode;

    __ move(AT, val);
    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, AT, L);
        else
          __ beq(op1, AT, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, AT, L);
        else
          __ bne(op1, AT, (int)0);
        break;
      case 0x03: //greater
        __ slt(AT, AT, op1);
        if(&L)
          __ bne(R0, AT, L);
        else
                __ bne(R0, AT, (int)0);
        break;
      case 0x04: //greater_equal
        __ slt(AT, op1, AT);
        if(&L)
          __ beq(AT, R0, L);
        else
                __ beq(AT, R0, (int)0);
        break;
      case 0x05: //less
        __ slt(AT, op1, AT);
        if(&L)
           __ bne(R0, AT, L);
        else
           __ bne(R0, AT, (int)0);
        break;
      case 0x06: //less_equal
        __ slt(AT, AT, op1);
        if(&L)
          __ beq(AT, R0, L);
        else
          __ beq(AT, R0, (int)0);
       break;
      default:
          Unimplemented();
    }
    __ delayed()->nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConIU_reg_immI_0_short(cmpOpU cmp, mRegI src1, immI_0 zero, label labl) %{
  match( If cmp (CmpU src1 zero) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, zero, $labl #@branchConIU_reg_immI_0_short" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Label     &L = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, R0, L);
        else
          __ beq(op1, R0, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, R0, L);
        else
          __ bne(op1, R0, (int)0);
        break;
      case 0x03: //above
        if(&L)
          __ bne(R0, op1, L);
        else
          __ bne(R0, op1, (int)0);
        break;
      case 0x04: //above_equal
        if(&L)
          __ beq(R0, R0, L);
        else
          __ beq(R0, R0, (int)0);
        break;
      case 0x05: //below
        return;
        break;
      case 0x06: //below_equal
        if(&L)
          __ beq(op1, R0, L);
        else
          __ beq(op1, R0, (int)0);
        break;
      default:
        Unimplemented();
    }
    __ delayed()->nop();
    %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}


instruct branchConIU_reg_immI16_short(cmpOpU cmp, mRegI src1, immI16 src2, label labl) %{
  match( If cmp (CmpU src1 src2) );
  effect(USE labl);
  ins_cost(180);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConIU_reg_immI16_short" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    int      val = $src2$$constant;
    Label     &L = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ move(AT, val);
        if (&L)
          __ beq(op1, AT, L);
        else
          __ beq(op1, AT, (int)0);
        break;
      case 0x02: //not_equal
        __ move(AT, val);
        if (&L)
          __ bne(op1, AT, L);
        else
          __ bne(op1, AT, (int)0);
        break;
      case 0x03: //above
        __ move(AT, val);
        __ sltu(AT, AT, op1);
        if(&L)
          __ bne(R0, AT, L);
        else
          __ bne(R0, AT, (int)0);
        break;
      case 0x04: //above_equal
        __ sltiu(AT, op1, val);
        if(&L)
          __ beq(AT, R0, L);
        else
          __ beq(AT, R0, (int)0);
        break;
      case 0x05: //below
        __ sltiu(AT, op1, val);
        if(&L)
          __ bne(R0, AT, L);
        else
          __ bne(R0, AT, (int)0);
        break;
      case 0x06: //below_equal
        __ move(AT, val);
        __ sltu(AT, AT, op1);
        if(&L)
          __ beq(AT, R0, L);
        else
          __ beq(AT, R0, (int)0);
        break;
      default:
        Unimplemented();
    }
    __ delayed()->nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}


instruct branchConL_regL_regL_short(cmpOp cmp, mRegL src1, mRegL src2, label labl) %{
  match( If cmp (CmpL src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConL_regL_regL_short" %}
  ins_cost(250);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = as_Register($src2$$reg);

    Label   &target = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&target)
          __ beq(opr1_reg, opr2_reg, target);
        else
          __ beq(opr1_reg, opr2_reg, (int)0);
        __ delayed()->nop();
        break;

      case 0x02: //not_equal
        if(&target)
          __ bne(opr1_reg, opr2_reg, target);
        else
          __ bne(opr1_reg, opr2_reg, (int)0);
        __ delayed()->nop();
        break;

      case 0x03: //greater
        __ slt(AT, opr2_reg, opr1_reg);
        if(&target)
          __ bne(AT, R0, target);
        else
          __ bne(AT, R0, (int)0);
        __ delayed()->nop();
        break;

      case 0x04: //greater_equal
        __ slt(AT, opr1_reg, opr2_reg);
        if(&target)
          __ beq(AT, R0, target);
        else
          __ beq(AT, R0, (int)0);
        __ delayed()->nop();

        break;

      case 0x05: //less
        __ slt(AT, opr1_reg, opr2_reg);
        if(&target)
          __ bne(AT, R0, target);
        else
          __ bne(AT, R0, (int)0);
        __ delayed()->nop();

        break;

      case 0x06: //less_equal
        __ slt(AT, opr2_reg, opr1_reg);

        if(&target)
          __ beq(AT, R0, target);
        else
          __ beq(AT, R0, (int)0);
        __ delayed()->nop();

        break;

      default:
        Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}


instruct branchConL_regL_immL_0_short(cmpOp cmp, mRegL src1, immL_0 zero, label labl) %{
  match( If cmp (CmpL src1 zero) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, zero, $labl #@branchConL_regL_immL_0_short" %}
  ins_cost(150);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Label   &target = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&target)
           __ beq(opr1_reg, R0, target);
        else
           __ beq(opr1_reg, R0, int(0));
        break;

      case 0x02: //not_equal
        if(&target)
           __ bne(opr1_reg, R0, target);
        else
           __ bne(opr1_reg, R0, (int)0);
        break;

      case 0x03: //greater
        if(&target)
           __ bgtz(opr1_reg, target);
        else
           __ bgtz(opr1_reg, (int)0);
       break;

      case 0x04: //greater_equal
        if(&target)
           __ bgez(opr1_reg, target);
        else
           __ bgez(opr1_reg, (int)0);
        break;

      case 0x05: //less
        __ slt(AT, opr1_reg, R0);
        if(&target)
           __ bne(AT, R0, target);
        else
           __ bne(AT, R0, (int)0);
        break;

      case 0x06: //less_equal
        if (&target)
           __ blez(opr1_reg, target);
        else
           __ blez(opr1_reg, int(0));
        break;

      default:
          Unimplemented();
    }
    __ delayed()->nop();
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConL_regL_immL_short(cmpOp cmp, mRegL src1, immL src2, label labl) %{
  match( If cmp (CmpL src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConL_regL_immL_short" %}
  ins_cost(180);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = AT;

    Label   &target = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    __ set64(opr2_reg, $src2$$constant);

    switch(flag) {
      case 0x01: //equal
        if (&target)
          __ beq(opr1_reg, opr2_reg, target);
        else
          __ beq(opr1_reg, opr2_reg, (int)0);
        break;

      case 0x02: //not_equal
        if(&target)
          __ bne(opr1_reg, opr2_reg, target);
        else
          __ bne(opr1_reg, opr2_reg, (int)0);
        break;

      case 0x03: //greater
        __ slt(AT, opr2_reg, opr1_reg);
        if(&target)
          __ bne(AT, R0, target);
        else
          __ bne(AT, R0, (int)0);
        break;

      case 0x04: //greater_equal
        __ slt(AT, opr1_reg, opr2_reg);
        if(&target)
          __ beq(AT, R0, target);
        else
          __ beq(AT, R0, (int)0);
        break;

      case 0x05: //less
        __ slt(AT, opr1_reg, opr2_reg);
        if(&target)
          __ bne(AT, R0, target);
        else
          __ bne(AT, R0, (int)0);
        break;

      case 0x06: //less_equal
        __ slt(AT, opr2_reg, opr1_reg);
        if(&target)
          __ beq(AT, R0, target);
        else
          __ beq(AT, R0, (int)0);
        break;

      default:
        Unimplemented();
    }
    __ delayed()->nop();
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}


//FIXME
instruct branchConF_reg_reg_short(cmpOp cmp, regF src1, regF src2, label labl) %{
  match( If cmp (CmpF src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConF_reg_reg_short" %}

  ins_encode %{
    FloatRegister reg_op1 = $src1$$FloatRegister;
    FloatRegister reg_op2 = $src2$$FloatRegister;
    Label& L = *($labl$$label);
    int flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: // equal
        __ c_eq_s(reg_op1, reg_op2);
        if (&L)
          __ bc1t(L);
        else
          __ bc1t((int)0);
        break;
      case 0x02: // not_equal
        __ c_eq_s(reg_op1, reg_op2);
        if (&L)
          __ bc1f(L);
        else
          __ bc1f((int)0);
        break;
      case 0x03: // greater
        __ c_ule_s(reg_op1, reg_op2);
        if(&L)
          __ bc1f(L);
        else
          __ bc1f((int)0);
        break;
      case 0x04: // greater_equal
        __ c_ult_s(reg_op1, reg_op2);
        if(&L)
          __ bc1f(L);
        else
          __ bc1f((int)0);
        break;
      case 0x05: // less
        __ c_ult_s(reg_op1, reg_op2);
        if(&L)
          __ bc1t(L);
        else
          __ bc1t((int)0);
        break;
      case 0x06: // less_equal
        __ c_ule_s(reg_op1, reg_op2);
        if(&L)
          __ bc1t(L);
        else
          __ bc1t((int)0);
        break;
      default:
        Unimplemented();
    }
    __ delayed()->nop();
  %}

  ins_pc_relative(1);
  ins_pipe(pipe_fpu_branch);
  ins_short_branch(1);
%}

instruct branchConD_reg_reg_short(cmpOp cmp, regD src1, regD src2, label labl) %{
  match( If cmp (CmpD src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConD_reg_reg_short" %}

  ins_encode %{
    FloatRegister reg_op1 = $src1$$FloatRegister;
    FloatRegister reg_op2 = $src2$$FloatRegister;
    Label& L = *($labl$$label);
    int flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: // equal
        __ c_eq_d(reg_op1, reg_op2);
        if (&L)
          __ bc1t(L);
        else
          __ bc1t((int)0);
        break;
      case 0x02: // not_equal
        // c_ueq_d cannot distinguish NaN from equal. Double.isNaN(Double) is implemented by 'f != f', so the use of c_ueq_d causes bugs.
        __ c_eq_d(reg_op1, reg_op2);
        if (&L)
          __ bc1f(L);
        else
          __ bc1f((int)0);
        break;
      case 0x03: // greater
        __ c_ule_d(reg_op1, reg_op2);
        if(&L)
          __ bc1f(L);
        else
          __ bc1f((int)0);
        break;
      case 0x04: // greater_equal
        __ c_ult_d(reg_op1, reg_op2);
        if(&L)
          __ bc1f(L);
        else
          __ bc1f((int)0);
        break;
      case 0x05: // less
        __ c_ult_d(reg_op1, reg_op2);
        if(&L)
          __ bc1t(L);
        else
          __ bc1t((int)0);
        break;
      case 0x06: // less_equal
        __ c_ule_d(reg_op1, reg_op2);
        if(&L)
          __ bc1t(L);
        else
          __ bc1t((int)0);
        break;
      default:
        Unimplemented();
    }
    __ delayed()->nop();
  %}

  ins_pc_relative(1);
  ins_pipe(pipe_fpu_branch);
  ins_short_branch(1);
%}

// =================== End of branch instructions ==========================

// Call Runtime Instruction
instruct CallRuntimeDirect(method meth) %{
  match(CallRuntime );
  effect(USE meth);

  ins_cost(300);
  format %{ "CALL,runtime #@CallRuntimeDirect" %}
  ins_encode( Java_To_Runtime( meth ) );
  ins_pipe( pipe_slow );
  ins_alignment(16);
%}



//------------------------MemBar Instructions-------------------------------
//Memory barrier flavors

instruct membar_acquire() %{
  match(MemBarAcquire);
  ins_cost(400);

  format %{ "MEMBAR-acquire @ membar_acquire" %}
  ins_encode %{
    __ sync();
  %}
  ins_pipe(empty);
%}

instruct load_fence() %{
  match(LoadFence);
  ins_cost(400);

  format %{ "MEMBAR @ load_fence" %}
  ins_encode %{
    __ sync();
  %}
  ins_pipe(pipe_slow);
%}

instruct membar_acquire_lock()
%{
  match(MemBarAcquireLock);
  ins_cost(0);

  size(0);
  format %{ "MEMBAR-acquire (acquire as part of CAS in prior FastLock so empty encoding) @ membar_acquire_lock" %}
  ins_encode();
  ins_pipe(empty);
%}

instruct membar_release() %{
  match(MemBarRelease);
  ins_cost(400);

  format %{ "MEMBAR-release @ membar_release" %}

  ins_encode %{
    // Attention: DO NOT DELETE THIS GUY!
    __ sync();
  %}

  ins_pipe(pipe_slow);
%}

instruct store_fence() %{
  match(StoreFence);
  ins_cost(400);

  format %{ "MEMBAR @ store_fence" %}

  ins_encode %{
    __ sync();
  %}

  ins_pipe(pipe_slow);
%}

instruct membar_release_lock()
%{
  match(MemBarReleaseLock);
  ins_cost(0);

  size(0);
  format %{ "MEMBAR-release-lock (release in FastUnlock so empty) @ membar_release_lock" %}
  ins_encode();
  ins_pipe(empty);
%}


instruct membar_volatile() %{
  match(MemBarVolatile);
  ins_cost(400);

  format %{ "MEMBAR-volatile" %}
  ins_encode %{
    if( !os::is_MP() ) return;     // Not needed on single CPU
    __ sync();

  %}
  ins_pipe(pipe_slow);
%}

instruct unnecessary_membar_volatile() %{
  match(MemBarVolatile);
  predicate(Matcher::post_store_load_barrier(n));
  ins_cost(0);

  size(0);
  format %{ "MEMBAR-volatile (unnecessary so empty encoding) @ unnecessary_membar_volatile" %}
  ins_encode( );
  ins_pipe(empty);
%}

instruct membar_storestore() %{
  match(MemBarStoreStore);

  ins_cost(400);
  format %{ "MEMBAR-storestore @ membar_storestore" %}
  ins_encode %{
    __ sync();
  %}
  ins_pipe(empty);
%}

//----------Move Instructions--------------------------------------------------
instruct castX2P(mRegP dst, mRegL src) %{
  match(Set dst (CastX2P src));
  format %{ "castX2P  $dst, $src @ castX2P" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

  if(src != dst)
    __ move(dst, src);
  %}
  ins_cost(10);
  ins_pipe( ialu_regI_mov );
%}

instruct castP2X(mRegL dst, mRegP src ) %{
  match(Set dst (CastP2X src));

  format %{ "mov    $dst, $src\t  #@castP2X" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

  if(src != dst)
    __ move(dst, src);
  %}
  ins_pipe( ialu_regI_mov );
%}

instruct MoveF2I_reg_reg(mRegI dst, regF src) %{
  match(Set dst (MoveF2I src));
  effect(DEF dst, USE src);
  ins_cost(85);
  format %{ "MoveF2I   $dst, $src @ MoveF2I_reg_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);

    __ mfc1(dst, src);
  %}
  ins_pipe( pipe_slow );
%}

instruct MoveI2F_reg_reg(regF dst, mRegI src) %{
  match(Set dst (MoveI2F src));
  effect(DEF dst, USE src);
  ins_cost(85);
  format %{ "MoveI2F   $dst, $src @ MoveI2F_reg_reg" %}
  ins_encode %{
    Register src = as_Register($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ mtc1(src, dst);
  %}
  ins_pipe( pipe_slow );
%}

instruct MoveD2L_reg_reg(mRegL dst, regD src) %{
  match(Set dst (MoveD2L src));
  effect(DEF dst, USE src);
  ins_cost(85);
  format %{ "MoveD2L   $dst, $src @ MoveD2L_reg_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);

    __ dmfc1(dst, src);
  %}
  ins_pipe( pipe_slow );
%}

instruct MoveL2D_reg_reg(regD dst, mRegL src) %{
  match(Set dst (MoveL2D src));
  effect(DEF dst, USE src);
  ins_cost(85);
  format %{ "MoveL2D   $dst, $src @ MoveL2D_reg_reg" %}
  ins_encode %{
    FloatRegister dst = as_FloatRegister($dst$$reg);
    Register src = as_Register($src$$reg);

    __ dmtc1(src, dst);
  %}
  ins_pipe( pipe_slow );
%}

//----------Conditional Move---------------------------------------------------
// Conditional move
instruct cmovI_cmpI_reg_reg(mRegI dst, mRegI src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovI_cmpI_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovI_cmpI_reg_reg"
         %}

  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovI_cmpP_reg_reg(mRegI dst, mRegI src, mRegP tmp1, mRegP tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpP tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovI_cmpP_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovI_cmpP_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovI_cmpN_reg_reg(mRegI dst, mRegI src, mRegN tmp1, mRegN tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpN tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovI_cmpN_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovI_cmpN_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpU_reg_reg(mRegP dst, mRegP src, mRegI tmp1, mRegI tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpU tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovP_cmpU_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovP_cmpU_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpF_reg_reg(mRegP dst, mRegP src, regF tmp1, regF tmp2, cmpOp cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpF tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovP_cmpF_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovP_cmpF_reg_reg"
         %}

  ins_encode %{
    FloatRegister reg_op1 = $tmp1$$FloatRegister;
    FloatRegister reg_op2 = $tmp2$$FloatRegister;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_float */);
  %}
  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpN_reg_reg(mRegP dst, mRegP src, mRegN tmp1, mRegN tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpN tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovP_cmpN_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovP_cmpN_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovN_cmpP_reg_reg(mRegN dst, mRegN src, mRegP tmp1, mRegP tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveN (Binary cop (CmpP tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovN_cmpP_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovN_cmpP_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpD_reg_reg(mRegP dst, mRegP src, regD tmp1, regD tmp2, cmpOp cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpD tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovP_cmpD_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovP_cmpD_reg_reg"
         %}
  ins_encode %{
    FloatRegister reg_op1 = as_FloatRegister($tmp1$$reg);
    FloatRegister reg_op2 = as_FloatRegister($tmp2$$reg);
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);
    int flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_float */);
  %}

  ins_pipe( pipe_slow );
%}


instruct cmovN_cmpN_reg_reg(mRegN dst, mRegN src, mRegN tmp1, mRegN tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveN (Binary cop (CmpN tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovN_cmpN_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovN_cmpN_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}


instruct cmovI_cmpU_reg_reg(mRegI dst, mRegI src, mRegI tmp1, mRegI tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpU tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovI_cmpU_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovI_cmpU_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovI_cmpL_reg_reg(mRegI dst, mRegI src, mRegL tmp1, mRegL tmp2, cmpOp cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpL tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovI_cmpL_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovI_cmpL_reg_reg"
         %}
  ins_encode %{
    Register opr1 = as_Register($tmp1$$reg);
    Register opr2 = as_Register($tmp2$$reg);
    Register dst     = $dst$$Register;
    Register src     = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(opr1, opr2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpL_reg_reg(mRegP dst, mRegP src, mRegL tmp1, mRegL tmp2, cmpOp cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpL tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovP_cmpL_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovP_cmpL_reg_reg"
         %}
  ins_encode %{
    Register opr1 = as_Register($tmp1$$reg);
    Register opr2 = as_Register($tmp2$$reg);
    Register dst     = $dst$$Register;
    Register src     = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(opr1, opr2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovI_cmpD_reg_reg(mRegI dst, mRegI src, regD tmp1, regD tmp2, cmpOp cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpD tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovI_cmpD_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovI_cmpD_reg_reg"
         %}
  ins_encode %{
    FloatRegister reg_op1 = as_FloatRegister($tmp1$$reg);
    FloatRegister reg_op2 = as_FloatRegister($tmp2$$reg);
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);
    int flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_float */);
  %}

  ins_pipe( pipe_slow );
%}


instruct cmovP_cmpP_reg_reg(mRegP dst, mRegP src, mRegP tmp1, mRegP tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpP tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovP_cmpP_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovP_cmpP_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpI_reg_reg(mRegP dst, mRegP src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop $tmp1,$tmp2\t @cmovP_cmpI_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovP_cmpI_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovL_cmpP_reg_reg(mRegL dst, mRegL src, mRegP tmp1, mRegP tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpP tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovL_cmpP_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovL_cmpP_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovN_cmpU_reg_reg(mRegN dst, mRegN src, mRegI tmp1, mRegI tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveN (Binary cop (CmpU tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovN_cmpU_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovN_cmpU_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovN_cmpL_reg_reg(mRegN dst, mRegN src, mRegL tmp1, mRegL tmp2, cmpOp cop) %{
  match(Set dst (CMoveN (Binary cop (CmpL tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovN_cmpL_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovN_cmpL_reg_reg"
         %}
  ins_encode %{
    Register opr1 = as_Register($tmp1$$reg);
    Register opr2 = as_Register($tmp2$$reg);
    Register dst  = $dst$$Register;
    Register src  = $src$$Register;
    int     flag  = $cop$$cmpcode;

    __ cmp_cmov(opr1, opr2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovN_cmpI_reg_reg(mRegN dst, mRegN src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveN (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop $tmp1,$tmp2\t @cmovN_cmpI_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovN_cmpI_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovL_cmpU_reg_reg(mRegL dst, mRegL src, mRegI tmp1, mRegI tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpU tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovL_cmpU_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovL_cmpU_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovL_cmpF_reg_reg(mRegL dst, mRegL src, regF tmp1, regF tmp2, cmpOp cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpF tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovL_cmpF_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovL_cmpF_reg_reg"
         %}

  ins_encode %{
    FloatRegister reg_op1 = $tmp1$$FloatRegister;
    FloatRegister reg_op2 = $tmp2$$FloatRegister;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_float */);
  %}
  ins_pipe( pipe_slow );
%}

instruct cmovL_cmpI_reg_reg(mRegL dst, mRegL src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovL_cmpI_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovL_cmpI_reg_reg"
         %}

  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovL_cmpL_reg_reg(mRegL dst, mRegL src, mRegL tmp1, mRegL tmp2, cmpOp cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpL tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovL_cmpL_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovL_cmpL_reg_reg"
         %}
  ins_encode %{
    Register opr1 = as_Register($tmp1$$reg);
    Register opr2 = as_Register($tmp2$$reg);
    Register dst  = as_Register($dst$$reg);
    Register src  = as_Register($src$$reg);
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(opr1, opr2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovL_cmpN_reg_reg(mRegL dst, mRegL src, mRegN tmp1, mRegN tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpN tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovL_cmpN_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovL_cmpN_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}


instruct cmovL_cmpD_reg_reg(mRegL dst, mRegL src, regD tmp1, regD tmp2, cmpOp cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpD tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovL_cmpD_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovL_cmpD_reg_reg"
         %}
  ins_encode %{
    FloatRegister reg_op1 = as_FloatRegister($tmp1$$reg);
    FloatRegister reg_op2 = as_FloatRegister($tmp2$$reg);
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);
    int flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_float */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovD_cmpD_reg_reg(regD dst, regD src, regD tmp1, regD tmp2, cmpOp cop ) %{
  match(Set dst (CMoveD (Binary cop (CmpD tmp1 tmp2)) (Binary dst src)));
  ins_cost(200);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovD_cmpD_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovD_cmpD_reg_reg"
         %}
  ins_encode %{
    FloatRegister reg_op1 = as_FloatRegister($tmp1$$reg);
    FloatRegister reg_op2 = as_FloatRegister($tmp2$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);
    int flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_float */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovF_cmpI_reg_reg(regF dst, regF src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveF (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(200);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovF_cmpI_reg_reg\n"
             "\tCMOV  $dst, $src \t @cmovF_cmpI_reg_reg"
         %}

  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    FloatRegister dst = as_FloatRegister($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_float */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovD_cmpI_reg_reg(regD dst, regD src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveD (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(200);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovD_cmpI_reg_reg\n"
             "\tCMOV  $dst, $src \t @cmovD_cmpI_reg_reg"
         %}

  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    FloatRegister dst = as_FloatRegister($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_float */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovD_cmpP_reg_reg(regD dst, regD src, mRegP tmp1, mRegP tmp2, cmpOp cop ) %{
  match(Set dst (CMoveD (Binary cop (CmpP tmp1 tmp2)) (Binary dst src)));
  ins_cost(200);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovD_cmpP_reg_reg\n"
             "\tCMOV  $dst, $src \t @cmovD_cmpP_reg_reg"
         %}

  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    FloatRegister dst = as_FloatRegister($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_float */);
  %}

  ins_pipe( pipe_slow );
%}

//FIXME
instruct cmovI_cmpF_reg_reg(mRegI dst, mRegI src, regF tmp1, regF tmp2, cmpOp cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpF tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovI_cmpF_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovI_cmpF_reg_reg"
         %}

  ins_encode %{
    FloatRegister reg_op1 = $tmp1$$FloatRegister;
    FloatRegister reg_op2 = $tmp2$$FloatRegister;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_float */);
  %}
  ins_pipe( pipe_slow );
%}

instruct cmovF_cmpF_reg_reg(regF dst, regF src, regF tmp1, regF tmp2, cmpOp cop ) %{
  match(Set dst (CMoveF (Binary cop (CmpF tmp1 tmp2)) (Binary dst src)));
  ins_cost(200);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovF_cmpF_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovF_cmpF_reg_reg"
         %}

  ins_encode %{
    FloatRegister reg_op1 = $tmp1$$FloatRegister;
    FloatRegister reg_op2 = $tmp2$$FloatRegister;
    FloatRegister dst = $dst$$FloatRegister;
    FloatRegister src = $src$$FloatRegister;
    int flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_float */);
  %}
  ins_pipe( pipe_slow );
%}

// Manifest a CmpL result in an integer register.  Very painful.
// This is the test to avoid.
instruct cmpL3_reg_reg(mRegI dst, mRegL src1, mRegL src2) %{
  match(Set dst (CmpL3 src1 src2));
  ins_cost(1000);
  format %{ "cmpL3  $dst, $src1, $src2 @ cmpL3_reg_reg" %}
  ins_encode %{
    Register opr1 = as_Register($src1$$reg);
    Register opr2 = as_Register($src2$$reg);
    Register dst  = as_Register($dst$$reg);

    Label Done;

    __ subu(AT, opr1, opr2);
    __ bltz(AT, Done);
    __ delayed()->daddiu(dst, R0, -1);

    __ move(dst, 1);
    __ movz(dst, R0, AT);

    __ bind(Done);
  %}
  ins_pipe( pipe_slow );
%}

//
// less_rsult     = -1
// greater_result =  1
// equal_result   =  0
// nan_result     = -1
//
instruct cmpF3_reg_reg(mRegI dst, regF src1, regF src2) %{
  match(Set dst (CmpF3 src1 src2));
  ins_cost(1000);
  format %{ "cmpF3  $dst, $src1, $src2 @ cmpF3_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    Register dst = as_Register($dst$$reg);

    Label Done;

    __ c_ult_s(src1, src2);
    __ bc1t(Done);
    __ delayed()->daddiu(dst, R0, -1);

    __ c_eq_s(src1, src2);
    __ move(dst, 1);
    __ movt(dst, R0);

    __ bind(Done);
  %}
  ins_pipe( pipe_slow );
%}

instruct cmpD3_reg_reg(mRegI dst, regD src1, regD src2) %{
  match(Set dst (CmpD3 src1 src2));
  ins_cost(1000);
  format %{ "cmpD3  $dst, $src1, $src2 @ cmpD3_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    Register dst = as_Register($dst$$reg);

    Label Done;

    __ c_ult_d(src1, src2);
    __ bc1t(Done);
    __ delayed()->daddiu(dst, R0, -1);

    __ c_eq_d(src1, src2);
    __ move(dst, 1);
    __ movt(dst, R0);

    __ bind(Done);
  %}
  ins_pipe( pipe_slow );
%}

instruct clear_array(mRegL cnt, mRegP base, Universe dummy) %{
  match(Set dummy (ClearArray cnt base));
  format %{ "CLEAR_ARRAY base = $base, cnt = $cnt # Clear doublewords" %}
  ins_encode %{
    //Assume cnt is the number of bytes in an array to be cleared,
    //and base points to the starting address of the array.
    Register base = $base$$Register;
    Register num  = $cnt$$Register;
    Label Loop, done;

    __ beq(num, R0, done);
    __ delayed()->daddu(AT, base, R0);

    __ move(T9, num);  /* T9 = words */

    __ bind(Loop);
    __ sd(R0, AT, 0);
    __ daddiu(T9, T9, -1);
    __ bne(T9, R0, Loop);
    __ delayed()->daddiu(AT, AT, wordSize);

    __ bind(done);
  %}
  ins_pipe( pipe_slow );
%}

instruct string_compare(a4_RegP str1, mA5RegI cnt1, a6_RegP str2,  mA7RegI cnt2, no_Ax_mRegI result) %{
  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
  effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2);

  format %{ "String Compare $str1[len: $cnt1], $str2[len: $cnt2] -> $result @ string_compare" %}
  ins_encode %{
    // Get the first character position in both strings
    //         [8] char array, [12] offset, [16] count
    Register str1   = $str1$$Register;
    Register str2   = $str2$$Register;
    Register cnt1   = $cnt1$$Register;
    Register cnt2   = $cnt2$$Register;
    Register result = $result$$Register;

    Label L, Loop, haveResult, done;

   // compute the and difference of lengths (in result)
   __ subu(result, cnt1, cnt2); // result holds the difference of two lengths

   // compute the shorter length (in cnt1)
   __ slt(AT, cnt2, cnt1);
   __ movn(cnt1, cnt2, AT);

   // Now the shorter length is in cnt1 and cnt2 can be used as a tmp register
   __ bind(Loop);                        // Loop begin
   __ beq(cnt1, R0, done);
   __ delayed()->lhu(AT, str1, 0);;

   // compare current character
   __ lhu(cnt2, str2, 0);
   __ bne(AT, cnt2, haveResult);
   __ delayed()->addiu(str1, str1, 2);
   __ addiu(str2, str2, 2);
   __ b(Loop);
   __ delayed()->addiu(cnt1, cnt1, -1);   // Loop end

   __ bind(haveResult);
   __ subu(result, AT, cnt2);

   __ bind(done);
  %}

  ins_pipe( pipe_slow );
%}

// intrinsic optimization
instruct string_equals(a4_RegP str1, a5_RegP str2, mA6RegI cnt, mA7RegI temp, no_Ax_mRegI result) %{
  match(Set result (StrEquals (Binary str1 str2) cnt));
  effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL temp);

  format %{ "String Equal $str1, $str2, len:$cnt  tmp:$temp -> $result @ string_equals" %}
  ins_encode %{
    // Get the first character position in both strings
    //         [8] char array, [12] offset, [16] count
    Register str1   = $str1$$Register;
    Register str2   = $str2$$Register;
    Register cnt    = $cnt$$Register;
    Register tmp    = $temp$$Register;
    Register result = $result$$Register;

    Label Loop, True, False;

    __ beq(str1, str2, True);  // same char[] ?
    __ delayed()->daddiu(result, R0, 1);

    __ beq(cnt, R0, True);
    __ delayed()->nop(); // count == 0

    __ bind(Loop);

    // compare current character
    __ lhu(AT, str1, 0);
    __ lhu(tmp, str2, 0);
    __ bne(AT, tmp, False);
    __ delayed()->addiu(str1, str1, 2);
    __ addiu(cnt, cnt, -1);
    __ bne(cnt, R0, Loop);
    __ delayed()->addiu(str2, str2, 2);

    __ b(True);
    __ delayed()->nop();

    __ bind(False);
    __ daddiu(result, R0, 0);

    __ bind(True);
  %}

  ins_pipe( pipe_slow );
%}

//----------Arithmetic Instructions-------------------------------------------
//----------Addition Instructions---------------------------------------------
instruct addI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (AddI src1 src2));

  format %{ "addu   $dst, $src1, $src2 #@addI_Reg_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ addu32(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct addI_Reg_imm(mRegI dst, mRegI src1,  immI src2) %{
  match(Set dst (AddI src1 src2));

  format %{ "addu    $dst, $src1, $src2 #@addI_Reg_imm" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    int       imm = $src2$$constant;

    if(Assembler::is_simm16(imm)) {
       __ addiu32(dst, src1, imm);
    } else {
       __ move(AT, imm);
       __ addu32(dst, src1, AT);
    }
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct addP_reg_reg(mRegP dst, mRegP src1, mRegL src2) %{
  match(Set dst (AddP src1 src2));

  format %{ "daddu    $dst, $src1, $src2 #@addP_reg_reg" %}

  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ daddu(dst, src1, src2);
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct addP_reg_reg_convI2L(mRegP dst, mRegP src1, mRegI src2) %{
  match(Set dst (AddP src1 (ConvI2L src2)));

  format %{ "daddu    $dst, $src1, $src2 #@addP_reg_reg_convI2L" %}

  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ daddu(dst, src1, src2);
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct addP_reg_imm(mRegP dst, mRegP src1,  immL src2) %{
  match(Set dst (AddP src1 src2));

  format %{ "daddiu   $dst, $src1, $src2 #@addP_reg_imm" %}
  ins_encode %{
    Register src1 = $src1$$Register;
    long      src2 = $src2$$constant;
    Register  dst = $dst$$Register;

    if(Assembler::is_simm16(src2)) {
       __ daddiu(dst, src1, src2);
    } else {
       __ set64(AT, src2);
       __ daddu(dst, src1, AT);
    }
  %}
  ins_pipe( ialu_regI_imm16 );
%}

// Add Long Register with Register
instruct addL_Reg_Reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (AddL src1 src2));
  ins_cost(200);
  format %{ "ADD    $dst, $src1, $src2 #@addL_Reg_Reg\t" %}

  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    Register src2_reg = as_Register($src2$$reg);

    __ daddu(dst_reg, src1_reg, src2_reg);
  %}

  ins_pipe( ialu_regL_regL );
%}

instruct addL_Reg_imm(mRegL dst, mRegL src1, immL16 src2)
%{
  match(Set dst (AddL src1 src2));

  format %{ "ADD    $dst, $src1, $src2 #@addL_Reg_imm " %}
  ins_encode %{
    Register dst_reg  = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    int      src2_imm = $src2$$constant;

    __ daddiu(dst_reg, src1_reg, src2_imm);
  %}

  ins_pipe( ialu_regL_regL );
%}

instruct addL_RegI2L_imm(mRegL dst, mRegI src1, immL16 src2)
%{
  match(Set dst (AddL (ConvI2L src1) src2));

  format %{ "ADD    $dst, $src1, $src2 #@addL_RegI2L_imm " %}
  ins_encode %{
    Register dst_reg  = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    int      src2_imm = $src2$$constant;

    __ daddiu(dst_reg, src1_reg, src2_imm);
  %}

  ins_pipe( ialu_regL_regL );
%}

instruct addL_RegI2L_Reg(mRegL dst, mRegI src1, mRegL src2) %{
  match(Set dst (AddL (ConvI2L src1) src2));
  ins_cost(200);
  format %{ "ADD    $dst, $src1, $src2 #@addL_RegI2L_Reg\t" %}

  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    Register src2_reg = as_Register($src2$$reg);

    __ daddu(dst_reg, src1_reg, src2_reg);
  %}

  ins_pipe( ialu_regL_regL );
%}

instruct addL_RegI2L_RegI2L(mRegL dst, mRegI src1, mRegI src2) %{
  match(Set dst (AddL (ConvI2L src1) (ConvI2L src2)));
  ins_cost(200);
  format %{ "ADD    $dst, $src1, $src2 #@addL_RegI2L_RegI2L\t" %}

  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    Register src2_reg = as_Register($src2$$reg);

    __ daddu(dst_reg, src1_reg, src2_reg);
  %}

  ins_pipe( ialu_regL_regL );
%}

instruct addL_Reg_RegI2L(mRegL dst, mRegL src1, mRegI src2) %{
  match(Set dst (AddL src1 (ConvI2L src2)));
  ins_cost(200);
  format %{ "ADD    $dst, $src1, $src2 #@addL_Reg_RegI2L\t" %}

  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    Register src2_reg = as_Register($src2$$reg);

    __ daddu(dst_reg, src1_reg, src2_reg);
  %}

  ins_pipe( ialu_regL_regL );
%}

//----------Subtraction Instructions-------------------------------------------
// Integer Subtraction Instructions
instruct subI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (SubI src1 src2));
  ins_cost(100);

  format %{ "subu    $dst, $src1, $src2 #@subI_Reg_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ subu32(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct subI_Reg_immI_M32767_32768(mRegI dst, mRegI src1,  immI_M32767_32768 src2) %{
  match(Set dst (SubI src1 src2));
  ins_cost(80);

  format %{ "subu    $dst, $src1, $src2 #@subI_Reg_immI_M32767_32768" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    __ addiu32(dst, src1, -1 * $src2$$constant);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct negI_Reg(mRegI dst, immI_0 zero,  mRegI src) %{
  match(Set dst (SubI zero src));
  ins_cost(80);

  format %{ "neg    $dst, $src #@negI_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register  src = $src$$Register;
    __ subu32(dst, R0, src);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct negL_Reg(mRegL dst, immL_0 zero,  mRegL src) %{
  match(Set dst (SubL zero src));
  ins_cost(80);

  format %{ "neg    $dst, $src #@negL_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register  src = $src$$Register;
    __ subu(dst, R0, src);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct subL_Reg_immL_M32767_32768(mRegL dst, mRegL src1,  immL_M32767_32768 src2) %{
  match(Set dst (SubL src1 src2));
  ins_cost(80);

  format %{ "subu    $dst, $src1, $src2 #@subL_Reg_immL_M32767_32768" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    __ daddiu(dst, src1, -1 * $src2$$constant);
  %}
  ins_pipe( ialu_regI_regI );
%}

// Subtract Long Register with Register.
instruct subL_Reg_Reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (SubL src1 src2));
  ins_cost(100);
  format %{ "SubL    $dst, $src1, $src2 @ subL_Reg_Reg" %}
  ins_encode %{
    Register dst  = as_Register($dst$$reg);
    Register src1 = as_Register($src1$$reg);
    Register src2 = as_Register($src2$$reg);

    __ subu(dst, src1, src2);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct subL_Reg_RegI2L(mRegL dst, mRegL src1, mRegI src2) %{
  match(Set dst (SubL src1 (ConvI2L src2)));
  ins_cost(100);
  format %{ "SubL    $dst, $src1, $src2 @ subL_Reg_RegI2L" %}
  ins_encode %{
    Register dst  = as_Register($dst$$reg);
    Register src1 = as_Register($src1$$reg);
    Register src2 = as_Register($src2$$reg);

    __ subu(dst, src1, src2);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct subL_RegI2L_Reg(mRegL dst, mRegI src1, mRegL src2) %{
  match(Set dst (SubL (ConvI2L src1) src2));
  ins_cost(200);
  format %{ "SubL    $dst, $src1, $src2 @ subL_RegI2L_Reg" %}
  ins_encode %{
    Register dst  = as_Register($dst$$reg);
    Register src1 = as_Register($src1$$reg);
    Register src2 = as_Register($src2$$reg);

    __ subu(dst, src1, src2);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct subL_RegI2L_RegI2L(mRegL dst, mRegI src1, mRegI src2) %{
  match(Set dst (SubL (ConvI2L src1) (ConvI2L src2)));
  ins_cost(200);
  format %{ "SubL    $dst, $src1, $src2 @ subL_RegI2L_RegI2L" %}
  ins_encode %{
    Register dst  = as_Register($dst$$reg);
    Register src1 = as_Register($src1$$reg);
    Register src2 = as_Register($src2$$reg);

    __ subu(dst, src1, src2);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Integer MOD with Register
instruct modI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (ModI src1 src2));
  ins_cost(300);
  format %{ "modi   $dst, $src1, $src2 @ modI_Reg_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    //if (UseLEXT1) {
    if (0) {
      // Experiments show that gsmod is slower that div+mfhi.
      // So I just disable it here.
      __ gsmod(dst, src1, src2);
    } else {
      __ div(src1, src2);
      __ mfhi(dst);
    }
  %}

  //ins_pipe( ialu_mod );
  ins_pipe( ialu_regI_regI );
%}

instruct modL_reg_reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (ModL src1 src2));
  format %{ "modL  $dst, $src1, $src2 @modL_reg_reg" %}

  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register op1 = as_Register($src1$$reg);
    Register op2 = as_Register($src2$$reg);

    if (UseLEXT1) {
      __ gsdmod(dst, op1, op2);
    } else {
      __ ddiv(op1, op2);
      __ mfhi(dst);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct mulI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (MulI src1 src2));

  ins_cost(300);
  format %{ "mul   $dst, $src1, $src2 @ mulI_Reg_Reg" %}
  ins_encode %{
     Register src1 = $src1$$Register;
     Register src2 = $src2$$Register;
     Register dst  = $dst$$Register;

     __ mul(dst, src1, src2);
  %}
  ins_pipe( ialu_mult );
%}

instruct maddI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2, mRegI src3) %{
  match(Set dst (AddI (MulI src1 src2) src3));

  ins_cost(999);
  format %{ "madd   $dst, $src1 * $src2 + $src3 #@maddI_Reg_Reg" %}
  ins_encode %{
     Register src1 = $src1$$Register;
     Register src2 = $src2$$Register;
     Register src3 = $src3$$Register;
     Register dst  = $dst$$Register;

     __ mtlo(src3);
     __ madd(src1, src2);
     __ mflo(dst);
  %}
  ins_pipe( ialu_mult );
%}

instruct divI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (DivI src1 src2));

  ins_cost(300);
  format %{ "div   $dst, $src1, $src2 @ divI_Reg_Reg" %}
  ins_encode %{
     Register src1 = $src1$$Register;
     Register src2 = $src2$$Register;
     Register dst  = $dst$$Register;

    // In MIPS, div does not cause exception.
    //   We must trap an exception manually.
    __ teq(R0, src2, 0x7);

    if (UseLEXT1) {
      __ gsdiv(dst, src1, src2);
    } else {
      __ div(src1, src2);

      __ nop();
      __ nop();
      __ mflo(dst);
    }
  %}
  ins_pipe( ialu_mod );
%}

instruct divF_Reg_Reg(regF dst, regF src1, regF src2) %{
  match(Set dst (DivF src1 src2));

  ins_cost(300);
  format %{ "divF   $dst, $src1, $src2 @ divF_Reg_Reg" %}
  ins_encode %{
     FloatRegister src1 = $src1$$FloatRegister;
     FloatRegister src2 = $src2$$FloatRegister;
     FloatRegister dst  = $dst$$FloatRegister;

    /* Here do we need to trap an exception manually ? */
    __ div_s(dst, src1, src2);
  %}
  ins_pipe( pipe_slow );
%}

instruct divD_Reg_Reg(regD dst, regD src1, regD src2) %{
  match(Set dst (DivD src1 src2));

  ins_cost(300);
  format %{ "divD   $dst, $src1, $src2 @ divD_Reg_Reg" %}
  ins_encode %{
     FloatRegister src1 = $src1$$FloatRegister;
     FloatRegister src2 = $src2$$FloatRegister;
     FloatRegister dst  = $dst$$FloatRegister;

    /* Here do we need to trap an exception manually ? */
    __ div_d(dst, src1, src2);
  %}
  ins_pipe( pipe_slow );
%}

instruct mulL_reg_reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (MulL src1 src2));
  format %{ "mulL  $dst, $src1, $src2 @mulL_reg_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register op1 = as_Register($src1$$reg);
    Register op2 = as_Register($src2$$reg);

    if (UseLEXT1) {
      __ gsdmult(dst, op1, op2);
    } else {
      __ dmult(op1, op2);
      __ mflo(dst);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct mulL_reg_regI2L(mRegL dst, mRegL src1, mRegI src2) %{
  match(Set dst (MulL src1 (ConvI2L src2)));
  format %{ "mulL  $dst, $src1, $src2 @mulL_reg_regI2L" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register op1 = as_Register($src1$$reg);
    Register op2 = as_Register($src2$$reg);

    if (UseLEXT1) {
      __ gsdmult(dst, op1, op2);
    } else {
      __ dmult(op1, op2);
      __ mflo(dst);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct divL_reg_reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (DivL src1 src2));
  format %{ "divL  $dst, $src1, $src2 @divL_reg_reg" %}

  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register op1 = as_Register($src1$$reg);
    Register op2 = as_Register($src2$$reg);

    if (UseLEXT1) {
      __ gsddiv(dst, op1, op2);
    } else {
      __ ddiv(op1, op2);
      __ mflo(dst);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct addF_reg_reg(regF dst, regF src1, regF src2) %{
  match(Set dst (AddF src1 src2));
  format %{ "AddF  $dst, $src1, $src2 @addF_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    FloatRegister dst  = as_FloatRegister($dst$$reg);

    __ add_s(dst, src1, src2);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct subF_reg_reg(regF dst, regF src1, regF src2) %{
  match(Set dst (SubF src1 src2));
  format %{ "SubF  $dst, $src1, $src2 @subF_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    FloatRegister dst  = as_FloatRegister($dst$$reg);

    __ sub_s(dst, src1, src2);
  %}
  ins_pipe( fpu_regF_regF );
%}
instruct addD_reg_reg(regD dst, regD src1, regD src2) %{
  match(Set dst (AddD src1 src2));
  format %{ "AddD  $dst, $src1, $src2 @addD_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    FloatRegister dst  = as_FloatRegister($dst$$reg);

    __ add_d(dst, src1, src2);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct subD_reg_reg(regD dst, regD src1, regD src2) %{
  match(Set dst (SubD src1 src2));
  format %{ "SubD  $dst, $src1, $src2 @subD_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    FloatRegister dst  = as_FloatRegister($dst$$reg);

    __ sub_d(dst, src1, src2);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct negF_reg(regF dst, regF src) %{
  match(Set dst (NegF src));
  format %{ "negF  $dst, $src @negF_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ neg_s(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct negD_reg(regD dst, regD src) %{
  match(Set dst (NegD src));
  format %{ "negD  $dst, $src @negD_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ neg_d(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}


instruct mulF_reg_reg(regF dst, regF src1, regF src2) %{
  match(Set dst (MulF src1 src2));
  format %{ "MULF  $dst, $src1, $src2 @mulF_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = $src1$$FloatRegister;
    FloatRegister src2 = $src2$$FloatRegister;
    FloatRegister dst  = $dst$$FloatRegister;

    __ mul_s(dst, src1, src2);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct maddF_reg_reg(regF dst, regF src1, regF src2, regF src3) %{
  match(Set dst (AddF (MulF src1 src2) src3));
  // For compatibility reason (e.g. on the Loongson platform), disable this guy.
  ins_cost(44444);
  format %{ "maddF  $dst, $src1, $src2, $src3 @maddF_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = $src1$$FloatRegister;
    FloatRegister src2 = $src2$$FloatRegister;
    FloatRegister src3 = $src3$$FloatRegister;
    FloatRegister dst  = $dst$$FloatRegister;

    __ madd_s(dst, src1, src2, src3);
  %}
  ins_pipe( fpu_regF_regF );
%}

// Mul two double precision floating piont number
instruct mulD_reg_reg(regD dst, regD src1, regD src2) %{
  match(Set dst (MulD src1 src2));
  format %{ "MULD  $dst, $src1, $src2 @mulD_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = $src1$$FloatRegister;
    FloatRegister src2 = $src2$$FloatRegister;
    FloatRegister dst  = $dst$$FloatRegister;

    __ mul_d(dst, src1, src2);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct maddD_reg_reg(regD dst, regD src1, regD src2, regD src3) %{
  match(Set dst (AddD (MulD src1 src2) src3));
  // For compatibility reason (e.g. on the Loongson platform), disable this guy.
  ins_cost(44444);
  format %{ "maddD  $dst, $src1, $src2, $src3 @maddD_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = $src1$$FloatRegister;
    FloatRegister src2 = $src2$$FloatRegister;
    FloatRegister src3 = $src3$$FloatRegister;
    FloatRegister dst  = $dst$$FloatRegister;

    __ madd_d(dst, src1, src2, src3);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct absF_reg(regF dst, regF src) %{
  match(Set dst (AbsF src));
  ins_cost(100);
  format %{ "absF  $dst, $src @absF_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ abs_s(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}


// intrinsics for math_native.
// AbsD  SqrtD  CosD  SinD  TanD  LogD  Log10D

instruct absD_reg(regD dst, regD src) %{
  match(Set dst (AbsD src));
  ins_cost(100);
  format %{ "absD  $dst, $src @absD_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ abs_d(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct sqrtD_reg(regD dst, regD src) %{
  match(Set dst (SqrtD src));
  ins_cost(100);
  format %{ "SqrtD  $dst, $src @sqrtD_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ sqrt_d(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct sqrtF_reg(regF dst, regF src) %{
  match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
  ins_cost(100);
  format %{ "SqrtF  $dst, $src @sqrtF_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ sqrt_s(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}
//----------------------------------Logical Instructions----------------------
//__________________________________Integer Logical Instructions-------------

//And Instuctions
// And Register with Immediate
instruct andI_Reg_immI(mRegI dst, mRegI src1,  immI src2) %{
  match(Set dst (AndI src1 src2));

  format %{ "and  $dst, $src1, $src2 #@andI_Reg_immI" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    int      val = $src2$$constant;

    __ move(AT, val);
    __ andr(dst, src, AT);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andI_Reg_imm_0_65535(mRegI dst, mRegI src1,  immI_0_65535 src2) %{
  match(Set dst (AndI src1 src2));
  ins_cost(60);

  format %{ "and  $dst, $src1, $src2 #@andI_Reg_imm_0_65535" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    int      val = $src2$$constant;

    __ andi(dst, src, val);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andI_Reg_immI_nonneg_mask(mRegI dst, mRegI src1,  immI_nonneg_mask mask) %{
  match(Set dst (AndI src1 mask));
  ins_cost(60);

  format %{ "and  $dst, $src1, $mask #@andI_Reg_immI_nonneg_mask" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    int     size = Assembler::is_int_mask($mask$$constant);

    __ ext(dst, src, 0, size);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andL_Reg_immL_nonneg_mask(mRegL dst, mRegL src1,  immL_nonneg_mask mask) %{
  match(Set dst (AndL src1 mask));
  ins_cost(60);

  format %{ "and  $dst, $src1, $mask #@andL_Reg_immL_nonneg_mask" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    int     size = Assembler::is_jlong_mask($mask$$constant);

    __ dext(dst, src, 0, size);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct xorI_Reg_imm_0_65535(mRegI dst, mRegI src1,  immI_0_65535 src2) %{
  match(Set dst (XorI src1 src2));
  ins_cost(60);

  format %{ "xori  $dst, $src1, $src2 #@xorI_Reg_imm_0_65535" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    int      val = $src2$$constant;

       __ xori(dst, src, val);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct xorI_Reg_immI_M1(mRegI dst, mRegI src1,  immI_M1 M1) %{
  match(Set dst (XorI src1 M1));
  predicate(UseLEXT3);
  ins_cost(60);

  format %{ "xor  $dst, $src1, $M1 #@xorI_Reg_immI_M1" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;

    __ gsorn(dst, R0, src);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct xorL2I_Reg_immI_M1(mRegI dst, mRegL src1,  immI_M1 M1) %{
  match(Set dst (XorI (ConvL2I src1) M1));
  predicate(UseLEXT3);
  ins_cost(60);

  format %{ "xor  $dst, $src1, $M1 #@xorL2I_Reg_immI_M1" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;

    __ gsorn(dst, R0, src);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct xorL_Reg_imm_0_65535(mRegL dst, mRegL src1,  immL_0_65535 src2) %{
  match(Set dst (XorL src1 src2));
  ins_cost(60);

  format %{ "xori  $dst, $src1, $src2 #@xorL_Reg_imm_0_65535" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    int      val = $src2$$constant;

       __ xori(dst, src, val);
  %}
  ins_pipe( ialu_regI_regI );
%}

/*
instruct xorL_Reg_immL_M1(mRegL dst, mRegL src1,  immL_M1 M1) %{
  match(Set dst (XorL src1 M1));
  predicate(UseLEXT3);
  ins_cost(60);

  format %{ "xor  $dst, $src1, $M1 #@xorL_Reg_immL_M1" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;

    __ gsorn(dst, R0, src);
  %}
  ins_pipe( ialu_regI_regI );
%}
*/

instruct lbu_and_lmask(mRegI dst, memory mem,  immI_255 mask) %{
  match(Set dst (AndI mask (LoadB mem)));
  ins_cost(60);

  format %{ "lhu  $dst, $mem #@lbu_and_lmask" %}
  ins_encode(load_UB_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

instruct lbu_and_rmask(mRegI dst, memory mem,  immI_255 mask) %{
  match(Set dst (AndI (LoadB mem) mask));
  ins_cost(60);

  format %{ "lhu  $dst, $mem #@lbu_and_rmask" %}
  ins_encode(load_UB_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

instruct andI_Reg_Reg(mRegI dst, mRegI src1,  mRegI src2) %{
  match(Set dst (AndI src1 src2));

  format %{ "and    $dst, $src1, $src2 #@andI_Reg_Reg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ andr(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andnI_Reg_nReg(mRegI dst, mRegI src1,  mRegI src2, immI_M1 M1) %{
  match(Set dst (AndI src1 (XorI src2 M1)));
  predicate(UseLEXT3);

  format %{ "andn   $dst, $src1, $src2 #@andnI_Reg_nReg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    __ gsandn(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct ornI_Reg_nReg(mRegI dst, mRegI src1,  mRegI src2, immI_M1 M1) %{
  match(Set dst (OrI src1 (XorI src2 M1)));
  predicate(UseLEXT3);

  format %{ "orn    $dst, $src1, $src2 #@ornI_Reg_nReg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    __ gsorn(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andnI_nReg_Reg(mRegI dst, mRegI src1,  mRegI src2, immI_M1 M1) %{
  match(Set dst (AndI (XorI src1 M1) src2));
  predicate(UseLEXT3);

  format %{ "andn   $dst, $src2, $src1 #@andnI_nReg_Reg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    __ gsandn(dst, src2, src1);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct ornI_nReg_Reg(mRegI dst, mRegI src1,  mRegI src2, immI_M1 M1) %{
  match(Set dst (OrI (XorI src1 M1) src2));
  predicate(UseLEXT3);

  format %{ "orn    $dst, $src2, $src1 #@ornI_nReg_Reg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    __ gsorn(dst, src2, src1);
  %}
  ins_pipe( ialu_regI_regI );
%}

// And Long Register with Register
instruct andL_Reg_Reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (AndL src1 src2));
  format %{ "AND    $dst, $src1, $src2 @ andL_Reg_Reg\n\t" %}
  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    Register src2_reg = as_Register($src2$$reg);

    __ andr(dst_reg, src1_reg, src2_reg);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct andL_Reg_Reg_convI2L(mRegL dst, mRegL src1, mRegI src2) %{
  match(Set dst (AndL src1 (ConvI2L src2)));
  format %{ "AND    $dst, $src1, $src2 @ andL_Reg_Reg_convI2L\n\t" %}
  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    Register src2_reg = as_Register($src2$$reg);

    __ andr(dst_reg, src1_reg, src2_reg);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct andL_Reg_imm_0_65535(mRegL dst, mRegL src1,  immL_0_65535 src2) %{
  match(Set dst (AndL src1 src2));
  ins_cost(60);

  format %{ "and  $dst, $src1, $src2 #@andL_Reg_imm_0_65535" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    long     val = $src2$$constant;

       __ andi(dst, src, val);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andL2I_Reg_imm_0_65535(mRegI dst, mRegL src1,  immL_0_65535 src2) %{
  match(Set dst (ConvL2I (AndL src1 src2)));
  ins_cost(60);

  format %{ "and  $dst, $src1, $src2 #@andL2I_Reg_imm_0_65535" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    long     val = $src2$$constant;

       __ andi(dst, src, val);
  %}
  ins_pipe( ialu_regI_regI );
%}

/*
instruct andnL_Reg_nReg(mRegL dst, mRegL src1,  mRegL src2, immL_M1 M1) %{
  match(Set dst (AndL src1 (XorL src2 M1)));
  predicate(UseLEXT3);

  format %{ "andn   $dst, $src1, $src2 #@andnL_Reg_nReg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    __ gsandn(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_regI );
%}
*/

/*
instruct ornL_Reg_nReg(mRegL dst, mRegL src1,  mRegL src2, immL_M1 M1) %{
  match(Set dst (OrL src1 (XorL src2 M1)));
  predicate(UseLEXT3);

  format %{ "orn    $dst, $src1, $src2 #@ornL_Reg_nReg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    __ gsorn(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_regI );
%}
*/

/*
instruct andnL_nReg_Reg(mRegL dst, mRegL src1,  mRegL src2, immL_M1 M1) %{
  match(Set dst (AndL (XorL src1 M1) src2));
  predicate(UseLEXT3);

  format %{ "andn   $dst, $src2, $src1 #@andnL_nReg_Reg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    __ gsandn(dst, src2, src1);
  %}
  ins_pipe( ialu_regI_regI );
%}
*/

/*
instruct ornL_nReg_Reg(mRegL dst, mRegL src1,  mRegL src2, immL_M1 M1) %{
  match(Set dst (OrL (XorL src1 M1) src2));
  predicate(UseLEXT3);

  format %{ "orn    $dst, $src2, $src1 #@ornL_nReg_Reg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    __ gsorn(dst, src2, src1);
  %}
  ins_pipe( ialu_regI_regI );
%}
*/

instruct andL_Reg_immL_M8(mRegL dst,  immL_M8 M8) %{
  match(Set dst (AndL dst M8));
  ins_cost(60);

  format %{ "and  $dst, $dst, $M8 #@andL_Reg_immL_M8" %}
  ins_encode %{
    Register dst = $dst$$Register;

    __ dins(dst, R0, 0, 3);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andL_Reg_immL_M5(mRegL dst,  immL_M5 M5) %{
  match(Set dst (AndL dst M5));
  ins_cost(60);

  format %{ "and  $dst, $dst, $M5 #@andL_Reg_immL_M5" %}
  ins_encode %{
    Register dst = $dst$$Register;

    __ dins(dst, R0, 2, 1);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andL_Reg_immL_M7(mRegL dst,  immL_M7 M7) %{
  match(Set dst (AndL dst M7));
  ins_cost(60);

  format %{ "and  $dst, $dst, $M7 #@andL_Reg_immL_M7" %}
  ins_encode %{
    Register dst = $dst$$Register;

    __ dins(dst, R0, 1, 2);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andL_Reg_immL_M4(mRegL dst,  immL_M4 M4) %{
  match(Set dst (AndL dst M4));
  ins_cost(60);

  format %{ "and  $dst, $dst, $M4 #@andL_Reg_immL_M4" %}
  ins_encode %{
    Register dst = $dst$$Register;

    __ dins(dst, R0, 0, 2);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andL_Reg_immL_M121(mRegL dst,  immL_M121 M121) %{
  match(Set dst (AndL dst M121));
  ins_cost(60);

  format %{ "and  $dst, $dst, $M121 #@andL_Reg_immL_M121" %}
  ins_encode %{
    Register dst = $dst$$Register;

    __ dins(dst, R0, 3, 4);
  %}
  ins_pipe( ialu_regI_regI );
%}

// Or Long Register with Register
instruct orL_Reg_Reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (OrL src1 src2));
  format %{ "OR    $dst, $src1, $src2 @ orL_Reg_Reg\t" %}
  ins_encode %{
    Register dst_reg  = $dst$$Register;
    Register src1_reg = $src1$$Register;
    Register src2_reg = $src2$$Register;

    __ orr(dst_reg, src1_reg, src2_reg);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct orL_Reg_P2XReg(mRegL dst, mRegP src1, mRegL src2) %{
  match(Set dst (OrL (CastP2X src1) src2));
  format %{ "OR    $dst, $src1, $src2 @ orL_Reg_P2XReg\t" %}
  ins_encode %{
    Register dst_reg  = $dst$$Register;
    Register src1_reg = $src1$$Register;
    Register src2_reg = $src2$$Register;

    __ orr(dst_reg, src1_reg, src2_reg);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Xor Long Register with Register
instruct xorL_Reg_Reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (XorL src1 src2));
  format %{ "XOR    $dst, $src1, $src2 @ xorL_Reg_Reg\t" %}
  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    Register src2_reg = as_Register($src2$$reg);

    __ xorr(dst_reg, src1_reg, src2_reg);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Shift Left by 8-bit immediate
instruct salI_Reg_imm(mRegI dst, mRegI src, immI8 shift) %{
  match(Set dst (LShiftI src shift));

  format %{ "SHL    $dst, $src, $shift #@salI_Reg_imm" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    int    shamt = $shift$$constant;

    __ sll(dst, src, shamt);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct salL2I_Reg_imm(mRegI dst, mRegL src, immI8 shift) %{
  match(Set dst (LShiftI (ConvL2I src) shift));

  format %{ "SHL    $dst, $src, $shift #@salL2I_Reg_imm" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    int    shamt = $shift$$constant;

    __ sll(dst, src, shamt);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct salI_Reg_imm_and_M65536(mRegI dst, mRegI src, immI_16 shift, immI_M65536 mask) %{
  match(Set dst (AndI (LShiftI src shift) mask));

  format %{ "SHL    $dst, $src, $shift #@salI_Reg_imm_and_M65536" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

    __ sll(dst, src, 16);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct land7_2_s(mRegI dst, mRegL src, immL_7 seven, immI_16 sixteen)
%{
  match(Set dst (RShiftI (LShiftI (ConvL2I (AndL src seven)) sixteen) sixteen));

  format %{ "andi  $dst, $src, 7\t# @land7_2_s" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

    __ andi(dst, src, 7);
  %}
  ins_pipe(ialu_regI_regI);
%}

instruct ori2s(mRegI dst, mRegI src1, immI_0_32767 src2, immI_16 sixteen)
%{
  match(Set dst (RShiftI (LShiftI (OrI src1 src2) sixteen) sixteen));

  format %{ "ori  $dst, $src1, $src2\t# @ori2s" %}
  ins_encode %{
    Register src = $src1$$Register;
    int      val = $src2$$constant;
    Register dst = $dst$$Register;

    __ ori(dst, src, val);
  %}
  ins_pipe(ialu_regI_regI);
%}

// Logical Shift Right by 16, followed by Arithmetic Shift Left by 16.
// This idiom is used by the compiler the i2s bytecode.
instruct i2s(mRegI dst, mRegI src, immI_16 sixteen)
%{
  match(Set dst (RShiftI (LShiftI src sixteen) sixteen));

  format %{ "i2s  $dst, $src\t# @i2s" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

    __ seh(dst, src);
  %}
  ins_pipe(ialu_regI_regI);
%}

// Logical Shift Right by 24, followed by Arithmetic Shift Left by 24.
// This idiom is used by the compiler for the i2b bytecode.
instruct i2b(mRegI dst, mRegI src, immI_24 twentyfour)
%{
  match(Set dst (RShiftI (LShiftI src twentyfour) twentyfour));

  format %{ "i2b  $dst, $src\t# @i2b" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

    __ seb(dst, src);
  %}
  ins_pipe(ialu_regI_regI);
%}


instruct salI_RegL2I_imm(mRegI dst, mRegL src, immI8 shift) %{
  match(Set dst (LShiftI (ConvL2I src) shift));

  format %{ "SHL    $dst, $src, $shift #@salI_RegL2I_imm" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    int    shamt = $shift$$constant;

    __ sll(dst, src, shamt);
  %}
  ins_pipe( ialu_regI_regI );
%}

// Shift Left by 8-bit immediate
instruct salI_Reg_Reg(mRegI dst, mRegI src, mRegI shift) %{
  match(Set dst (LShiftI src shift));

  format %{ "SHL    $dst, $src, $shift #@salI_Reg_Reg" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    Register shamt = $shift$$Register;
    __ sllv(dst, src, shamt);
  %}
  ins_pipe( ialu_regI_regI );
%}


// Shift Left Long
instruct salL_Reg_imm(mRegL dst, mRegL src, immI8 shift) %{
  match(Set dst (LShiftL src shift));
  ins_cost(100);
  format %{ "salL    $dst, $src, $shift @ salL_Reg_imm" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int      shamt = $shift$$constant;

    if (__ is_simm(shamt, 5))
        __ dsll(dst_reg, src_reg, shamt);
    else {
      int sa = Assembler::low(shamt, 6);
      if (sa < 32) {
        __ dsll(dst_reg, src_reg, sa);
      } else {
        __ dsll32(dst_reg, src_reg, sa - 32);
      }
    }
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct salL_RegI2L_imm(mRegL dst, mRegI src, immI8 shift) %{
  match(Set dst (LShiftL (ConvI2L src) shift));
  ins_cost(100);
  format %{ "salL    $dst, $src, $shift @ salL_RegI2L_imm" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int      shamt = $shift$$constant;

    if (__ is_simm(shamt, 5))
        __ dsll(dst_reg, src_reg, shamt);
    else {
      int sa = Assembler::low(shamt, 6);
      if (sa < 32) {
        __ dsll(dst_reg, src_reg, sa);
      } else {
        __ dsll32(dst_reg, src_reg, sa - 32);
      }
    }
  %}
  ins_pipe( ialu_regL_regL );
%}

// Shift Left Long
instruct salL_Reg_Reg(mRegL dst, mRegL src, mRegI shift) %{
  match(Set dst (LShiftL src shift));
  ins_cost(100);
  format %{ "salL    $dst, $src, $shift @ salL_Reg_Reg" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);

    __ dsllv(dst_reg, src_reg, $shift$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Shift Right Long
instruct sarL_Reg_imm(mRegL dst, mRegL src, immI8 shift) %{
  match(Set dst (RShiftL src shift));
  ins_cost(100);
  format %{ "sarL    $dst, $src, $shift @ sarL_Reg_imm" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int      shamt = ($shift$$constant & 0x3f);
    if (__  is_simm(shamt, 5))
      __ dsra(dst_reg, src_reg, shamt);
    else {
      int sa = Assembler::low(shamt, 6);
      if (sa < 32) {
        __ dsra(dst_reg, src_reg, sa);
      } else {
        __ dsra32(dst_reg, src_reg, sa - 32);
      }
    }
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct sarL2I_Reg_immI_32_63(mRegI dst, mRegL src, immI_32_63 shift) %{
  match(Set dst (ConvL2I (RShiftL src shift)));
  ins_cost(100);
  format %{ "sarL    $dst, $src, $shift @ sarL2I_Reg_immI_32_63" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int      shamt   = $shift$$constant;

    __ dsra32(dst_reg, src_reg, shamt - 32);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Shift Right Long arithmetically
instruct sarL_Reg_Reg(mRegL dst, mRegL src, mRegI shift) %{
  match(Set dst (RShiftL src shift));
  ins_cost(100);
  format %{ "sarL    $dst, $src, $shift @ sarL_Reg_Reg" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);

    __ dsrav(dst_reg, src_reg, $shift$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Shift Right Long logically
instruct slrL_Reg_Reg(mRegL dst, mRegL src, mRegI shift) %{
  match(Set dst (URShiftL src shift));
  ins_cost(100);
  format %{ "slrL    $dst, $src, $shift @ slrL_Reg_Reg" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);

    __ dsrlv(dst_reg, src_reg, $shift$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct slrL_Reg_immI_0_31(mRegL dst, mRegL src, immI_0_31 shift) %{
  match(Set dst (URShiftL src shift));
  ins_cost(80);
  format %{ "slrL    $dst, $src, $shift @ slrL_Reg_immI_0_31" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int        shamt = $shift$$constant;

    __ dsrl(dst_reg, src_reg, shamt);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct slrL_Reg_immI_0_31_and_max_int(mRegI dst, mRegL src, immI_0_31 shift, immI_MaxI max_int) %{
  match(Set dst (AndI (ConvL2I (URShiftL src shift)) max_int));
  ins_cost(80);
  format %{ "dext    $dst, $src, $shift, 31 @ slrL_Reg_immI_0_31_and_max_int" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int        shamt = $shift$$constant;

    __ dext(dst_reg, src_reg, shamt, 31);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct slrL_P2XReg_immI_0_31(mRegL dst, mRegP src, immI_0_31 shift) %{
  match(Set dst (URShiftL (CastP2X src) shift));
  ins_cost(80);
  format %{ "slrL    $dst, $src, $shift @ slrL_P2XReg_immI_0_31" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int        shamt = $shift$$constant;

    __ dsrl(dst_reg, src_reg, shamt);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct slrL_Reg_immI_32_63(mRegL dst, mRegL src, immI_32_63 shift) %{
  match(Set dst (URShiftL src shift));
  ins_cost(80);
  format %{ "slrL    $dst, $src, $shift @ slrL_Reg_immI_32_63" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int        shamt = $shift$$constant;

    __ dsrl32(dst_reg, src_reg, shamt - 32);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct slrL_Reg_immI_convL2I(mRegI dst, mRegL src, immI_32_63 shift) %{
  match(Set dst (ConvL2I (URShiftL src shift)));
  predicate(n->in(1)->in(2)->get_int() > 32);
  ins_cost(80);
  format %{ "slrL    $dst, $src, $shift @ slrL_Reg_immI_convL2I" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int        shamt = $shift$$constant;

    __ dsrl32(dst_reg, src_reg, shamt - 32);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct slrL_P2XReg_immI_32_63(mRegL dst, mRegP src, immI_32_63 shift) %{
  match(Set dst (URShiftL (CastP2X src) shift));
  ins_cost(80);
  format %{ "slrL    $dst, $src, $shift @ slrL_P2XReg_immI_32_63" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int        shamt = $shift$$constant;

    __ dsrl32(dst_reg, src_reg, shamt - 32);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Xor Instructions
// Xor Register with Register
instruct xorI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (XorI src1 src2));

  format %{ "XOR    $dst, $src1, $src2 #@xorI_Reg_Reg" %}

  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ xorr(dst, src1, src2);
  %}

  ins_pipe( ialu_regI_regI );
%}

// Or Instructions
// Or Register with Register
instruct orI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (OrI src1 src2));

  format %{ "OR     $dst, $src1, $src2 #@orI_Reg_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ orr(dst, src1, src2);
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct rotI_shr_logical_Reg(mRegI dst, mRegI src, immI_0_31 rshift, immI_0_31 lshift, immI_1 one) %{
  match(Set dst (OrI (URShiftI src rshift) (LShiftI (AndI src one) lshift)));
  predicate(32 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int())));

  format %{ "rotr     $dst, $src, 1 ...\n\t"
            "srl      $dst, $dst, ($rshift-1) @ rotI_shr_logical_Reg" %}
  ins_encode %{
    Register   dst = $dst$$Register;
    Register   src = $src$$Register;
    int     rshift = $rshift$$constant;

    __ rotr(dst, src, 1);
    if (rshift - 1) {
      __ srl(dst, dst, rshift - 1);
    }
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct orI_Reg_castP2X(mRegL dst, mRegL src1, mRegP src2) %{
  match(Set dst (OrI src1 (CastP2X src2)));

  format %{ "OR     $dst, $src1, $src2 #@orI_Reg_castP2X" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ orr(dst, src1, src2);
  %}

  ins_pipe( ialu_regI_regI );
%}

// Logical Shift Right by 8-bit immediate
instruct shr_logical_Reg_imm(mRegI dst, mRegI src, immI8 shift) %{
  match(Set dst (URShiftI src shift));
  //effect(KILL cr);

  format %{ "SRL    $dst, $src, $shift #@shr_logical_Reg_imm" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    int    shift = $shift$$constant;

    __ srl(dst, src, shift);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct shr_logical_Reg_imm_nonneg_mask(mRegI dst, mRegI src, immI_0_31 shift, immI_nonneg_mask mask) %{
  match(Set dst (AndI (URShiftI src shift) mask));

  format %{ "ext    $dst, $src, $shift, one-bits($mask) #@shr_logical_Reg_imm_nonneg_mask" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    int      pos = $shift$$constant;
    int     size = Assembler::is_int_mask($mask$$constant);

    __ ext(dst, src, pos, size);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct rolI_Reg_immI_0_31(mRegI dst, immI_0_31 lshift, immI_0_31 rshift)
%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x1f));
  match(Set dst (OrI (LShiftI dst lshift) (URShiftI dst rshift)));

  ins_cost(100);
  format %{ "rotr    $dst, $dst, $rshift #@rolI_Reg_immI_0_31" %}
  ins_encode %{
    Register dst = $dst$$Register;
    int      sa  = $rshift$$constant;

    __ rotr(dst, dst, sa);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct rolL_Reg_immI_0_31(mRegL dst, mRegL src, immI_32_63 lshift, immI_0_31 rshift)
%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x3f));
  match(Set dst (OrL (LShiftL src lshift) (URShiftL src rshift)));

  ins_cost(100);
  format %{ "rotr    $dst, $src, $rshift #@rolL_Reg_immI_0_31" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int      sa  = $rshift$$constant;

    __ drotr(dst, src, sa);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct rolL_Reg_immI_32_63(mRegL dst, mRegL src, immI_0_31 lshift, immI_32_63 rshift)
%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x3f));
  match(Set dst (OrL (LShiftL src lshift) (URShiftL src rshift)));

  ins_cost(100);
  format %{ "rotr    $dst, $src, $rshift #@rolL_Reg_immI_32_63" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int      sa  = $rshift$$constant;

    __ drotr32(dst, src, sa - 32);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct rorI_Reg_immI_0_31(mRegI dst, mRegI src, immI_0_31 rshift, immI_0_31 lshift)
%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x1f));
  match(Set dst (OrI (URShiftI src rshift) (LShiftI src lshift)));

  ins_cost(100);
  format %{ "rotr    $dst, $src, $rshift #@rorI_Reg_immI_0_31" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int      sa  = $rshift$$constant;

    __ rotr(dst, src, sa);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct rorL_Reg_immI_0_31(mRegL dst, mRegL src, immI_0_31 rshift, immI_32_63 lshift)
%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x3f));
  match(Set dst (OrL (URShiftL src rshift) (LShiftL src lshift)));

  ins_cost(100);
  format %{ "rotr    $dst, $src, $rshift #@rorL_Reg_immI_0_31" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int      sa  = $rshift$$constant;

    __ drotr(dst, src, sa);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct rorL_Reg_immI_32_63(mRegL dst, mRegL src, immI_32_63 rshift, immI_0_31 lshift)
%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x3f));
  match(Set dst (OrL (URShiftL src rshift) (LShiftL src lshift)));

  ins_cost(100);
  format %{ "rotr    $dst, $src, $rshift #@rorL_Reg_immI_32_63" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int      sa  = $rshift$$constant;

    __ drotr32(dst, src, sa - 32);
  %}
  ins_pipe( ialu_regI_regI );
%}

// Logical Shift Right
instruct shr_logical_Reg_Reg(mRegI dst, mRegI src, mRegI shift) %{
  match(Set dst (URShiftI src shift));

  format %{ "SRL    $dst, $src, $shift #@shr_logical_Reg_Reg" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    Register shift = $shift$$Register;
    __ srlv(dst, src, shift);
  %}
  ins_pipe( ialu_regI_regI );
%}


instruct shr_arith_Reg_imm(mRegI dst, mRegI src, immI8 shift) %{
  match(Set dst (RShiftI src shift));
 // effect(KILL cr);

  format %{ "SRA    $dst, $src, $shift #@shr_arith_Reg_imm" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    int    shift = $shift$$constant;
    __ sra(dst, src, shift);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct shr_arith_Reg_Reg(mRegI dst, mRegI src, mRegI shift) %{
  match(Set dst (RShiftI src shift));
 // effect(KILL cr);

  format %{ "SRA    $dst, $src, $shift #@shr_arith_Reg_Reg" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    Register shift = $shift$$Register;
    __ srav(dst, src, shift);
  %}
  ins_pipe( ialu_regI_regI );
%}

//----------Convert Int to Boolean---------------------------------------------

instruct convI2B(mRegI dst, mRegI src) %{
  match(Set dst (Conv2B src));

  ins_cost(100);
  format %{ "convI2B    $dst, $src @ convI2B"  %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);

    if (dst != src) {
      __ daddiu(dst, R0, 1);
      __ movz(dst, R0, src);
    } else {
      __ move(AT, src);
      __ daddiu(dst, R0, 1);
      __ movz(dst, R0, AT);
    }
  %}

  ins_pipe( ialu_regL_regL );
%}

instruct convI2L_reg( mRegL dst, mRegI src) %{
  match(Set dst (ConvI2L src));

  ins_cost(100);
  format %{ "SLL    $dst, $src @ convI2L_reg\t"  %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);

    if(dst != src) __ sll(dst, src, 0);
  %}
  ins_pipe( ialu_regL_regL );
%}


instruct convL2I_reg( mRegI dst, mRegL src ) %{
  match(Set dst (ConvL2I src));

  format %{ "MOV    $dst, $src @ convL2I_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);

    __ sll(dst, src, 0);
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct convL2I2L_reg( mRegL dst, mRegL src ) %{
  match(Set dst (ConvI2L (ConvL2I src)));

  format %{ "sll    $dst, $src, 0 @ convL2I2L_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);

    __ sll(dst, src, 0);
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct convL2D_reg( regD dst, mRegL src ) %{
  match(Set dst (ConvL2D src));
  format %{ "convL2D    $dst, $src @ convL2D_reg" %}
  ins_encode %{
    Register src = as_Register($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ dmtc1(src, dst);
    __ cvt_d_l(dst, dst);
  %}

  ins_pipe( pipe_slow );
%}


instruct convD2L_reg_fast( mRegL dst, regD src ) %{
  match(Set dst (ConvD2L src));
  ins_cost(150);
  format %{ "convD2L    $dst, $src @ convD2L_reg_fast" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);

    Label Done;

    __ trunc_l_d(F30, src);
    // max_long:    0x7fffffffffffffff
    // __ set64(AT, 0x7fffffffffffffff);
    __ daddiu(AT, R0, -1);
    __ dsrl(AT, AT, 1);
    __ dmfc1(dst, F30);

    __ bne(dst, AT, Done);
    __ delayed()->mtc1(R0, F30);

    __ cvt_d_w(F30, F30);
    __ c_ult_d(src, F30);
    __ bc1f(Done);
    __ delayed()->daddiu(T9, R0, -1);

    __ c_un_d(src, src);    //NaN?
    __ subu(dst, T9, AT);
    __ movt(dst, R0);

    __ bind(Done);
  %}

  ins_pipe( pipe_slow );
%}


instruct convD2L_reg_slow( mRegL dst, regD src ) %{
  match(Set dst (ConvD2L src));
  ins_cost(250);
  format %{ "convD2L    $dst, $src @ convD2L_reg_slow" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);

    Label L;

    __ c_un_d(src, src);    //NaN?
    __ bc1t(L);
    __ delayed();
    __ move(dst, R0);

    __ trunc_l_d(F30, src);
    __ cfc1(AT, 31);
    __ li(T9, 0x10000);
    __ andr(AT, AT, T9);
    __ beq(AT, R0, L);
    __ delayed()->dmfc1(dst, F30);

    __ mov_d(F12, src);
    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::d2l), 1);
    __ move(dst, V0);
    __ bind(L);
  %}

  ins_pipe( pipe_slow );
%}


instruct convF2I_reg_fast( mRegI dst, regF src ) %{
  match(Set dst (ConvF2I src));
  ins_cost(150);
  format %{ "convf2i    $dst, $src @ convF2I_reg_fast" %}
  ins_encode %{
    Register      dreg = $dst$$Register;
    FloatRegister fval = $src$$FloatRegister;
    Label L;

    __ trunc_w_s(F30, fval);
    __ move(AT, 0x7fffffff);
    __ mfc1(dreg, F30);
    __ c_un_s(fval, fval);    //NaN?
    __ movt(dreg, R0);

    __ bne(AT, dreg, L);
    __ delayed()->lui(T9, 0x8000);

    __ mfc1(AT, fval);
    __ andr(AT, AT, T9);

    __ movn(dreg, T9, AT);

    __ bind(L);

  %}

  ins_pipe( pipe_slow );
%}



instruct convF2I_reg_slow( mRegI dst, regF src ) %{
  match(Set dst (ConvF2I src));
  ins_cost(250);
  format %{ "convf2i    $dst, $src @ convF2I_reg_slow" %}
  ins_encode %{
    Register      dreg = $dst$$Register;
    FloatRegister fval = $src$$FloatRegister;
    Label L;

    __ c_un_s(fval, fval);    //NaN?
    __ bc1t(L);
    __ delayed();
    __ move(dreg, R0);

    __ trunc_w_s(F30, fval);

    /* Call SharedRuntime:f2i() to do valid convention */
    __ cfc1(AT, 31);
    __ li(T9, 0x10000);
    __ andr(AT, AT, T9);
    __ beq(AT, R0, L);
    __ delayed()->mfc1(dreg, F30);

    __ mov_s(F12, fval);

    //This bug was found when running ezDS's control-panel.
    //    J 982 C2 javax.swing.text.BoxView.layoutMajorAxis(II[I[I)V (283 bytes) @ 0x000000555c46aa74
    //
    // An interger array index has been assigned to V0, and then changed from 1 to Integer.MAX_VALUE.
    // V0 is corrupted during call_VM_leaf(), and should be preserved.
    //
    __ push(fval);
    if(dreg != V0) {
      __ push(V0);
    }
    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::f2i), 1);
    if(dreg != V0) {
      __ move(dreg, V0);
      __ pop(V0);
    }
    __ pop(fval);
    __ bind(L);
  %}

  ins_pipe( pipe_slow );
%}


instruct convF2L_reg_fast( mRegL dst, regF src ) %{
  match(Set dst (ConvF2L src));
  ins_cost(150);
  format %{ "convf2l    $dst, $src @ convF2L_reg_fast" %}
  ins_encode %{
    Register      dreg = $dst$$Register;
    FloatRegister fval = $src$$FloatRegister;
    Label L;

    __ trunc_l_s(F30, fval);
    __ daddiu(AT, R0, -1);
    __ dsrl(AT, AT, 1);
    __ dmfc1(dreg, F30);
    __ c_un_s(fval, fval);    //NaN?
    __ movt(dreg, R0);

    __ bne(AT, dreg, L);
    __ delayed()->lui(T9, 0x8000);

    __ mfc1(AT, fval);
    __ andr(AT, AT, T9);

    __ dsll32(T9, T9, 0);
    __ movn(dreg, T9, AT);

    __ bind(L);
  %}

  ins_pipe( pipe_slow );
%}


instruct convF2L_reg_slow( mRegL dst, regF src ) %{
  match(Set dst (ConvF2L src));
  ins_cost(250);
  format %{ "convf2l    $dst, $src @ convF2L_reg_slow" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    FloatRegister fval = $src$$FloatRegister;
    Label L;

    __ c_un_s(fval, fval);    //NaN?
    __ bc1t(L);
    __ delayed();
    __ move(dst, R0);

    __ trunc_l_s(F30, fval);
    __ cfc1(AT, 31);
    __ li(T9, 0x10000);
    __ andr(AT, AT, T9);
    __ beq(AT, R0, L);
    __ delayed()->dmfc1(dst, F30);

    __ mov_s(F12, fval);
    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::f2l), 1);
    __ move(dst, V0);
    __ bind(L);
  %}

  ins_pipe( pipe_slow );
%}

instruct convL2F_reg( regF dst, mRegL src ) %{
  match(Set dst (ConvL2F src));
  format %{ "convl2f    $dst, $src @ convL2F_reg" %}
  ins_encode %{
    FloatRegister dst = $dst$$FloatRegister;
    Register src = as_Register($src$$reg);
    Label L;

    __ dmtc1(src, dst);
    __ cvt_s_l(dst, dst);
  %}

  ins_pipe( pipe_slow );
%}

instruct convI2F_reg( regF dst, mRegI src ) %{
  match(Set dst (ConvI2F src));
  format %{ "convi2f    $dst, $src @ convI2F_reg" %}
  ins_encode %{
    Register      src = $src$$Register;
    FloatRegister dst = $dst$$FloatRegister;

    __ mtc1(src, dst);
    __ cvt_s_w(dst, dst);
  %}

  ins_pipe( fpu_regF_regF );
%}

instruct cmpLTMask_immI_0( mRegI dst, mRegI p, immI_0 zero ) %{
  match(Set dst (CmpLTMask p zero));
  ins_cost(100);

  format %{ "sra    $dst, $p, 31 @ cmpLTMask_immI_0" %}
    ins_encode %{
       Register src = $p$$Register;
       Register dst = $dst$$Register;

       __ sra(dst, src, 31);
    %}
    ins_pipe( pipe_slow );
%}


instruct cmpLTMask( mRegI dst, mRegI p, mRegI q ) %{
  match(Set dst (CmpLTMask p q));
  ins_cost(400);

  format %{ "cmpLTMask    $dst, $p, $q @ cmpLTMask" %}
  ins_encode %{
    Register p   = $p$$Register;
    Register q   = $q$$Register;
    Register dst = $dst$$Register;

    __ slt(dst, p, q);
    __ subu(dst, R0, dst);
    %}
  ins_pipe( pipe_slow );
%}

instruct convP2B(mRegI dst, mRegP src) %{
  match(Set dst (Conv2B src));

  ins_cost(100);
  format %{ "convP2B    $dst, $src @ convP2B"  %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);

    if (dst != src) {
      __ daddiu(dst, R0, 1);
      __ movz(dst, R0, src);
    } else {
      __ move(AT, src);
      __ daddiu(dst, R0, 1);
      __ movz(dst, R0, AT);
    }
  %}

  ins_pipe( ialu_regL_regL );
%}


instruct convI2D_reg_reg(regD dst, mRegI src) %{
  match(Set dst (ConvI2D src));
  format %{ "conI2D $dst, $src @convI2D_reg" %}
  ins_encode %{
    Register      src = $src$$Register;
    FloatRegister dst = $dst$$FloatRegister;
    __ mtc1(src, dst);
    __ cvt_d_w(dst, dst);
    %}
  ins_pipe( fpu_regF_regF );
%}

instruct convF2D_reg_reg(regD dst, regF src) %{
  match(Set dst (ConvF2D src));
  format %{ "convF2D  $dst, $src\t# @convF2D_reg_reg" %}
  ins_encode %{
    FloatRegister dst = $dst$$FloatRegister;
    FloatRegister src = $src$$FloatRegister;

    __ cvt_d_s(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct convD2F_reg_reg(regF dst, regD src) %{
  match(Set dst (ConvD2F src));
  format %{ "convD2F  $dst, $src\t# @convD2F_reg_reg" %}
  ins_encode %{
    FloatRegister dst = $dst$$FloatRegister;
    FloatRegister src = $src$$FloatRegister;

    __ cvt_s_d(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}


// Convert a double to an int.  If the double is a NAN, stuff a zero in instead.
instruct convD2I_reg_reg_fast( mRegI dst, regD src ) %{
  match(Set dst (ConvD2I src));

  ins_cost(150);
  format %{ "convD2I $dst, $src\t# @ convD2I_reg_reg_fast" %}

  ins_encode %{
    FloatRegister src = $src$$FloatRegister;
    Register      dst = $dst$$Register;

    Label Done;

    __ trunc_w_d(F30, src);
    // max_int: 2147483647
    __ move(AT, 0x7fffffff);
    __ mfc1(dst, F30);

    __ bne(dst, AT, Done);
    __ delayed()->mtc1(R0, F30);

    __ cvt_d_w(F30, F30);
    __ c_ult_d(src, F30);
    __ bc1f(Done);
    __ delayed()->addiu(T9, R0, -1);

    __ c_un_d(src, src);    //NaN?
    __ subu32(dst, T9, AT);
    __ movt(dst, R0);

    __ bind(Done);
  %}
  ins_pipe( pipe_slow );
%}


instruct convD2I_reg_reg_slow( mRegI dst, regD src ) %{
  match(Set dst (ConvD2I src));

  ins_cost(250);
  format %{ "convD2I $dst, $src\t# @ convD2I_reg_reg_slow" %}

  ins_encode %{
    FloatRegister src = $src$$FloatRegister;
    Register      dst = $dst$$Register;
    Label L;

    __ trunc_w_d(F30, src);
    __ cfc1(AT, 31);
    __ li(T9, 0x10000);
    __ andr(AT, AT, T9);
    __ beq(AT, R0, L);
    __ delayed()->mfc1(dst, F30);

    __ mov_d(F12, src);
    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::d2i), 1);
    __ move(dst, V0);
    __ bind(L);

  %}
  ins_pipe( pipe_slow );
%}

// Convert oop pointer into compressed form
instruct encodeHeapOop(mRegN dst, mRegP src) %{
  predicate(n->bottom_type()->make_ptr()->ptr() != TypePtr::NotNull);
  match(Set dst (EncodeP src));
  format %{ "encode_heap_oop $dst,$src" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

    __ encode_heap_oop(dst, src);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct encodeHeapOop_not_null(mRegN dst, mRegP src) %{
  predicate(n->bottom_type()->make_ptr()->ptr() == TypePtr::NotNull);
  match(Set dst (EncodeP src));
  format %{ "encode_heap_oop_not_null $dst,$src @ encodeHeapOop_not_null" %}
  ins_encode %{
    __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct decodeHeapOop(mRegP dst, mRegN src) %{
  predicate(n->bottom_type()->is_ptr()->ptr() != TypePtr::NotNull &&
            n->bottom_type()->is_ptr()->ptr() != TypePtr::Constant);
  match(Set dst (DecodeN src));
  format %{ "decode_heap_oop $dst,$src @ decodeHeapOop" %}
  ins_encode %{
    Register s = $src$$Register;
    Register d = $dst$$Register;

    __ decode_heap_oop(d, s);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct decodeHeapOop_not_null(mRegP dst, mRegN src) %{
  predicate(n->bottom_type()->is_ptr()->ptr() == TypePtr::NotNull ||
            n->bottom_type()->is_ptr()->ptr() == TypePtr::Constant);
  match(Set dst (DecodeN src));
  format %{ "decode_heap_oop_not_null $dst,$src @ decodeHeapOop_not_null" %}
  ins_encode %{
    Register s = $src$$Register;
    Register d = $dst$$Register;
    if (s != d) {
      __ decode_heap_oop_not_null(d, s);
    } else {
      __ decode_heap_oop_not_null(d);
    }
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct encodeKlass_not_null(mRegN dst, mRegP src) %{
  match(Set dst (EncodePKlass src));
  format %{ "encode_heap_oop_not_null $dst,$src @ encodeKlass_not_null" %}
  ins_encode %{
    __ encode_klass_not_null($dst$$Register, $src$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct decodeKlass_not_null(mRegP dst, mRegN src) %{
  match(Set dst (DecodeNKlass src));
  format %{ "decode_heap_klass_not_null $dst,$src" %}
  ins_encode %{
    Register s = $src$$Register;
    Register d = $dst$$Register;
    if (s != d) {
      __ decode_klass_not_null(d, s);
    } else {
      __ decode_klass_not_null(d);
    }
  %}
  ins_pipe( ialu_regL_regL );
%}

//FIXME
instruct tlsLoadP(mRegP dst) %{
  match(Set dst (ThreadLocal));

  ins_cost(0);
  format %{ " get_thread in $dst #@tlsLoadP" %}
  ins_encode %{
    Register dst = $dst$$Register;
#ifdef OPT_THREAD
    __ move(dst, TREG);
#else
    __ get_thread(dst);
#endif
  %}

  ins_pipe( ialu_loadI );
%}


instruct checkCastPP( mRegP dst ) %{
  match(Set dst (CheckCastPP dst));

  format %{ "#checkcastPP of $dst (empty encoding) #@chekCastPP" %}
  ins_encode( /*empty encoding*/ );
  ins_pipe( empty );
%}

instruct castPP(mRegP dst)
%{
  match(Set dst (CastPP dst));

  size(0);
  format %{ "# castPP of $dst" %}
  ins_encode(/* empty encoding */);
  ins_pipe(empty);
%}

instruct castII( mRegI dst ) %{
  match(Set dst (CastII dst));
  format %{ "#castII of $dst  empty encoding" %}
  ins_encode( /*empty encoding*/ );
  ins_cost(0);
  ins_pipe( empty );
%}

// Return Instruction
// Remove the return address & jump to it.
instruct Ret() %{
  match(Return);
  format %{ "RET #@Ret" %}

  ins_encode %{
   __ jr(RA);
   __ delayed()->nop();
  %}

  ins_pipe( pipe_jump );
%}

/*
// For Loongson CPUs, jr seems too slow, so this rule shouldn't be imported.
instruct jumpXtnd(mRegL switch_val) %{
  match(Jump switch_val);

  ins_cost(350);

  format %{  "load   T9 <-- [$constanttablebase, $switch_val, $constantoffset] @ jumpXtnd\n\t"
             "jr     T9\n\t"
             "nop" %}
  ins_encode %{
    Register table_base = $constanttablebase;
    int      con_offset = $constantoffset;
    Register switch_reg = $switch_val$$Register;

    if (UseLEXT1) {
       if (Assembler::is_simm(con_offset, 8)) {
         __ gsldx(T9, table_base, switch_reg, con_offset);
       } else if (Assembler::is_simm16(con_offset)) {
         __ daddu(T9, table_base, switch_reg);
         __ ld(T9, T9, con_offset);
       } else {
         __ move(T9, con_offset);
         __ daddu(AT, table_base, switch_reg);
         __ gsldx(T9, AT, T9, 0);
       }
    } else {
       if (Assembler::is_simm16(con_offset)) {
         __ daddu(T9, table_base, switch_reg);
         __ ld(T9, T9, con_offset);
       } else {
         __ move(T9, con_offset);
         __ daddu(AT, table_base, switch_reg);
         __ daddu(AT, T9, AT);
         __ ld(T9, AT, 0);
       }
    }

    __ jr(T9);
    __ delayed()->nop();

  %}
  ins_pipe(pipe_jump);
%}
*/


// Tail Jump; remove the return address; jump to target.
// TailCall above leaves the return address around.
// TailJump is used in only one place, the rethrow_Java stub (fancy_jump=2).
// ex_oop (Exception Oop) is needed in %o0 at the jump. As there would be a
// "restore" before this instruction (in Epilogue), we need to materialize it
// in %i0.
//FIXME
instruct tailjmpInd(mRegP jump_target,mRegP ex_oop) %{
  match( TailJump jump_target ex_oop );
  ins_cost(200);
  format %{ "Jmp     $jump_target  ; ex_oop = $ex_oop #@tailjmpInd" %}
  ins_encode %{
    Register target = $jump_target$$Register;

    // V0, V1 are indicated in:
    //     [stubGenerator_mips.cpp] generate_forward_exception()
    //     [runtime_mips.cpp] OptoRuntime::generate_exception_blob()
    //
    Register oop  = $ex_oop$$Register;
    Register exception_oop = V0;
    Register exception_pc = V1;

    __ move(exception_pc, RA);
    __ move(exception_oop, oop);

    __ jr(target);
    __ delayed()->nop();
  %}
  ins_pipe( pipe_jump );
%}

// ============================================================================
// Procedure Call/Return Instructions
// Call Java Static Instruction
// Note: If this code changes, the corresponding ret_addr_offset() and
//       compute_padding() functions will have to be adjusted.
instruct CallStaticJavaDirect(method meth) %{
  match(CallStaticJava);
  effect(USE meth);

  ins_cost(300);
  format %{ "CALL,static #@CallStaticJavaDirect " %}
  ins_encode( Java_Static_Call( meth ) );
  ins_pipe( pipe_slow );
  ins_pc_relative(1);
  ins_alignment(16);
%}

// Call Java Dynamic Instruction
// Note: If this code changes, the corresponding ret_addr_offset() and
//       compute_padding() functions will have to be adjusted.
instruct CallDynamicJavaDirect(method meth) %{
  match(CallDynamicJava);
  effect(USE meth);

  ins_cost(300);
  format %{"MOV IC_Klass, #Universe::non_oop_word()\n\t"
           "CallDynamic @ CallDynamicJavaDirect" %}
  ins_encode( Java_Dynamic_Call( meth ) );
  ins_pipe( pipe_slow );
  ins_pc_relative(1);
  ins_alignment(16);
%}

instruct CallLeafNoFPDirect(method meth) %{
  match(CallLeafNoFP);
  effect(USE meth);

  ins_cost(300);
  format %{ "CALL_LEAF_NOFP,runtime " %}
  ins_encode(Java_To_Runtime(meth));
  ins_pipe( pipe_slow );
  ins_pc_relative(1);
  ins_alignment(16);
%}

// Prefetch instructions.

instruct prefetchrNTA( memory mem ) %{
  match(PrefetchRead mem);
  ins_cost(125);

  format %{ "pref $mem\t# Prefetch into non-temporal cache for read @ prefetchrNTA" %}
  ins_encode %{
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if (scale == 0) {
        __ daddu(AT, as_Register(base), as_Register(index));
      } else {
        __ dsll(AT, as_Register(index), scale);
        __ daddu(AT, as_Register(base), AT);
      }
    } else {
      __ move(AT, as_Register(base));
    }
    if( Assembler::is_simm16(disp) ) {
      __ daddiu(AT, AT, disp);
    } else {
      __ move(T9, disp);
      __ daddu(AT, AT, T9);
    }
    __ pref(0, AT, 0); //hint: 0:load
  %}
  ins_pipe(pipe_slow);
%}

instruct prefetchwNTA( memory mem ) %{
  match(PrefetchWrite mem);
  ins_cost(125);
  format %{ "pref $mem\t# Prefetch to non-temporal cache for write @ prefetchwNTA" %}
  ins_encode %{
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if (scale == 0) {
        __ daddu(AT, as_Register(base), as_Register(index));
      } else {
        __ dsll(AT, as_Register(index), scale);
        __ daddu(AT, as_Register(base), AT);
      }
    } else {
      __ move(AT, as_Register(base));
    }
    if( Assembler::is_simm16(disp) ) {
      __ daddiu(AT, AT, disp);
    } else {
      __ move(T9, disp);
      __ daddu(AT, AT, T9);
    }
     __ pref(1, AT, 0); //hint: 1:store
  %}
  ins_pipe(pipe_slow);
%}

// Prefetch instructions for allocation.

instruct prefetchAllocNTA( memory mem ) %{
  match(PrefetchAllocation mem);
  ins_cost(125);
  format %{ "pref $mem\t# Prefetch allocation @ prefetchAllocNTA" %}
  ins_encode %{
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    Register dst = R0;

    if ( index != 0 ) {
      if ( Assembler::is_simm16(disp) ) {
        if (UseLEXT1) {
          if (scale == 0) {
            __ gslbx(dst, as_Register(base), as_Register(index), disp);
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ gslbx(dst, as_Register(base), AT, disp);
          }
        } else {
          if (scale == 0) {
            __ addu(AT, as_Register(base), as_Register(index));
          } else {
            __ dsll(AT, as_Register(index), scale);
            __ addu(AT, as_Register(base), AT);
          }
          __ lb(dst, AT, disp);
        }
      } else {
        if (scale == 0) {
          __ addu(AT, as_Register(base), as_Register(index));
        } else {
          __ dsll(AT, as_Register(index), scale);
          __ addu(AT, as_Register(base), AT);
        }
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gslbx(dst, AT, T9, 0);
        } else {
          __ addu(AT, AT, T9);
          __ lb(dst, AT, 0);
        }
      }
    } else {
      if ( Assembler::is_simm16(disp) ) {
        __ lb(dst, as_Register(base), disp);
      } else {
        __ move(T9, disp);
        if (UseLEXT1) {
          __ gslbx(dst, as_Register(base), T9, 0);
        } else {
          __ addu(AT, as_Register(base), T9);
          __ lb(dst, AT, 0);
        }
      }
    }
  %}
  ins_pipe(pipe_slow);
%}


// Call runtime without safepoint
instruct CallLeafDirect(method meth) %{
  match(CallLeaf);
  effect(USE meth);

  ins_cost(300);
  format %{ "CALL_LEAF,runtime #@CallLeafDirect " %}
  ins_encode(Java_To_Runtime(meth));
  ins_pipe( pipe_slow );
  ins_pc_relative(1);
  ins_alignment(16);
%}

// Load Char (16bit unsigned)
instruct loadUS(mRegI dst, memory mem) %{
  match(Set dst (LoadUS mem));

  ins_cost(125);
  format %{ "loadUS  $dst,$mem @ loadC" %}
  ins_encode(load_C_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

instruct loadUS_convI2L(mRegL dst, memory mem) %{
  match(Set dst (ConvI2L (LoadUS mem)));

  ins_cost(125);
  format %{ "loadUS  $dst,$mem @ loadUS_convI2L" %}
  ins_encode(load_C_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Store Char (16bit unsigned)
instruct storeC(memory mem, mRegI src) %{
  match(Set mem (StoreC mem src));

  ins_cost(125);
  format %{ "storeC  $src, $mem @ storeC" %}
  ins_encode(store_C_reg_enc(mem, src));
  ins_pipe( ialu_loadI );
%}

instruct storeC_0(memory mem, immI_0 zero) %{
  match(Set mem (StoreC mem zero));

  ins_cost(125);
  format %{ "storeC  $zero, $mem @ storeC_0" %}
  ins_encode(store_C0_enc(mem));
  ins_pipe( ialu_loadI );
%}


instruct loadConF_immF_0(regF dst, immF_0 zero) %{
  match(Set dst zero);
  ins_cost(100);

  format %{ "mov  $dst, zero @ loadConF_immF_0\n"%}
  ins_encode %{
    FloatRegister dst = $dst$$FloatRegister;

    __ mtc1(R0, dst);
  %}
  ins_pipe( fpu_loadF );
%}


instruct loadConF(regF dst, immF src) %{
  match(Set dst src);
  ins_cost(125);

  format %{ "lwc1  $dst, $constantoffset[$constanttablebase] # load FLOAT $src from table @ loadConF" %}
  ins_encode %{
    int con_offset = $constantoffset($src);

    if (Assembler::is_simm16(con_offset)) {
      __ lwc1($dst$$FloatRegister, $constanttablebase, con_offset);
    } else {
      __ set64(AT, con_offset);
      if (UseLEXT1) {
        __ gslwxc1($dst$$FloatRegister, $constanttablebase, AT, 0);
      } else {
        __ daddu(AT, $constanttablebase, AT);
        __ lwc1($dst$$FloatRegister, AT, 0);
      }
    }
  %}
  ins_pipe( fpu_loadF );
%}


instruct loadConD_immD_0(regD dst, immD_0 zero) %{
  match(Set dst zero);
  ins_cost(100);

  format %{ "mov  $dst, zero @ loadConD_immD_0"%}
  ins_encode %{
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ dmtc1(R0, dst);
  %}
  ins_pipe( fpu_loadF );
%}

instruct loadConD(regD dst, immD src) %{
  match(Set dst src);
  ins_cost(125);

  format %{ "ldc1  $dst, $constantoffset[$constanttablebase] # load DOUBLE $src from table @ loadConD" %}
  ins_encode %{
    int con_offset = $constantoffset($src);

    if (Assembler::is_simm16(con_offset)) {
      __ ldc1($dst$$FloatRegister, $constanttablebase, con_offset);
    } else {
      __ set64(AT, con_offset);
      if (UseLEXT1) {
        __ gsldxc1($dst$$FloatRegister, $constanttablebase, AT, 0);
      } else {
        __ daddu(AT, $constanttablebase, AT);
        __ ldc1($dst$$FloatRegister, AT, 0);
      }
    }
  %}
  ins_pipe( fpu_loadF );
%}

// Store register Float value (it is faster than store from FPU register)
instruct storeF_reg( memory mem, regF src) %{
  match(Set mem (StoreF mem src));

  ins_cost(50);
  format %{ "store   $mem, $src\t# store float @ storeF_reg" %}
  ins_encode(store_F_reg_enc(mem, src));
  ins_pipe( fpu_storeF );
%}

instruct storeF_immF_0( memory mem, immF_0 zero) %{
  match(Set mem (StoreF mem zero));

  ins_cost(40);
  format %{ "store   $mem, zero\t# store float @ storeF_immF_0" %}
  ins_encode %{
    int      base = $mem$$base;
    int     index = $mem$$index;
    int     scale = $mem$$scale;
    int      disp = $mem$$disp;

    if( index != 0 ) {
      if (UseLEXT1) {
        if ( Assembler::is_simm(disp, 8) ) {
          if ( scale == 0 ) {
            __ gsswx(R0, as_Register(base), as_Register(index), disp);
          } else {
            __ dsll(T9, as_Register(index), scale);
            __ gsswx(R0, as_Register(base), T9, disp);
          }
        } else if ( Assembler::is_simm16(disp) ) {
          if ( scale == 0 ) {
            __ daddu(AT, as_Register(base), as_Register(index));
          } else {
            __ dsll(T9, as_Register(index), scale);
            __ daddu(AT, as_Register(base), T9);
          }
          __ sw(R0, AT, disp);
        } else {
          if ( scale == 0 ) {
            __ move(T9, disp);
            __ daddu(AT, as_Register(index), T9);
            __ gsswx(R0, as_Register(base), AT, 0);
          } else {
            __ dsll(T9, as_Register(index), scale);
            __ move(AT, disp);
            __ daddu(AT, AT, T9);
            __ gsswx(R0, as_Register(base), AT, 0);
          }
        }
      } else { //not use loongson isa
        if(scale != 0) {
          __ dsll(T9, as_Register(index), scale);
          __ daddu(AT, as_Register(base), T9);
        } else {
          __ daddu(AT, as_Register(base), as_Register(index));
        }
        if( Assembler::is_simm16(disp) ) {
          __ sw(R0, AT, disp);
        } else {
          __ move(T9, disp);
          __ daddu(AT, AT, T9);
          __ sw(R0, AT, 0);
        }
      }
    } else { //index is 0
      if (UseLEXT1) {
        if ( Assembler::is_simm16(disp) ) {
          __ sw(R0, as_Register(base), disp);
        } else {
          __ move(T9, disp);
          __ gsswx(R0, as_Register(base), T9, 0);
        }
      } else {
        if( Assembler::is_simm16(disp) ) {
          __ sw(R0, as_Register(base), disp);
        } else {
          __ move(T9, disp);
          __ daddu(AT, as_Register(base), T9);
          __ sw(R0, AT, 0);
        }
      }
    }
  %}
  ins_pipe( ialu_storeI );
%}

// Load Double
instruct loadD(regD dst, memory mem) %{
  match(Set dst (LoadD mem));

  ins_cost(150);
  format %{ "loadD   $dst, $mem #@loadD" %}
  ins_encode(load_D_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Load Double - UNaligned
instruct loadD_unaligned(regD dst, memory mem ) %{
  match(Set dst (LoadD_unaligned mem));
  ins_cost(250);
  // FIXME: Need more effective ldl/ldr
  format %{ "loadD_unaligned   $dst, $mem #@loadD_unaligned" %}
  ins_encode(load_D_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

instruct storeD_reg( memory mem, regD src) %{
  match(Set mem (StoreD mem src));

  ins_cost(50);
  format %{ "store   $mem, $src\t# store float @ storeD_reg" %}
  ins_encode(store_D_reg_enc(mem, src));
  ins_pipe( fpu_storeF );
%}

instruct storeD_immD_0( memory mem, immD_0 zero) %{
  match(Set mem (StoreD mem zero));

  ins_cost(40);
  format %{ "store   $mem, zero\t# store float @ storeD_immD_0" %}
  ins_encode %{
    int      base = $mem$$base;
    int     index = $mem$$index;
    int     scale = $mem$$scale;
    int      disp = $mem$$disp;

    __ mtc1(R0, F30);
    __ cvt_d_w(F30, F30);

    if( index != 0 ) {
    if (UseLEXT1) {
      if ( Assembler::is_simm(disp, 8) ) {
        if (scale == 0) {
          __ gssdxc1(F30, as_Register(base), as_Register(index), disp);
        } else {
          __ dsll(T9, as_Register(index), scale);
          __ gssdxc1(F30, as_Register(base), T9, disp);
        }
      } else if ( Assembler::is_simm16(disp) ) {
        if (scale == 0) {
          __ daddu(AT, as_Register(base), as_Register(index));
          __ sdc1(F30, AT, disp);
        } else {
          __ dsll(T9, as_Register(index), scale);
          __ daddu(AT, as_Register(base), T9);
          __ sdc1(F30, AT, disp);
        }
      } else {
        if (scale == 0) {
          __ move(T9, disp);
          __ daddu(AT, as_Register(index), T9);
          __ gssdxc1(F30, as_Register(base), AT, 0);
        } else {
          __ move(T9, disp);
          __ dsll(AT, as_Register(index), scale);
          __ daddu(AT, AT, T9);
          __ gssdxc1(F30, as_Register(base), AT, 0);
        }
      }
    } else { // not use loongson isa
        if(scale != 0) {
           __ dsll(T9, as_Register(index), scale);
           __ daddu(AT, as_Register(base), T9);
        } else {
           __ daddu(AT, as_Register(base), as_Register(index));
        }
       if( Assembler::is_simm16(disp) ) {
          __ sdc1(F30, AT, disp);
       } else {
          __ move(T9, disp);
          __ daddu(AT, AT, T9);
          __ sdc1(F30, AT, 0);
       }
    }
    } else {// index is 0
    if (UseLEXT1) {
      if ( Assembler::is_simm16(disp) ) {
        __ sdc1(F30, as_Register(base), disp);
      } else {
        __ move(T9, disp);
        __ gssdxc1(F30, as_Register(base), T9, 0);
      }
    } else {
       if( Assembler::is_simm16(disp) ) {
          __ sdc1(F30, as_Register(base), disp);
       } else {
          __ move(T9, disp);
          __ daddu(AT, as_Register(base), T9);
          __ sdc1(F30, AT, 0);
       }
    }
    }
  %}
  ins_pipe( ialu_storeI );
%}

instruct loadSSI(mRegI dst, stackSlotI src)
%{
  match(Set dst src);

  ins_cost(125);
  format %{ "lw    $dst, $src\t# int stk @ loadSSI" %}
  ins_encode %{
    guarantee( Assembler::is_simm16($src$$disp), "disp too long (loadSSI) !");
    __ lw($dst$$Register, SP, $src$$disp);
  %}
  ins_pipe(ialu_loadI);
%}

instruct storeSSI(stackSlotI dst, mRegI src)
%{
  match(Set dst src);

  ins_cost(100);
  format %{ "sw    $dst, $src\t# int stk @ storeSSI" %}
  ins_encode %{
    guarantee( Assembler::is_simm16($dst$$disp), "disp too long (storeSSI) !");
    __ sw($src$$Register, SP, $dst$$disp);
  %}
  ins_pipe(ialu_storeI);
%}

instruct loadSSL(mRegL dst, stackSlotL src)
%{
  match(Set dst src);

  ins_cost(125);
  format %{ "ld    $dst, $src\t# long stk @ loadSSL" %}
  ins_encode %{
    guarantee( Assembler::is_simm16($src$$disp), "disp too long (loadSSL) !");
    __ ld($dst$$Register, SP, $src$$disp);
  %}
  ins_pipe(ialu_loadI);
%}

instruct storeSSL(stackSlotL dst, mRegL src)
%{
  match(Set dst src);

  ins_cost(100);
  format %{ "sd    $dst, $src\t# long stk @ storeSSL" %}
  ins_encode %{
    guarantee( Assembler::is_simm16($dst$$disp), "disp too long (storeSSL) !");
    __ sd($src$$Register, SP, $dst$$disp);
  %}
  ins_pipe(ialu_storeI);
%}

instruct loadSSP(mRegP dst, stackSlotP src)
%{
  match(Set dst src);

  ins_cost(125);
  format %{ "ld    $dst, $src\t# ptr stk @ loadSSP" %}
  ins_encode %{
    guarantee( Assembler::is_simm16($src$$disp), "disp too long (loadSSP) !");
    __ ld($dst$$Register, SP, $src$$disp);
  %}
  ins_pipe(ialu_loadI);
%}

instruct storeSSP(stackSlotP dst, mRegP src)
%{
  match(Set dst src);

  ins_cost(100);
  format %{ "sd    $dst, $src\t# ptr stk @ storeSSP" %}
  ins_encode %{
    guarantee( Assembler::is_simm16($dst$$disp), "disp too long (storeSSP) !");
    __ sd($src$$Register, SP, $dst$$disp);
  %}
  ins_pipe(ialu_storeI);
%}

instruct loadSSF(regF dst, stackSlotF src)
%{
  match(Set dst src);

  ins_cost(125);
  format %{ "lwc1   $dst, $src\t# float stk @ loadSSF" %}
  ins_encode %{
    guarantee( Assembler::is_simm16($src$$disp), "disp too long (loadSSF) !");
    __ lwc1($dst$$FloatRegister, SP, $src$$disp);
  %}
  ins_pipe(ialu_loadI);
%}

instruct storeSSF(stackSlotF dst, regF src)
%{
  match(Set dst src);

  ins_cost(100);
  format %{ "swc1    $dst, $src\t# float stk @ storeSSF" %}
  ins_encode %{
    guarantee( Assembler::is_simm16($dst$$disp), "disp too long (storeSSF) !");
    __ swc1($src$$FloatRegister, SP, $dst$$disp);
  %}
  ins_pipe(fpu_storeF);
%}

// Use the same format since predicate() can not be used here.
instruct loadSSD(regD dst, stackSlotD src)
%{
  match(Set dst src);

  ins_cost(125);
  format %{ "ldc1   $dst, $src\t# double stk @ loadSSD" %}
  ins_encode %{
    guarantee( Assembler::is_simm16($src$$disp), "disp too long (loadSSD) !");
    __ ldc1($dst$$FloatRegister, SP, $src$$disp);
  %}
  ins_pipe(ialu_loadI);
%}

instruct storeSSD(stackSlotD dst, regD src)
%{
  match(Set dst src);

  ins_cost(100);
  format %{ "sdc1    $dst, $src\t# double stk @ storeSSD" %}
  ins_encode %{
    guarantee( Assembler::is_simm16($dst$$disp), "disp too long (storeSSD) !");
    __ sdc1($src$$FloatRegister, SP, $dst$$disp);
  %}
  ins_pipe(fpu_storeF);
%}

instruct cmpFastLock( FlagsReg cr, mRegP object, s0_RegP box, mRegI tmp, mRegP scr) %{
  match( Set cr (FastLock object box) );
  effect( TEMP tmp, TEMP scr, USE_KILL box );
  ins_cost(300);
  format %{ "FASTLOCK $cr <-- $object, $box, $tmp, $scr #@ cmpFastLock" %}
  ins_encode %{
    __ fast_lock($object$$Register, $box$$Register, $tmp$$Register, $scr$$Register);
  %}

  ins_pipe( pipe_slow );
  ins_pc_relative(1);
%}

instruct cmpFastUnlock( FlagsReg cr, mRegP object, s0_RegP box, mRegP tmp ) %{
  match( Set cr (FastUnlock object box) );
  effect( TEMP tmp, USE_KILL box );
  ins_cost(300);
  format %{ "FASTUNLOCK $cr <-- $object, $box, $tmp #@cmpFastUnlock" %}
  ins_encode %{
    __ fast_unlock($object$$Register, $box$$Register, $tmp$$Register);
  %}

  ins_pipe( pipe_slow );
  ins_pc_relative(1);
%}

// Store CMS card-mark Immediate
instruct storeImmCM(memory mem, immI8 src) %{
  match(Set mem (StoreCM mem src));

  ins_cost(150);
  format %{ "MOV8   $mem,$src\t! CMS card-mark imm0" %}
//  opcode(0xC6);
  ins_encode(store_B_immI_enc_sync(mem, src));
  ins_pipe( ialu_storeI );
%}

// Die now
instruct ShouldNotReachHere( )
%{
  match(Halt);
  ins_cost(300);

  // Use the following format syntax
  format %{ "ILLTRAP   ;#@ShouldNotReachHere" %}
  ins_encode %{
    // Here we should emit illtrap !

    __ stop("in ShoudNotReachHere");

  %}
  ins_pipe( pipe_jump );
%}

instruct leaP8Narrow(mRegP dst, indOffset8Narrow mem)
%{
  predicate(Universe::narrow_oop_shift() == 0);
  match(Set dst mem);

  ins_cost(110);
  format %{ "leaq    $dst, $mem\t# ptr off8narrow @ leaP8Narrow" %}
  ins_encode %{
    Register  dst  = $dst$$Register;
    Register  base = as_Register($mem$$base);
    int       disp = $mem$$disp;

    __ daddiu(dst, base, disp);
  %}
  ins_pipe( ialu_regI_imm16 );
%}

instruct leaPPosIdxScaleOff8(mRegP dst, basePosIndexScaleOffset8 mem)
%{
  match(Set dst mem);

  ins_cost(110);
  format %{ "leaq    $dst, $mem\t# @ PosIdxScaleOff8" %}
  ins_encode %{
    Register  dst   = $dst$$Register;
    Register  base  = as_Register($mem$$base);
    Register  index = as_Register($mem$$index);
    int       scale = $mem$$scale;
    int       disp  = $mem$$disp;

    if (scale == 0) {
      __ daddu(AT, base, index);
      __ daddiu(dst, AT, disp);
    } else {
      __ dsll(AT, index, scale);
      __ daddu(AT, base, AT);
      __ daddiu(dst, AT, disp);
    }
 %}

  ins_pipe( ialu_regI_imm16 );
%}

instruct leaPIdxScale(mRegP dst, indIndexScale mem)
%{
  match(Set dst mem);

  ins_cost(110);
  format %{ "leaq    $dst, $mem\t# @ leaPIdxScale" %}
  ins_encode %{
    Register  dst   = $dst$$Register;
    Register  base  = as_Register($mem$$base);
    Register  index = as_Register($mem$$index);
    int       scale = $mem$$scale;

    if (scale == 0) {
       __ daddu(dst, base, index);
    } else {
       __ dsll(AT, index, scale);
       __ daddu(dst, base, AT);
    }
 %}

  ins_pipe( ialu_regI_imm16 );
%}


// ============================================================================
// The 2nd slow-half of a subtype check.  Scan the subklass's 2ndary superklass
// array for an instance of the superklass.  Set a hidden internal cache on a
// hit (cache is checked with exposed code in gen_subtype_check()).  Return
// NZ for a miss or zero for a hit.  The encoding ALSO sets flags.
instruct partialSubtypeCheck( mRegP result, no_T8_mRegP sub, no_T8_mRegP super, mT8RegI tmp ) %{
  match(Set result (PartialSubtypeCheck sub super));
  effect(KILL tmp);
  ins_cost(1100);  // slightly larger than the next version
  format %{ "partialSubtypeCheck result=$result, sub=$sub, super=$super, tmp=$tmp " %}

  ins_encode( enc_PartialSubtypeCheck(result, sub, super, tmp) );
  ins_pipe( pipe_slow );
%}

// Conditional-store of the updated heap-top.
// Used during allocation of the shared heap.

instruct storePConditional( memory heap_top_ptr, mRegP oldval, mRegP newval, FlagsReg cr ) %{
  match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));

  format %{ "CMPXCHG $heap_top_ptr, $newval\t# (ptr) @storePConditional "
            "If $oldval  == $heap_top_ptr then store $newval into $heap_top_ptr" %}
  ins_encode%{
    Register oldval = $oldval$$Register;
    Register newval = $newval$$Register;
    Address addr(as_Register($heap_top_ptr$$base), $heap_top_ptr$$disp);

    int     index = $heap_top_ptr$$index;
    int     scale = $heap_top_ptr$$scale;
    int      disp = $heap_top_ptr$$disp;

    guarantee(Assembler::is_simm16(disp), "");

    if( index != 0 ) {
      __ stop("in storePConditional: index != 0");
    } else {
      __ cmpxchg(newval, addr, oldval);
    }
  %}
  ins_pipe( long_memory_op );
%}

// Conditional-store of an int value.
// AT flag is set on success, reset otherwise.
instruct storeIConditional( memory mem, mRegI oldval, mRegI newval, FlagsReg cr ) %{
  match(Set cr (StoreIConditional mem (Binary oldval newval)));
//  effect(KILL oldval);
  format %{ "CMPXCHG  $newval, $mem, $oldval \t# @storeIConditional" %}

  ins_encode %{
    Register oldval = $oldval$$Register;
    Register newval = $newval$$Register;
    Address  addr(as_Register($mem$$base), $mem$$disp);
    Label    again, failure;

    int     index = $mem$$index;
    int     scale = $mem$$scale;
    int      disp = $mem$$disp;

    guarantee(Assembler::is_simm16(disp), "");

    if( index != 0 ) {
      __ stop("in storeIConditional: index != 0");
    } else {
      __ bind(again);
      if (UseSyncLevel >= 10000 || UseSyncLevel == 1000 || UseSyncLevel == 4000) __ sync();
      __ ll(AT, addr);
      __ bne(AT, oldval, failure);
      __ delayed()->addu(AT, R0, R0);

      __ addu(AT, newval, R0);
      __ sc(AT, addr);
      __ beq(AT, R0, again);
      __ delayed()->addiu(AT, R0, 0xFF);
      __ bind(failure);
      __ sync();
    }
%}

  ins_pipe( long_memory_op );
%}

// Conditional-store of a long value.
// ZF flag is set on success, reset otherwise.  Implemented with a CMPXCHG.
instruct storeLConditional(memory mem, t2RegL oldval, mRegL newval, FlagsReg cr )
%{
  match(Set cr (StoreLConditional mem (Binary oldval newval)));
  effect(KILL oldval);

  format %{ "cmpxchg $mem, $newval\t# If $oldval == $mem then store $newval into $mem" %}
  ins_encode%{
    Register oldval = $oldval$$Register;
    Register newval = $newval$$Register;
    Address addr(as_Register($mem$$base), $mem$$disp);

    int     index = $mem$$index;
    int     scale = $mem$$scale;
    int      disp = $mem$$disp;

    guarantee(Assembler::is_simm16(disp), "");

    if( index != 0 ) {
      __ stop("in storeIConditional: index != 0");
    } else {
      __ cmpxchg(newval, addr, oldval);
    }
  %}
  ins_pipe( long_memory_op );
%}

// Implement LoadPLocked. Must be ordered against changes of the memory location
// by storePConditional.
instruct loadPLocked(mRegP dst, memory mem) %{
  match(Set dst (LoadPLocked mem));
  ins_cost(MEMORY_REF_COST);

  format %{ "ld    $dst, $mem #@loadPLocked\n\t"
            "sync" %}
  size(12);
  ins_encode (load_P_enc_ac(dst, mem));
  ins_pipe( ialu_loadI );
%}


instruct compareAndSwapI( mRegI res, mRegP mem_ptr, mS2RegI oldval, mRegI newval) %{
  match(Set res (CompareAndSwapI mem_ptr (Binary oldval newval)));
  effect(KILL oldval);
//  match(CompareAndSwapI mem_ptr (Binary oldval newval));
  format %{ "CMPXCHG $newval, [$mem_ptr], $oldval @ compareAndSwapL\n\t"
            "MOV    $res, 1 @ compareAndSwapI\n\t"
            "BNE    AT, R0 @ compareAndSwapI\n\t"
            "MOV    $res, 0 @ compareAndSwapI\n"
          "L:" %}
  ins_encode %{
    Register newval = $newval$$Register;
    Register oldval = $oldval$$Register;
    Register res    = $res$$Register;
    Address  addr($mem_ptr$$Register, 0);
    Label L;

    __ cmpxchg32(newval, addr, oldval);
    __ move(res, AT);
  %}
  ins_pipe( long_memory_op );
%}

instruct compareAndSwapL( mRegI res, mRegP mem_ptr, s2RegL oldval, mRegL newval) %{
  predicate(VM_Version::supports_cx8());
  match(Set res (CompareAndSwapL mem_ptr (Binary oldval newval)));
  effect(KILL oldval);
  format %{ "CMPXCHG $newval, [$mem_ptr], $oldval @ compareAndSwapI\n\t"
            "MOV    $res, 1 @ compareAndSwapI\n\t"
            "BNE    AT, R0 @ compareAndSwapI\n\t"
            "MOV    $res, 0 @ compareAndSwapI\n"
          "L:" %}
  ins_encode %{
    Register newval = $newval$$Register;
    Register oldval = $oldval$$Register;
    Register res    = $res$$Register;
    Address  addr($mem_ptr$$Register, 0);
    Label L;

    __ cmpxchg(newval, addr, oldval);
    __ move(res, AT);
  %}
  ins_pipe( long_memory_op );
%}

//FIXME:
instruct compareAndSwapP( mRegI res, mRegP mem_ptr, s2_RegP oldval, mRegP newval) %{
  match(Set res (CompareAndSwapP mem_ptr (Binary oldval newval)));
  effect(KILL oldval);
  format %{ "CMPXCHG $newval, [$mem_ptr], $oldval @ compareAndSwapP\n\t"
            "MOV    $res, AT @ compareAndSwapP\n\t"
          "L:" %}
  ins_encode %{
    Register newval = $newval$$Register;
    Register oldval = $oldval$$Register;
    Register res    = $res$$Register;
    Address  addr($mem_ptr$$Register, 0);
    Label L;

    __ cmpxchg(newval, addr, oldval);
    __ move(res, AT);
  %}
  ins_pipe( long_memory_op );
%}

instruct compareAndSwapN( mRegI res, mRegP mem_ptr, t2_RegN oldval, mRegN newval) %{
  match(Set res (CompareAndSwapN mem_ptr (Binary oldval newval)));
  effect(KILL oldval);
  format %{ "CMPXCHG $newval, [$mem_ptr], $oldval @ compareAndSwapN\n\t"
            "MOV    $res, AT @ compareAndSwapN\n\t"
          "L:" %}
  ins_encode %{
    Register newval = $newval$$Register;
    Register oldval = $oldval$$Register;
    Register res    = $res$$Register;
    Address  addr($mem_ptr$$Register, 0);
    Label L;

    // cmpxchg32 is implemented with ll/sc, which will do sign extension.
    //      Thus, we should extend oldval's sign for correct comparision.
    //
    __ sll(oldval, oldval, 0);

    __ cmpxchg32(newval, addr, oldval);
    __ move(res, AT);
  %}
  ins_pipe( long_memory_op );
%}

//----------Max and Min--------------------------------------------------------
// Min Instructions
////
//   *** Min and Max using the conditional move are slower than the
//   *** branch version on a Pentium III.
// // Conditional move for min
//instruct cmovI_reg_lt( eRegI op2, eRegI op1, eFlagsReg cr ) %{
//  effect( USE_DEF op2, USE op1, USE cr );
//  format %{ "CMOVlt $op2,$op1\t! min" %}
//  opcode(0x4C,0x0F);
//  ins_encode( OpcS, OpcP, RegReg( op2, op1 ) );
//  ins_pipe( pipe_cmov_reg );
//%}
//
//// Min Register with Register (P6 version)
//instruct minI_eReg_p6( eRegI op1, eRegI op2 ) %{
//  predicate(VM_Version::supports_cmov() );
//  match(Set op2 (MinI op1 op2));
//  ins_cost(200);
//  expand %{
//    eFlagsReg cr;
//    compI_eReg(cr,op1,op2);
//    cmovI_reg_lt(op2,op1,cr);
//  %}
//%}

// Min Register with Register (generic version)
instruct minI_Reg_Reg(mRegI dst, mRegI src) %{
  match(Set dst (MinI dst src));
  //effect(KILL flags);
  ins_cost(80);

  format %{ "MIN    $dst, $src @minI_Reg_Reg" %}
  ins_encode %{
    Register dst   = $dst$$Register;
    Register src   = $src$$Register;

    __ slt(AT, src, dst);
    __ movn(dst, src, AT);

  %}

  ins_pipe( pipe_slow );
%}

// Max Register with Register
//   *** Min and Max using the conditional move are slower than the
//   *** branch version on a Pentium III.
// // Conditional move for max
//instruct cmovI_reg_gt( eRegI op2, eRegI op1, eFlagsReg cr ) %{
//  effect( USE_DEF op2, USE op1, USE cr );
//  format %{ "CMOVgt $op2,$op1\t! max" %}
//  opcode(0x4F,0x0F);
//  ins_encode( OpcS, OpcP, RegReg( op2, op1 ) );
//  ins_pipe( pipe_cmov_reg );
//%}
//
// // Max Register with Register (P6 version)
//instruct maxI_eReg_p6( eRegI op1, eRegI op2 ) %{
//  predicate(VM_Version::supports_cmov() );
//  match(Set op2 (MaxI op1 op2));
//  ins_cost(200);
//  expand %{
//    eFlagsReg cr;
//    compI_eReg(cr,op1,op2);
//    cmovI_reg_gt(op2,op1,cr);
//  %}
//%}

// Max Register with Register (generic version)
instruct maxI_Reg_Reg(mRegI dst, mRegI src) %{
  match(Set dst (MaxI dst src));
  ins_cost(80);

  format %{ "MAX    $dst, $src @maxI_Reg_Reg" %}

  ins_encode %{
    Register dst   = $dst$$Register;
    Register src   = $src$$Register;

    __ slt(AT, dst, src);
    __ movn(dst, src, AT);

  %}

  ins_pipe( pipe_slow );
%}

instruct maxI_Reg_zero(mRegI dst, immI_0 zero) %{
  match(Set dst (MaxI dst zero));
  ins_cost(50);

  format %{ "MAX    $dst, 0 @maxI_Reg_zero" %}

  ins_encode %{
    Register dst   = $dst$$Register;

    __ slt(AT, dst, R0);
    __ movn(dst, R0, AT);

  %}

  ins_pipe( pipe_slow );
%}

instruct zerox_long_reg_reg(mRegL dst, mRegL src, immL_MaxUI mask)
%{
  match(Set dst (AndL src mask));

  format %{ "movl    $dst, $src\t# zero-extend long @ zerox_long_reg_reg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;

    __ dext(dst, src, 0, 32);
  %}
  ins_pipe(ialu_regI_regI);
%}

instruct combine_i2l(mRegL dst, mRegI src1, immL_MaxUI mask, mRegI src2, immI_32 shift32)
%{
  match(Set dst (OrL (AndL (ConvI2L src1) mask) (LShiftL (ConvI2L src2) shift32)));

  format %{ "combine_i2l    $dst, $src2(H), $src1(L) @ combine_i2l" %}
  ins_encode %{
    Register dst  = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    if (src1 == dst) {
       __ dinsu(dst, src2, 32, 32);
    } else if (src2 == dst) {
       __ dsll32(dst, dst, 0);
       __ dins(dst, src1, 0, 32);
    } else {
       __ dext(dst, src1, 0, 32);
       __ dinsu(dst, src2, 32, 32);
    }
  %}
  ins_pipe(ialu_regI_regI);
%}

// Zero-extend convert int to long
instruct convI2L_reg_reg_zex(mRegL dst, mRegI src, immL_MaxUI mask)
%{
  match(Set dst (AndL (ConvI2L src) mask));

  format %{ "movl    $dst, $src\t# i2l zero-extend @ convI2L_reg_reg_zex" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;

    __ dext(dst, src, 0, 32);
  %}
  ins_pipe(ialu_regI_regI);
%}

instruct convL2I2L_reg_reg_zex(mRegL dst, mRegL src, immL_MaxUI mask)
%{
  match(Set dst (AndL (ConvI2L (ConvL2I src)) mask));

  format %{ "movl    $dst, $src\t# i2l zero-extend @ convL2I2L_reg_reg_zex" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;

    __ dext(dst, src, 0, 32);
  %}
  ins_pipe(ialu_regI_regI);
%}

// Match loading integer and casting it to unsigned int in long register.
// LoadI + ConvI2L + AndL 0xffffffff.
instruct loadUI2L_rmask(mRegL dst, memory mem, immL_MaxUI mask) %{
  match(Set dst (AndL (ConvI2L (LoadI mem)) mask));

  format %{ "lwu     $dst, $mem \t// zero-extend to long @ loadUI2L_rmask" %}
  ins_encode (load_N_enc(dst, mem));
  ins_pipe(ialu_loadI);
%}

instruct loadUI2L_lmask(mRegL dst, memory mem, immL_MaxUI mask) %{
  match(Set dst (AndL mask (ConvI2L (LoadI mem))));

  format %{ "lwu     $dst, $mem \t// zero-extend to long @ loadUI2L_lmask" %}
  ins_encode (load_N_enc(dst, mem));
  ins_pipe(ialu_loadI);
%}


// ============================================================================
// Safepoint Instruction
instruct safePoint_poll_reg(mRegP poll) %{
  match(SafePoint poll);
  predicate(false);
  effect(USE poll);

  ins_cost(125);
  format %{ "Safepoint @ [$poll] : poll for GC @ safePoint_poll_reg" %}

  ins_encode %{
    Register poll_reg = $poll$$Register;

    __ block_comment("Safepoint:");
    __ relocate(relocInfo::poll_type);
    __ lw(AT, poll_reg, 0);
  %}

  ins_pipe( ialu_storeI );
%}

instruct safePoint_poll() %{
  match(SafePoint);

  ins_cost(105);
  format %{ "poll for GC @ safePoint_poll" %}

  ins_encode %{
    __ block_comment("Safepoint:");
    __ set64(T9, (long)os::get_polling_page());
    __ relocate(relocInfo::poll_type);
    __ lw(AT, T9, 0);
  %}

  ins_pipe( ialu_storeI );
%}

//----------Arithmetic Conversion Instructions---------------------------------

instruct roundFloat_nop(regF dst)
%{
  match(Set dst (RoundFloat dst));

  ins_cost(0);
  ins_encode();
  ins_pipe(empty);
%}

instruct roundDouble_nop(regD dst)
%{
  match(Set dst (RoundDouble dst));

  ins_cost(0);
  ins_encode();
  ins_pipe(empty);
%}

//---------- Zeros Count Instructions ------------------------------------------
// CountLeadingZerosINode CountTrailingZerosINode
instruct countLeadingZerosI(mRegI dst, mRegI src) %{
  predicate(UseCountLeadingZerosInstructionMIPS64);
  match(Set dst (CountLeadingZerosI src));

  format %{ "clz  $dst, $src\t# count leading zeros (int)" %}
  ins_encode %{
    __ clz($dst$$Register, $src$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct countLeadingZerosL(mRegI dst, mRegL src) %{
  predicate(UseCountLeadingZerosInstructionMIPS64);
  match(Set dst (CountLeadingZerosL src));

  format %{ "dclz  $dst, $src\t# count leading zeros (long)" %}
  ins_encode %{
    __ dclz($dst$$Register, $src$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct countTrailingZerosI(mRegI dst, mRegI src) %{
  predicate(UseCountTrailingZerosInstructionMIPS64);
  match(Set dst (CountTrailingZerosI src));

  format %{ "ctz    $dst, $src\t# count trailing zeros (int)" %}
  ins_encode %{
    // ctz and dctz is gs instructions.
    __ ctz($dst$$Register, $src$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct countTrailingZerosL(mRegI dst, mRegL src) %{
  predicate(UseCountTrailingZerosInstructionMIPS64);
  match(Set dst (CountTrailingZerosL src));

  format %{ "dcto    $dst, $src\t# count trailing zeros (long)" %}
  ins_encode %{
    __ dctz($dst$$Register, $src$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

// ====================VECTOR INSTRUCTIONS=====================================

// Load vectors (8 bytes long)
instruct loadV8(vecD dst, memory mem) %{
  predicate(n->as_LoadVector()->memory_size() == 8);
  match(Set dst (LoadVector mem));
  ins_cost(125);
  format %{ "load    $dst, $mem\t! load vector (8 bytes)" %}
  ins_encode(load_D_enc(dst, mem));
  ins_pipe( fpu_loadF );
%}

// Store vectors (8 bytes long)
instruct storeV8(memory mem, vecD src) %{
  predicate(n->as_StoreVector()->memory_size() == 8);
  match(Set mem (StoreVector mem src));
  ins_cost(145);
  format %{ "store    $mem, $src\t! store vector (8 bytes)" %}
  ins_encode(store_D_reg_enc(mem, src));
  ins_pipe( fpu_storeF );
%}

instruct Repl8B_DSP(vecD dst, mRegI src) %{
  predicate(n->as_Vector()->length() == 8 && UseLEXT3);
  match(Set dst (ReplicateB src));
  ins_cost(100);
  format %{ "replv_ob    AT, $src\n\t"
            "dmtc1 AT, $dst\t! replicate8B" %}
  ins_encode %{
    __ replv_ob(AT, $src$$Register);
    __ dmtc1(AT, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

instruct Repl8B(vecD dst, mRegI src) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (ReplicateB src));
  ins_cost(140);
  format %{ "move       AT,  $src\n\t"
            "dins  AT, AT,  8,  8\n\t"
            "dins  AT, AT, 16, 16\n\t"
            "dinsu AT, AT, 32, 32\n\t"
            "dmtc1 AT, $dst\t! replicate8B" %}
  ins_encode %{
    __ move(AT, $src$$Register);
    __ dins(AT, AT, 8, 8);
    __ dins(AT, AT, 16, 16);
    __ dinsu(AT, AT, 32, 32);
    __ dmtc1(AT, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

instruct Repl8B_imm_DSP(vecD dst, immI con) %{
  predicate(n->as_Vector()->length() == 8 && UseLEXT3);
  match(Set dst (ReplicateB con));
  ins_cost(110);
  format %{ "repl_ob    AT, [$con]\n\t"
            "dmtc1 AT, $dst,0x00\t! replicate8B($con)" %}
  ins_encode %{
    int      val = $con$$constant;
    __ repl_ob(AT, val);
    __ dmtc1(AT, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

instruct Repl8B_imm(vecD dst, immI con) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (ReplicateB con));
  ins_cost(150);
  format %{ "move      AT, [$con]\n\t"
            "dins  AT, AT,  8,  8\n\t"
            "dins  AT, AT, 16, 16\n\t"
            "dinsu AT, AT, 32, 32\n\t"
            "dmtc1 AT, $dst,0x00\t! replicate8B($con)" %}
  ins_encode %{
    __ move(AT, $con$$constant);
    __ dins(AT, AT, 8, 8);
    __ dins(AT, AT, 16, 16);
    __ dinsu(AT, AT, 32, 32);
    __ dmtc1(AT, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

instruct Repl8B_zero(vecD dst, immI_0 zero) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (ReplicateB zero));
  ins_cost(90);
  format %{ "dmtc1    R0, $dst\t! replicate8B zero" %}
  ins_encode %{
    __ dmtc1(R0, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

instruct Repl8B_M1(vecD dst, immI_M1 M1) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (ReplicateB M1));
  ins_cost(80);
  format %{ "dmtc1    -1, $dst\t! replicate8B -1" %}
  ins_encode %{
    __ nor(AT, R0, R0);
    __ dmtc1(AT, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

instruct Repl4S_DSP(vecD dst, mRegI src) %{
  predicate(n->as_Vector()->length() == 4 && UseLEXT3);
  match(Set dst (ReplicateS src));
  ins_cost(100);
  format %{ "replv_qh    AT, $src\n\t"
            "dmtc1 AT, $dst\t! replicate4S" %}
  ins_encode %{
    __ replv_qh(AT, $src$$Register);
    __ dmtc1(AT, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

instruct Repl4S(vecD dst, mRegI src) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (ReplicateS src));
  ins_cost(120);
  format %{ "move    AT,     $src  \n\t"
            "dins    AT, AT, 16, 16\n\t"
            "dinsu   AT, AT, 32, 32\n\t"
            "dmtc1 AT, $dst\t! replicate4S" %}
  ins_encode %{
    __ move(AT, $src$$Register);
    __ dins(AT, AT, 16, 16);
    __ dinsu(AT, AT, 32, 32);
    __ dmtc1(AT, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

instruct Repl4S_imm_DSP(vecD dst, immI con) %{
  predicate(n->as_Vector()->length() == 4 && UseLEXT3);
  match(Set dst (ReplicateS con));
  ins_cost(100);
  format %{ "repl_qh    AT, [$con]\n\t"
            "dmtc1 AT, $dst\t! replicate4S($con)" %}
  ins_encode %{
    int      val = $con$$constant;
    if ( Assembler::is_simm(val, 10)) {
      //repl_qh supports 10 bits immediate
      __ repl_qh(AT, val);
    } else {
      __ li32(AT, val);
      __ replv_qh(AT, AT);
    }
    __ dmtc1(AT, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

instruct Repl4S_imm(vecD dst, immI con) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (ReplicateS con));
  ins_cost(110);
  format %{ "move    AT,   [$con]\n\t"
            "dins  AT, AT, 16, 16\n\t"
            "dinsu AT, AT, 32, 32\n\t"
            "dmtc1 AT, $dst\t! replicate4S($con)" %}
  ins_encode %{
    __ move(AT, $con$$constant);
    __ dins(AT, AT, 16, 16);
    __ dinsu(AT, AT, 32, 32);
    __ dmtc1(AT, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

instruct Repl4S_zero(vecD dst, immI_0 zero) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (ReplicateS zero));
  format %{ "dmtc1    R0, $dst\t! replicate4S zero" %}
  ins_encode %{
    __ dmtc1(R0, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

instruct Repl4S_M1(vecD dst, immI_M1 M1) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (ReplicateS M1));
  format %{ "dmtc1    -1, $dst\t! replicate4S -1" %}
  ins_encode %{
    __ nor(AT, R0, R0);
    __ dmtc1(AT, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

// Replicate integer (4 byte) scalar to be vector
instruct Repl2I(vecD dst, mRegI src) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (ReplicateI src));
  format %{ "dins    AT, $src, 0, 32\n\t"
            "dinsu   AT, $src, 32, 32\n\t"
            "dmtc1   AT, $dst\t! replicate2I" %}
  ins_encode %{
    __ dins(AT, $src$$Register, 0, 32);
    __ dinsu(AT, $src$$Register, 32, 32);
    __ dmtc1(AT, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

// Replicate integer (4 byte) scalar immediate to be vector by loading from const table.
instruct Repl2I_imm(vecD dst, immI con, mA7RegI tmp) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (ReplicateI con));
  effect(KILL tmp);
  format %{ "li32    AT, [$con], 32\n\t"
            "dinsu   AT,         AT\n\t"
            "dmtc1   AT, $dst\t! replicate2I($con)" %}
  ins_encode %{
    int      val = $con$$constant;
    __ li32(AT, val);
    __ dinsu(AT, AT, 32, 32);
    __ dmtc1(AT, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

// Replicate integer (4 byte) scalar zero to be vector
instruct Repl2I_zero(vecD dst, immI_0 zero) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (ReplicateI zero));
  format %{ "dmtc1    R0, $dst\t! replicate2I zero" %}
  ins_encode %{
    __ dmtc1(R0, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

// Replicate integer (4 byte) scalar -1 to be vector
instruct Repl2I_M1(vecD dst, immI_M1 M1) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (ReplicateI M1));
  format %{ "dmtc1    -1, $dst\t! replicate2I -1, use AT" %}
  ins_encode %{
    __ nor(AT, R0, R0);
    __ dmtc1(AT, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}

// Replicate float (4 byte) scalar to be vector
instruct Repl2F(vecD dst, regF src) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (ReplicateF src));
  format %{ "cvt.ps  $dst, $src, $src\t! replicate2F" %}
  ins_encode %{
    __ cvt_ps_s($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

// Replicate float (4 byte) scalar zero to be vector
instruct Repl2F_zero(vecD dst, immF_0 zero) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (ReplicateF zero));
  format %{ "dmtc1   R0, $dst\t! replicate2F zero" %}
  ins_encode %{
    __ dmtc1(R0, $dst$$FloatRegister);
  %}
  ins_pipe( pipe_mtc1 );
%}


// ====================VECTOR ARITHMETIC=======================================

// --------------------------------- ADD --------------------------------------

// Floats vector add
// kernel does not have emulation of PS instructions yet, so PS instructions is disabled.
instruct vadd2F(vecD dst, vecD src) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (AddVF dst src));
  format %{ "add.ps   $dst,$src\t! add packed2F" %}
  ins_encode %{
    __ add_ps($dst$$FloatRegister, $dst$$FloatRegister, $src$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct vadd2F3(vecD dst, vecD src1, vecD src2) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (AddVF src1 src2));
  format %{ "add.ps   $dst,$src1,$src2\t! add packed2F" %}
  ins_encode %{
    __ add_ps($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( fpu_regF_regF );
%}

// --------------------------------- SUB --------------------------------------

// Floats vector sub
instruct vsub2F(vecD dst, vecD src) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (SubVF dst src));
  format %{ "sub.ps   $dst,$src\t! sub packed2F" %}
  ins_encode %{
    __ sub_ps($dst$$FloatRegister, $dst$$FloatRegister, $src$$FloatRegister);
  %}
  ins_pipe( fpu_regF_regF );
%}

// --------------------------------- MUL --------------------------------------

// Floats vector mul
instruct vmul2F(vecD dst, vecD src) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (MulVF dst src));
  format %{ "mul.ps   $dst, $src\t! mul packed2F" %}
  ins_encode %{
    __ mul_ps($dst$$FloatRegister, $dst$$FloatRegister, $src$$FloatRegister);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct vmul2F3(vecD dst, vecD src1, vecD src2) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (MulVF src1 src2));
  format %{ "mul.ps   $dst, $src1, $src2\t! mul packed2F" %}
  ins_encode %{
    __ mul_ps($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( fpu_regF_regF );
%}

// --------------------------------- DIV --------------------------------------
// MIPS do not have div.ps

// --------------------------------- MADD --------------------------------------
// Floats vector madd
//instruct vmadd2F(vecD dst, vecD src1, vecD src2, vecD src3) %{
//  predicate(n->as_Vector()->length() == 2);
//  match(Set dst (AddVF (MulVF src1 src2) src3));
//  ins_cost(50);
//  format %{ "madd.ps   $dst, $src3, $src1, $src2\t! madd packed2F" %}
//  ins_encode %{
//    __ madd_ps($dst$$FloatRegister, $src3$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
//  %}
//  ins_pipe( fpu_regF_regF );
//%}


//----------PEEPHOLE RULES-----------------------------------------------------
// These must follow all instruction definitions as they use the names
// defined in the instructions definitions.
//
// peepmatch ( root_instr_name [preceeding_instruction]* );
//
// peepconstraint %{
// (instruction_number.operand_name relational_op instruction_number.operand_name
//  [, ...] );
// // instruction numbers are zero-based using left to right order in peepmatch
//
// peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
// // provide an instruction_number.operand_name for each operand that appears
// // in the replacement instruction's match rule
//
// ---------VM FLAGS---------------------------------------------------------
//
// All peephole optimizations can be turned off using -XX:-OptoPeephole
//
// Each peephole rule is given an identifying number starting with zero and
// increasing by one in the order seen by the parser.  An individual peephole
// can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
// on the command-line.
//
// ---------CURRENT LIMITATIONS----------------------------------------------
//
// Only match adjacent instructions in same basic block
// Only equality constraints
// Only constraints between operands, not (0.dest_reg == EAX_enc)
// Only one replacement instruction
//
// ---------EXAMPLE----------------------------------------------------------
//
// // pertinent parts of existing instructions in architecture description
// instruct movI(eRegI dst, eRegI src) %{
//   match(Set dst (CopyI src));
// %}
//
// instruct incI_eReg(eRegI dst, immI_1 src, eFlagsReg cr) %{
//   match(Set dst (AddI dst src));
//   effect(KILL cr);
// %}
//
// // Change (inc mov) to lea
// peephole %{
//   // increment preceeded by register-register move
//   peepmatch ( incI_eReg movI );
//   // require that the destination register of the increment
//   // match the destination register of the move
//   peepconstraint ( 0.dst == 1.dst );
//   // construct a replacement instruction that sets
//   // the destination to ( move's source register + one )
//   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );
// %}
//
// Implementation no longer uses movX instructions since
// machine-independent system no longer uses CopyX nodes.
//
// peephole %{
//   peepmatch ( incI_eReg movI );
//   peepconstraint ( 0.dst == 1.dst );
//   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );
// %}
//
// peephole %{
//   peepmatch ( decI_eReg movI );
//   peepconstraint ( 0.dst == 1.dst );
//   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );
// %}
//
// peephole %{
//   peepmatch ( addI_eReg_imm movI );
//   peepconstraint ( 0.dst == 1.dst );
//   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );
// %}
//
// peephole %{
//   peepmatch ( addP_eReg_imm movP );
//   peepconstraint ( 0.dst == 1.dst );
//   peepreplace ( leaP_eReg_immI( 0.dst 1.src 0.src ) );
// %}

// // Change load of spilled value to only a spill
// instruct storeI(memory mem, eRegI src) %{
//   match(Set mem (StoreI mem src));
// %}
//
// instruct loadI(eRegI dst, memory mem) %{
//   match(Set dst (LoadI mem));
// %}
//
//peephole %{
//  peepmatch ( loadI storeI );
//  peepconstraint ( 1.src == 0.dst, 1.mem == 0.mem );
//  peepreplace ( storeI( 1.mem 1.mem 1.src ) );
//%}

//----------SMARTSPILL RULES---------------------------------------------------
// These must follow all instruction definitions as they use the names
// defined in the instructions definitions.

